{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shajarian/Transformer/blob/main/Maybe_Final_Attempt_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGuHA9vDgGwH",
        "outputId": "c4319f78-4d40-41f2-ae50-5303a60f5576"
      },
      "id": "vGuHA9vDgGwH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May  2 03:08:56 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cd24096",
      "metadata": {
        "id": "9cd24096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "7509e7b9-5f52-4291-9352-e8d229ef39a1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-48b0917e1e7c>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdata_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/My Drive/data/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "data_location = \"/content/drive/My Drive/data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f97d3b6a",
      "metadata": {
        "id": "f97d3b6a"
      },
      "outputs": [],
      "source": [
        "questions_df = pd.read_csv(data_location + \"Questions.csv\",encoding='ISO-8859-1')\n",
        "questions_df.drop(columns = [\"CreationDate\", \"OwnerUserId\", \"ClosedDate\"],inplace = True)\n",
        "questions_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HiqrqLUNET3R",
      "metadata": {
        "id": "HiqrqLUNET3R"
      },
      "outputs": [],
      "source": [
        "# filter out questions with score less than 10\n",
        "min_score = 10\n",
        "np.shape(questions_df[questions_df['Score']>min_score])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34c23e77",
      "metadata": {
        "id": "34c23e77"
      },
      "outputs": [],
      "source": [
        "# drop questions that have score less than 10\n",
        "questions_df = questions_df[questions_df['Score']>min_score]\n",
        "questions_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a62a50a4",
      "metadata": {
        "id": "a62a50a4"
      },
      "outputs": [],
      "source": [
        "tags_df = pd.read_csv(data_location + \"Tags.csv\")\n",
        "tags_df['Tag'] = tags_df['Tag'].astype(str) # Converting \"Tag\" values into string to make actions like appending easier\n",
        "tags_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a70463e",
      "metadata": {
        "id": "7a70463e"
      },
      "outputs": [],
      "source": [
        "# Counting the number of unique tags\n",
        "len(tags_df.Tag.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfbaa3d8",
      "metadata": {
        "id": "bfbaa3d8"
      },
      "outputs": [],
      "source": [
        "top_tags_number = 30\n",
        "top_tags = tags_df['Tag'].value_counts().head(top_tags_number).index.tolist()\n",
        "top_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92442def",
      "metadata": {
        "id": "92442def"
      },
      "outputs": [],
      "source": [
        "tags_df = tags_df[tags_df['Tag'].isin(top_tags)]\n",
        "tags_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4b25430",
      "metadata": {
        "id": "f4b25430"
      },
      "outputs": [],
      "source": [
        "grouped_tags_df = tags_df.groupby('Id')['Tag'].apply(list).reset_index(name = \"Tags\")\n",
        "grouped_tags_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07ac2921",
      "metadata": {
        "id": "07ac2921"
      },
      "outputs": [],
      "source": [
        "# v = 99.85\n",
        "# p = np.percentile(tag_counts, v)\n",
        "# print(v, \" percentile of arr : \", p)\n",
        "# print(np.count_nonzero(tag_counts >= p))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51bae3e0",
      "metadata": {
        "id": "51bae3e0"
      },
      "source": [
        "Based on the graph, the threshold for cutting the data can be at around count of 18,000 which equals percentile 99.95 and leaves only 20 labels in our dataset. Since we want a higher number of labels, we will consider top-50 labels in tags dataset and remove the rest. This will help students find the most relevant categories or teachers categories the assignments in the meaningful groups."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = re.sub(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});|\\n', '', text)   # remove HTML tags\n",
        "    text = re.sub(r'[^\\w\\s]','', text)  # remove punctuation marks\n",
        "    Tidy_body = text.lower()\n",
        "    return Tidy_body\n",
        "\n",
        "questions_df['Tidy_body'] = questions_df['Body'].apply(preprocess_text)\n",
        "questions_df.reset_index(inplace=True,drop=True)\n",
        "questions_df"
      ],
      "metadata": {
        "id": "EqFLbLImXXxZ"
      },
      "id": "EqFLbLImXXxZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c288f389",
      "metadata": {
        "id": "c288f389"
      },
      "outputs": [],
      "source": [
        "questions_df = questions_df.merge(grouped_tags_df, on='Id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80b1d39a",
      "metadata": {
        "id": "80b1d39a"
      },
      "outputs": [],
      "source": [
        "questions_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32756c2f",
      "metadata": {
        "id": "32756c2f"
      },
      "outputs": [],
      "source": [
        "questions_df.Tags[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49b2d0a6",
      "metadata": {
        "id": "49b2d0a6"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "tag_matrix = mlb.fit_transform(questions_df.Tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67ecf575",
      "metadata": {
        "id": "67ecf575"
      },
      "outputs": [],
      "source": [
        "mlb.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "457648ca",
      "metadata": {
        "id": "457648ca"
      },
      "outputs": [],
      "source": [
        "questions_df['Binarized_Tags'] = list(tag_matrix)\n",
        "questions_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# create example dataframe\n",
        "df = questions_df\n",
        "\n",
        "# filter rows with list of more than one element\n",
        "df_filtered = df[df['Tags'].apply(lambda x: len(x) > 1)]\n",
        "\n",
        "# plot count of sizes more than one\n",
        "sizes = df_filtered['Tags'].apply(len)\n",
        "sizes_counts = sizes.value_counts()\n",
        "sizes_counts.plot(kind='bar')\n",
        "plt.xlabel('List size')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Count of list sizes more than one')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O5ohFje_ha7w"
      },
      "id": "O5ohFje_ha7w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions_df.drop(columns = [\"Id\", \"Score\", \"Title\",\"Body\"],inplace = True)\n",
        "questions_df"
      ],
      "metadata": {
        "id": "lrWijfi6aVUk"
      },
      "id": "lrWijfi6aVUk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14464ded",
      "metadata": {
        "id": "14464ded"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# compute no. of words in each question\n",
        "questions = questions_df.Tidy_body\n",
        "word_cnt = [len(quest) for quest in questions]\n",
        "\n",
        "# Plot the distribution\n",
        "plt.figure(figsize=[8,5])\n",
        "n, bins, patches = plt.hist(word_cnt, bins = 4 * 13) # the highest number of tokens in a question is 13368--so we choose the n*13 as the no. of bins to the bin range\n",
        "plt.xlabel('Word Count/Question')\n",
        "plt.ylabel('# of Occurrences')\n",
        "plt.title(\"Frequency of Word Counts/sentence\")\n",
        "\n",
        "# Add count values to top of each bar\n",
        "for i, patch in enumerate(patches):\n",
        "    x = patch.get_x() + patch.get_width() / 2\n",
        "    y = patch.get_height()\n",
        "    plt.text(x, y, int(n[i]), ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from wordcloud import WordCloud\n",
        "# tag_to_count_map\n",
        "# tupl = dict(tag_to_count_map.items())\n",
        "# word_cloud = WordCloud(width=1600,height=800,).generate_from_frequencies(tupl)\n",
        "# plt.figure(figsize = (12,8))\n",
        "# plt.imshow(word_cloud)\n",
        "# plt.axis('off')\n",
        "# plt.tight_layout(pad=0)"
      ],
      "metadata": {
        "id": "inC7OjUIY5CI"
      },
      "id": "inC7OjUIY5CI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7YYpNIDNY4gB"
      },
      "id": "7YYpNIDNY4gB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "812ac85e",
      "metadata": {
        "id": "812ac85e"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "MAX_LEN = 512\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 16\n",
        "EPOCHS = 4\n",
        "LEARNING_RATE = 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcb877a9",
      "metadata": {
        "id": "dcb877a9"
      },
      "outputs": [],
      "source": [
        "# Import tokenizer\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We use BERT-base and as in our context the upper case is not important, we use uncased\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "DBO9Q-yEbnT-"
      },
      "id": "DBO9Q-yEbnT-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bfbd89cf",
      "metadata": {
        "id": "bfbd89cf"
      },
      "source": [
        "Based on this plot, it can be seen that the maximum number of 500 tokens encompass most of questions."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions_df[\"Binarized_Tags\"]"
      ],
      "metadata": {
        "id": "KWPIwjzPCr_p"
      },
      "id": "KWPIwjzPCr_p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tokenizer.encode_plus function combines multiple steps for us:\n",
        "\n",
        "\n",
        "*   Split the sentence into tokens.\n",
        "*   Add the special [CLS] and [SEP] tokens.\n",
        "*   Map the tokens to their IDs.\n",
        "*   Pad or truncate all sentences to the same length.\n",
        "*   Create the attention masks which explicitly differentiate real tokens from [PAD] tokens.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m_1Vap2u2UGe"
      },
      "id": "m_1Vap2u2UGe"
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data for BERT and prepare DataLoader\n",
        "import torch\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.title = df.Tidy_body\n",
        "        self.targets = df.Binarized_Tags\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.title)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        title = str(self.title[index])\n",
        "        title = \" \".join(title.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            title,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
        "            'targets': torch.FloatTensor(self.targets[index])\n",
        "        }\n"
      ],
      "metadata": {
        "id": "IcmNRcA11pay"
      },
      "id": "IcmNRcA11pay",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We Divide up our training set to use 80% for training and 20% for validation and test."
      ],
      "metadata": {
        "id": "TlvqO87d29Ac"
      },
      "id": "TlvqO87d29Ac"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ed0a97d",
      "metadata": {
        "id": "7ed0a97d"
      },
      "outputs": [],
      "source": [
        "# Dataset Split\n",
        "train_size = 0.8\n",
        "\n",
        "train_df = questions_df.sample(frac=train_size, random_state=200).reset_index(drop=True)\n",
        "remaining_df = questions_df.drop(train_df.index).reset_index(drop=True)\n",
        "val_df = remaining_df.sample(frac=0.5, random_state=200).reset_index(drop=True)\n",
        "test_df = remaining_df.drop(val_df.index).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad120c44",
      "metadata": {
        "id": "ad120c44"
      },
      "outputs": [],
      "source": [
        "len(train_df) ,len(val_df), len(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61f5d9bc",
      "metadata": {
        "id": "61f5d9bc"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(train_df, tokenizer, MAX_LEN)\n",
        "valid_dataset = CustomDataset(val_df, tokenizer, MAX_LEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The DataLoader is responsible for providing batches of data during training."
      ],
      "metadata": {
        "id": "ikrwIyZj4exS"
      },
      "id": "ikrwIyZj4exS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e480a94",
      "metadata": {
        "id": "7e480a94"
      },
      "outputs": [],
      "source": [
        "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_data_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "    batch_size=VALID_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of the tensor is typically (batch_size, sequence_length), where batch_size is the number of samples in a batch and sequence_length is the length of the padded or truncated input sequences."
      ],
      "metadata": {
        "id": "NASvlEcC4SNs"
      },
      "id": "NASvlEcC4SNs"
    },
    {
      "cell_type": "code",
      "source": [
        "a=next(iter(train_data_loader))\n",
        "a['input_ids'].shape"
      ],
      "metadata": {
        "id": "uis_9V_yr-Dl"
      },
      "id": "uis_9V_yr-Dl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cde0aa2b",
      "metadata": {
        "id": "cde0aa2b"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "  This is one of the important part of this code. Hence I explain it step-by-step.\n",
        "*   BERTClass is defined as a subclass of nn.Module, which is the base class for all neural network modules in PyTorch.\n",
        "* In the __init__ method, super(BERTClass, self).__init__() calls the constructor of the base class nn.Module.\n",
        "* The BERT model is loaded from the 'bert-base-uncased' pre-trained weights using the BertModel.from_pretrained() method, with the return_dict argument set to True. This means the model will return its outputs as a dictionary instead of a tuple.\n",
        "* A dropout layer with a 0.3 dropout rate is added to the model.\n",
        "* A linear layer is added to the model, which takes the BERT model's hidden layer representation of size 768 as input and outputs a vector of size top_tags_number for multi-label classification.\n",
        "* The forward method takes input_ids, attn_mask, and token_type_ids as input and passes them through the BERT model.\n",
        "* The output of the BERT model is a dictionary, and the pooled output representation (corresponding to the [CLS] token) is passed through the dropout layer.\n",
        "* The output of the dropout layer is passed through the linear layer, which produces the final output of the model."
      ],
      "metadata": {
        "id": "IrmKly315jpe"
      },
      "id": "IrmKly315jpe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "383fbf05",
      "metadata": {
        "id": "383fbf05"
      },
      "outputs": [],
      "source": [
        "# Define model and train\n",
        "import torch.nn as nn\n",
        "\n",
        "class BERTClass(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True) # sets the return_dict flag to True, so that the model outputs are returned as a dictionary instead of a tuple.\n",
        "        self.dropout = torch.nn.Dropout(0.4)\n",
        "        self.linear = torch.nn.Linear(768, top_tags_number) # 768 is the size of the hidden layer representations in the transformer network.\n",
        "\n",
        "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
        "        output = self.bert_model(\n",
        "            input_ids,\n",
        "            attention_mask=attn_mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "        output_dropout = self.dropout(output.pooler_output) #this is a pooler output\n",
        "        output = self.linear(output_dropout)\n",
        "        return output\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We chose BCEWithLogitsLoss because it stands for Binary Cross-Entropy with Logits Loss. This loss function is suitable for multi-label classification tasks where each label can be either 0 or 1, and the model should predict probabilities for each label independently. It combines a sigmoid activation function and the binary cross-entropy loss in a single class. This is more numerically stable than using a separate sigmoid activation followed by a binary cross-entropy loss"
      ],
      "metadata": {
        "id": "iz7IvyPq8VMp"
      },
      "id": "iz7IvyPq8VMp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49b7fedd",
      "metadata": {
        "id": "49b7fedd"
      },
      "outputs": [],
      "source": [
        "# Define loss function using logits loss (combination of Binary Cross Entropy)\n",
        "def loss_fn(outputs, targets):\n",
        "    return nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = EPOCHS\n",
        "# Total number of training steps is [number of batches] x [number of epochs].\n",
        "total_steps = len(train_data_loader) * epochs\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "rinzz-MrLO5y"
      },
      "id": "rinzz-MrLO5y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e571995",
      "metadata": {
        "id": "3e571995"
      },
      "outputs": [],
      "source": [
        "val_targets=[]\n",
        "val_outputs=[]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Function to calculate the accuracy of our predictions vs targets\n",
        "# def flat_accuracy(preds, targets):\n",
        "#     pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#     targets_flat = targets.flatten()\n",
        "#     return np.sum(pred_flat == targets_flat) / len(targets_flat)"
      ],
      "metadata": {
        "id": "2ZsYn8IengCD"
      },
      "id": "2ZsYn8IengCD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "3BoSsOQwIW9c"
      },
      "id": "3BoSsOQwIW9c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11ec2f9f",
      "metadata": {
        "id": "11ec2f9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "63176d09-0e82-4495-a2d7-e1473567cea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "Training...\n",
            "  Batch    40  of  1,189.    Elapsed: 0:00:02.\n",
            "bert_model.embeddings.word_embeddings.weight 0.06225099787116051\n",
            "bert_model.embeddings.position_embeddings.weight 0.054681554436683655\n",
            "bert_model.embeddings.token_type_embeddings.weight 0.2115832269191742\n",
            "bert_model.embeddings.LayerNorm.weight 0.020112715661525726\n",
            "bert_model.embeddings.LayerNorm.bias 0.01539535354822874\n",
            "bert_model.encoder.layer.0.attention.self.query.weight 0.021729519590735435\n",
            "bert_model.encoder.layer.0.attention.self.query.bias 0.001712016761302948\n",
            "bert_model.encoder.layer.0.attention.self.key.weight 0.020216593518853188\n",
            "bert_model.encoder.layer.0.attention.self.key.bias 3.840443241198699e-10\n",
            "bert_model.encoder.layer.0.attention.self.value.weight 0.069302037358284\n",
            "bert_model.encoder.layer.0.attention.self.value.bias 0.014064876362681389\n",
            "bert_model.encoder.layer.0.attention.output.dense.weight 0.04588440805673599\n",
            "bert_model.encoder.layer.0.attention.output.dense.bias 0.011352401226758957\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.weight 0.00559678440913558\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.bias 0.008210462518036366\n",
            "bert_model.encoder.layer.0.intermediate.dense.weight 0.16618309915065765\n",
            "bert_model.encoder.layer.0.intermediate.dense.bias 0.0035432083532214165\n",
            "bert_model.encoder.layer.0.output.dense.weight 0.03998393937945366\n",
            "bert_model.encoder.layer.0.output.dense.bias 0.007354686502367258\n",
            "bert_model.encoder.layer.0.output.LayerNorm.weight 0.0129645224660635\n",
            "bert_model.encoder.layer.0.output.LayerNorm.bias 0.015181231312453747\n",
            "bert_model.encoder.layer.1.attention.self.query.weight 0.02159169688820839\n",
            "bert_model.encoder.layer.1.attention.self.query.bias 0.0027130760718137026\n",
            "bert_model.encoder.layer.1.attention.self.key.weight 0.01593608222901821\n",
            "bert_model.encoder.layer.1.attention.self.key.bias 2.0218092477986005e-10\n",
            "bert_model.encoder.layer.1.attention.self.value.weight 0.07209266722202301\n",
            "bert_model.encoder.layer.1.attention.self.value.bias 0.009614660404622555\n",
            "bert_model.encoder.layer.1.attention.output.dense.weight 0.050986308604478836\n",
            "bert_model.encoder.layer.1.attention.output.dense.bias 0.011396954767405987\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.weight 0.005327625200152397\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.bias 0.00894669909030199\n",
            "bert_model.encoder.layer.1.intermediate.dense.weight 0.13947339355945587\n",
            "bert_model.encoder.layer.1.intermediate.dense.bias 0.006179731339216232\n",
            "bert_model.encoder.layer.1.output.dense.weight 0.050638772547245026\n",
            "bert_model.encoder.layer.1.output.dense.bias 0.010224899277091026\n",
            "bert_model.encoder.layer.1.output.LayerNorm.weight 0.006412501446902752\n",
            "bert_model.encoder.layer.1.output.LayerNorm.bias 0.016521304845809937\n",
            "bert_model.encoder.layer.2.attention.self.query.weight 0.01846250519156456\n",
            "bert_model.encoder.layer.2.attention.self.query.bias 0.0016179897356778383\n",
            "bert_model.encoder.layer.2.attention.self.key.weight 0.01346858125180006\n",
            "bert_model.encoder.layer.2.attention.self.key.bias 1.677603056471355e-10\n",
            "bert_model.encoder.layer.2.attention.self.value.weight 0.1099906787276268\n",
            "bert_model.encoder.layer.2.attention.self.value.bias 0.011046611703932285\n",
            "bert_model.encoder.layer.2.attention.output.dense.weight 0.05941755697131157\n",
            "bert_model.encoder.layer.2.attention.output.dense.bias 0.01334505993872881\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.weight 0.0053903087973594666\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.bias 0.011338657699525356\n",
            "bert_model.encoder.layer.2.intermediate.dense.weight 0.09497631341218948\n",
            "bert_model.encoder.layer.2.intermediate.dense.bias 0.0036636353470385075\n",
            "bert_model.encoder.layer.2.output.dense.weight 0.04975563660264015\n",
            "bert_model.encoder.layer.2.output.dense.bias 0.011240502819418907\n",
            "bert_model.encoder.layer.2.output.LayerNorm.weight 0.0351480208337307\n",
            "bert_model.encoder.layer.2.output.LayerNorm.bias 0.018152903765439987\n",
            "bert_model.encoder.layer.3.attention.self.query.weight 0.03184029087424278\n",
            "bert_model.encoder.layer.3.attention.self.query.bias 0.003050713101401925\n",
            "bert_model.encoder.layer.3.attention.self.key.weight 0.0196064505726099\n",
            "bert_model.encoder.layer.3.attention.self.key.bias 1.7536107288496083e-10\n",
            "bert_model.encoder.layer.3.attention.self.value.weight 0.10902708768844604\n",
            "bert_model.encoder.layer.3.attention.self.value.bias 0.013347025960683823\n",
            "bert_model.encoder.layer.3.attention.output.dense.weight 0.06391985714435577\n",
            "bert_model.encoder.layer.3.attention.output.dense.bias 0.013943611644208431\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.weight 0.008014331571757793\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.bias 0.012128644622862339\n",
            "bert_model.encoder.layer.3.intermediate.dense.weight 0.2802180051803589\n",
            "bert_model.encoder.layer.3.intermediate.dense.bias 0.007403321098536253\n",
            "bert_model.encoder.layer.3.output.dense.weight 0.06600296497344971\n",
            "bert_model.encoder.layer.3.output.dense.bias 0.010563352145254612\n",
            "bert_model.encoder.layer.3.output.LayerNorm.weight 0.018864484503865242\n",
            "bert_model.encoder.layer.3.output.LayerNorm.bias 0.01804518885910511\n",
            "bert_model.encoder.layer.4.attention.self.query.weight 0.050635162740945816\n",
            "bert_model.encoder.layer.4.attention.self.query.bias 0.003229741472750902\n",
            "bert_model.encoder.layer.4.attention.self.key.weight 0.041928209364414215\n",
            "bert_model.encoder.layer.4.attention.self.key.bias 3.718559071774763e-10\n",
            "bert_model.encoder.layer.4.attention.self.value.weight 0.09746726602315903\n",
            "bert_model.encoder.layer.4.attention.self.value.bias 0.012223925441503525\n",
            "bert_model.encoder.layer.4.attention.output.dense.weight 0.05479288101196289\n",
            "bert_model.encoder.layer.4.attention.output.dense.bias 0.012238854542374611\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.weight 0.005576405208557844\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.bias 0.01116653811186552\n",
            "bert_model.encoder.layer.4.intermediate.dense.weight 0.13565079867839813\n",
            "bert_model.encoder.layer.4.intermediate.dense.bias 0.005639819428324699\n",
            "bert_model.encoder.layer.4.output.dense.weight 0.05453241616487503\n",
            "bert_model.encoder.layer.4.output.dense.bias 0.011419654823839664\n",
            "bert_model.encoder.layer.4.output.LayerNorm.weight 0.01697278395295143\n",
            "bert_model.encoder.layer.4.output.LayerNorm.bias 0.01842541992664337\n",
            "bert_model.encoder.layer.5.attention.self.query.weight 0.02298545464873314\n",
            "bert_model.encoder.layer.5.attention.self.query.bias 0.0013299582060426474\n",
            "bert_model.encoder.layer.5.attention.self.key.weight 0.019058961421251297\n",
            "bert_model.encoder.layer.5.attention.self.key.bias 1.6095684507444474e-10\n",
            "bert_model.encoder.layer.5.attention.self.value.weight 0.08843233436346054\n",
            "bert_model.encoder.layer.5.attention.self.value.bias 0.011269775219261646\n",
            "bert_model.encoder.layer.5.attention.output.dense.weight 0.044351015239953995\n",
            "bert_model.encoder.layer.5.attention.output.dense.bias 0.013495011255145073\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.weight 0.006442207843065262\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.bias 0.012306692078709602\n",
            "bert_model.encoder.layer.5.intermediate.dense.weight 0.09680917859077454\n",
            "bert_model.encoder.layer.5.intermediate.dense.bias 0.0037094259168952703\n",
            "bert_model.encoder.layer.5.output.dense.weight 0.04465511813759804\n",
            "bert_model.encoder.layer.5.output.dense.bias 0.011400172486901283\n",
            "bert_model.encoder.layer.5.output.LayerNorm.weight 0.011802851222455502\n",
            "bert_model.encoder.layer.5.output.LayerNorm.bias 0.018082404509186745\n",
            "bert_model.encoder.layer.6.attention.self.query.weight 0.016329143196344376\n",
            "bert_model.encoder.layer.6.attention.self.query.bias 0.0008911962504498661\n",
            "bert_model.encoder.layer.6.attention.self.key.weight 0.014958114363253117\n",
            "bert_model.encoder.layer.6.attention.self.key.bias 2.015844852154558e-10\n",
            "bert_model.encoder.layer.6.attention.self.value.weight 0.08791237324476242\n",
            "bert_model.encoder.layer.6.attention.self.value.bias 0.010224827565252781\n",
            "bert_model.encoder.layer.6.attention.output.dense.weight 0.04257017746567726\n",
            "bert_model.encoder.layer.6.attention.output.dense.bias 0.012266337871551514\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.weight 0.0071911863051354885\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.bias 0.011890497989952564\n",
            "bert_model.encoder.layer.6.intermediate.dense.weight 0.08669963479042053\n",
            "bert_model.encoder.layer.6.intermediate.dense.bias 0.0033676528837531805\n",
            "bert_model.encoder.layer.6.output.dense.weight 0.04397730529308319\n",
            "bert_model.encoder.layer.6.output.dense.bias 0.011173875071108341\n",
            "bert_model.encoder.layer.6.output.LayerNorm.weight 0.013307636603713036\n",
            "bert_model.encoder.layer.6.output.LayerNorm.bias 0.01794174313545227\n",
            "bert_model.encoder.layer.7.attention.self.query.weight 0.010544544085860252\n",
            "bert_model.encoder.layer.7.attention.self.query.bias 0.0006997525342740119\n",
            "bert_model.encoder.layer.7.attention.self.key.weight 0.00898248702287674\n",
            "bert_model.encoder.layer.7.attention.self.key.bias 1.0714507059361722e-10\n",
            "bert_model.encoder.layer.7.attention.self.value.weight 0.08477190881967545\n",
            "bert_model.encoder.layer.7.attention.self.value.bias 0.009520107880234718\n",
            "bert_model.encoder.layer.7.attention.output.dense.weight 0.03680946305394173\n",
            "bert_model.encoder.layer.7.attention.output.dense.bias 0.013515702448785305\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.weight 0.008595430292189121\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.bias 0.012605005875229836\n",
            "bert_model.encoder.layer.7.intermediate.dense.weight 0.10155947506427765\n",
            "bert_model.encoder.layer.7.intermediate.dense.bias 0.0034149496350437403\n",
            "bert_model.encoder.layer.7.output.dense.weight 0.05221426859498024\n",
            "bert_model.encoder.layer.7.output.dense.bias 0.01259760744869709\n",
            "bert_model.encoder.layer.7.output.LayerNorm.weight 0.010270236991345882\n",
            "bert_model.encoder.layer.7.output.LayerNorm.bias 0.021002884954214096\n",
            "bert_model.encoder.layer.8.attention.self.query.weight 0.02489187754690647\n",
            "bert_model.encoder.layer.8.attention.self.query.bias 0.0021558094304054976\n",
            "bert_model.encoder.layer.8.attention.self.key.weight 0.01963840238749981\n",
            "bert_model.encoder.layer.8.attention.self.key.bias 1.8801393775191855e-10\n",
            "bert_model.encoder.layer.8.attention.self.value.weight 0.10355313122272491\n",
            "bert_model.encoder.layer.8.attention.self.value.bias 0.013512173667550087\n",
            "bert_model.encoder.layer.8.attention.output.dense.weight 0.04779363051056862\n",
            "bert_model.encoder.layer.8.attention.output.dense.bias 0.01614123024046421\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.weight 0.013332199305295944\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.bias 0.013977045193314552\n",
            "bert_model.encoder.layer.8.intermediate.dense.weight 0.1244044229388237\n",
            "bert_model.encoder.layer.8.intermediate.dense.bias 0.0037128012627363205\n",
            "bert_model.encoder.layer.8.output.dense.weight 0.056002210825681686\n",
            "bert_model.encoder.layer.8.output.dense.bias 0.01419405173510313\n",
            "bert_model.encoder.layer.8.output.LayerNorm.weight 0.011633713729679585\n",
            "bert_model.encoder.layer.8.output.LayerNorm.bias 0.022445382550358772\n",
            "bert_model.encoder.layer.9.attention.self.query.weight 0.01775299943983555\n",
            "bert_model.encoder.layer.9.attention.self.query.bias 0.0013185404241085052\n",
            "bert_model.encoder.layer.9.attention.self.key.weight 0.01437889039516449\n",
            "bert_model.encoder.layer.9.attention.self.key.bias 1.8018619929449642e-10\n",
            "bert_model.encoder.layer.9.attention.self.value.weight 0.08552349358797073\n",
            "bert_model.encoder.layer.9.attention.self.value.bias 0.012873068451881409\n",
            "bert_model.encoder.layer.9.attention.output.dense.weight 0.06365570425987244\n",
            "bert_model.encoder.layer.9.attention.output.dense.bias 0.014564651064574718\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.weight 0.010947277769446373\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.bias 0.01360031682997942\n",
            "bert_model.encoder.layer.9.intermediate.dense.weight 0.0825423002243042\n",
            "bert_model.encoder.layer.9.intermediate.dense.bias 0.004552031867206097\n",
            "bert_model.encoder.layer.9.output.dense.weight 0.06572133302688599\n",
            "bert_model.encoder.layer.9.output.dense.bias 0.014309077523648739\n",
            "bert_model.encoder.layer.9.output.LayerNorm.weight 0.012553944252431393\n",
            "bert_model.encoder.layer.9.output.LayerNorm.bias 0.020789096131920815\n",
            "bert_model.encoder.layer.10.attention.self.query.weight 0.01950402744114399\n",
            "bert_model.encoder.layer.10.attention.self.query.bias 0.001428579562343657\n",
            "bert_model.encoder.layer.10.attention.self.key.weight 0.016743142157793045\n",
            "bert_model.encoder.layer.10.attention.self.key.bias 1.838644375640186e-10\n",
            "bert_model.encoder.layer.10.attention.self.value.weight 0.09041450917720795\n",
            "bert_model.encoder.layer.10.attention.self.value.bias 0.013125510886311531\n",
            "bert_model.encoder.layer.10.attention.output.dense.weight 0.06731044501066208\n",
            "bert_model.encoder.layer.10.attention.output.dense.bias 0.01281756442040205\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.weight 0.011947437189519405\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.bias 0.01288359984755516\n",
            "bert_model.encoder.layer.10.intermediate.dense.weight 0.09468778967857361\n",
            "bert_model.encoder.layer.10.intermediate.dense.bias 0.0046760751865804195\n",
            "bert_model.encoder.layer.10.output.dense.weight 0.06530936062335968\n",
            "bert_model.encoder.layer.10.output.dense.bias 0.013251426629722118\n",
            "bert_model.encoder.layer.10.output.LayerNorm.weight 0.014138514176011086\n",
            "bert_model.encoder.layer.10.output.LayerNorm.bias 0.018466075882315636\n",
            "bert_model.encoder.layer.11.attention.self.query.weight 0.018284311518073082\n",
            "bert_model.encoder.layer.11.attention.self.query.bias 0.001143513130955398\n",
            "bert_model.encoder.layer.11.attention.self.key.weight 0.017743462696671486\n",
            "bert_model.encoder.layer.11.attention.self.key.bias 1.1137520072868057e-10\n",
            "bert_model.encoder.layer.11.attention.self.value.weight 0.13011083006858826\n",
            "bert_model.encoder.layer.11.attention.self.value.bias 0.01093662902712822\n",
            "bert_model.encoder.layer.11.attention.output.dense.weight 0.07584911584854126\n",
            "bert_model.encoder.layer.11.attention.output.dense.bias 0.00965228583663702\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.weight 0.007654649671167135\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.bias 0.00860388670116663\n",
            "bert_model.encoder.layer.11.intermediate.dense.weight 0.13187485933303833\n",
            "bert_model.encoder.layer.11.intermediate.dense.bias 0.0043413215316832066\n",
            "bert_model.encoder.layer.11.output.dense.weight 0.07347772270441055\n",
            "bert_model.encoder.layer.11.output.dense.bias 0.008013472892343998\n",
            "bert_model.encoder.layer.11.output.LayerNorm.weight 0.019374828785657883\n",
            "bert_model.encoder.layer.11.output.LayerNorm.bias 0.018465789034962654\n",
            "bert_model.pooler.dense.weight 0.42800405621528625\n",
            "bert_model.pooler.dense.bias 0.03417695686221123\n",
            "linear.weight 1.251747727394104\n",
            "linear.bias 0.08309003710746765\n",
            "\n",
            "  training loss: 0.02\n",
            "  Training epcoh took: 0:00:07\n",
            "  Batch    80  of  1,189.    Elapsed: 0:00:10.\n",
            "bert_model.embeddings.word_embeddings.weight 0.005133000668138266\n",
            "bert_model.embeddings.position_embeddings.weight 0.0051318006590008736\n",
            "bert_model.embeddings.token_type_embeddings.weight 0.030377522110939026\n",
            "bert_model.embeddings.LayerNorm.weight 0.0011052151676267385\n",
            "bert_model.embeddings.LayerNorm.bias 0.001978002954274416\n",
            "bert_model.encoder.layer.0.attention.self.query.weight 0.0011013572802767158\n",
            "bert_model.encoder.layer.0.attention.self.query.bias 0.00011511949560372159\n",
            "bert_model.encoder.layer.0.attention.self.key.weight 0.0010541124502196908\n",
            "bert_model.encoder.layer.0.attention.self.key.bias 8.427104500330351e-12\n",
            "bert_model.encoder.layer.0.attention.self.value.weight 0.004562717862427235\n",
            "bert_model.encoder.layer.0.attention.self.value.bias 0.0011358935153111815\n",
            "bert_model.encoder.layer.0.attention.output.dense.weight 0.0041503868997097015\n",
            "bert_model.encoder.layer.0.attention.output.dense.bias 0.0011694009881466627\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.weight 0.0003365623124409467\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.bias 0.0008631128584966063\n",
            "bert_model.encoder.layer.0.intermediate.dense.weight 0.013669738546013832\n",
            "bert_model.encoder.layer.0.intermediate.dense.bias 0.000376789626898244\n",
            "bert_model.encoder.layer.0.output.dense.weight 0.003784515894949436\n",
            "bert_model.encoder.layer.0.output.dense.bias 0.0008215060806833208\n",
            "bert_model.encoder.layer.0.output.LayerNorm.weight 0.0012555503053590655\n",
            "bert_model.encoder.layer.0.output.LayerNorm.bias 0.001674742205068469\n",
            "bert_model.encoder.layer.1.attention.self.query.weight 0.0016870275139808655\n",
            "bert_model.encoder.layer.1.attention.self.query.bias 0.00013970812142360955\n",
            "bert_model.encoder.layer.1.attention.self.key.weight 0.0014251291286200285\n",
            "bert_model.encoder.layer.1.attention.self.key.bias 1.9349589638895104e-11\n",
            "bert_model.encoder.layer.1.attention.self.value.weight 0.007824177853763103\n",
            "bert_model.encoder.layer.1.attention.self.value.bias 0.0010638243984431028\n",
            "bert_model.encoder.layer.1.attention.output.dense.weight 0.007951422594487667\n",
            "bert_model.encoder.layer.1.attention.output.dense.bias 0.0012834524968639016\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.weight 0.0006305522983893752\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.bias 0.0010738978162407875\n",
            "bert_model.encoder.layer.1.intermediate.dense.weight 0.018600672483444214\n",
            "bert_model.encoder.layer.1.intermediate.dense.bias 0.0003756374935619533\n",
            "bert_model.encoder.layer.1.output.dense.weight 0.00765406247228384\n",
            "bert_model.encoder.layer.1.output.dense.bias 0.001081066788174212\n",
            "bert_model.encoder.layer.1.output.LayerNorm.weight 0.001052324427291751\n",
            "bert_model.encoder.layer.1.output.LayerNorm.bias 0.001805360079742968\n",
            "bert_model.encoder.layer.2.attention.self.query.weight 0.0022615576162934303\n",
            "bert_model.encoder.layer.2.attention.self.query.bias 0.00015003113367129117\n",
            "bert_model.encoder.layer.2.attention.self.key.weight 0.0014487258158624172\n",
            "bert_model.encoder.layer.2.attention.self.key.bias 1.569439370130432e-11\n",
            "bert_model.encoder.layer.2.attention.self.value.weight 0.0151135865598917\n",
            "bert_model.encoder.layer.2.attention.self.value.bias 0.0013609473826363683\n",
            "bert_model.encoder.layer.2.attention.output.dense.weight 0.012594632804393768\n",
            "bert_model.encoder.layer.2.attention.output.dense.bias 0.001616750843822956\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.weight 0.0008746806415729225\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.bias 0.0013622308615595102\n",
            "bert_model.encoder.layer.2.intermediate.dense.weight 0.02883324772119522\n",
            "bert_model.encoder.layer.2.intermediate.dense.bias 0.0007128275465220213\n",
            "bert_model.encoder.layer.2.output.dense.weight 0.008219750598073006\n",
            "bert_model.encoder.layer.2.output.dense.bias 0.0013865561923012137\n",
            "bert_model.encoder.layer.2.output.LayerNorm.weight 0.0032147245947271585\n",
            "bert_model.encoder.layer.2.output.LayerNorm.bias 0.0023932852782309055\n",
            "bert_model.encoder.layer.3.attention.self.query.weight 0.0038006198592483997\n",
            "bert_model.encoder.layer.3.attention.self.query.bias 0.0002862847177311778\n",
            "bert_model.encoder.layer.3.attention.self.key.weight 0.0026167212054133415\n",
            "bert_model.encoder.layer.3.attention.self.key.bias 1.8772814899814527e-11\n",
            "bert_model.encoder.layer.3.attention.self.value.weight 0.020603233948349953\n",
            "bert_model.encoder.layer.3.attention.self.value.bias 0.001732576871290803\n",
            "bert_model.encoder.layer.3.attention.output.dense.weight 0.021123092621564865\n",
            "bert_model.encoder.layer.3.attention.output.dense.bias 0.0021074016112834215\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.weight 0.0012753563933074474\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.bias 0.001787153072655201\n",
            "bert_model.encoder.layer.3.intermediate.dense.weight 0.02085120417177677\n",
            "bert_model.encoder.layer.3.intermediate.dense.bias 0.0006461135344579816\n",
            "bert_model.encoder.layer.3.output.dense.weight 0.011595884338021278\n",
            "bert_model.encoder.layer.3.output.dense.bias 0.0017782635986804962\n",
            "bert_model.encoder.layer.3.output.LayerNorm.weight 0.0020712956320494413\n",
            "bert_model.encoder.layer.3.output.LayerNorm.bias 0.0031136376783251762\n",
            "bert_model.encoder.layer.4.attention.self.query.weight 0.004416107665747404\n",
            "bert_model.encoder.layer.4.attention.self.query.bias 0.00026045480626635253\n",
            "bert_model.encoder.layer.4.attention.self.key.weight 0.003686480689793825\n",
            "bert_model.encoder.layer.4.attention.self.key.bias 2.6843510053664588e-11\n",
            "bert_model.encoder.layer.4.attention.self.value.weight 0.022368544712662697\n",
            "bert_model.encoder.layer.4.attention.self.value.bias 0.0021235973108559847\n",
            "bert_model.encoder.layer.4.attention.output.dense.weight 0.014223210513591766\n",
            "bert_model.encoder.layer.4.attention.output.dense.bias 0.002343195490539074\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.weight 0.0014053640188649297\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.bias 0.002055471297353506\n",
            "bert_model.encoder.layer.4.intermediate.dense.weight 0.01849137432873249\n",
            "bert_model.encoder.layer.4.intermediate.dense.bias 0.0005931177292950451\n",
            "bert_model.encoder.layer.4.output.dense.weight 0.011243782937526703\n",
            "bert_model.encoder.layer.4.output.dense.bias 0.0020421165972948074\n",
            "bert_model.encoder.layer.4.output.LayerNorm.weight 0.004510915372520685\n",
            "bert_model.encoder.layer.4.output.LayerNorm.bias 0.003721859771758318\n",
            "bert_model.encoder.layer.5.attention.self.query.weight 0.003967667929828167\n",
            "bert_model.encoder.layer.5.attention.self.query.bias 0.00023484512348659337\n",
            "bert_model.encoder.layer.5.attention.self.key.weight 0.003271743655204773\n",
            "bert_model.encoder.layer.5.attention.self.key.bias 1.4742970733117033e-11\n",
            "bert_model.encoder.layer.5.attention.self.value.weight 0.021461041644215584\n",
            "bert_model.encoder.layer.5.attention.self.value.bias 0.0022637213114649057\n",
            "bert_model.encoder.layer.5.attention.output.dense.weight 0.010307674296200275\n",
            "bert_model.encoder.layer.5.attention.output.dense.bias 0.002667466877028346\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.weight 0.001730186864733696\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.bias 0.002370998030528426\n",
            "bert_model.encoder.layer.5.intermediate.dense.weight 0.020494138821959496\n",
            "bert_model.encoder.layer.5.intermediate.dense.bias 0.0007512875599786639\n",
            "bert_model.encoder.layer.5.output.dense.weight 0.014885454438626766\n",
            "bert_model.encoder.layer.5.output.dense.bias 0.0023392075672745705\n",
            "bert_model.encoder.layer.5.output.LayerNorm.weight 0.00925235915929079\n",
            "bert_model.encoder.layer.5.output.LayerNorm.bias 0.004330585710704327\n",
            "bert_model.encoder.layer.6.attention.self.query.weight 0.009493885561823845\n",
            "bert_model.encoder.layer.6.attention.self.query.bias 0.0004262362199369818\n",
            "bert_model.encoder.layer.6.attention.self.key.weight 0.007803869899362326\n",
            "bert_model.encoder.layer.6.attention.self.key.bias 3.669547304907539e-11\n",
            "bert_model.encoder.layer.6.attention.self.value.weight 0.02936447784304619\n",
            "bert_model.encoder.layer.6.attention.self.value.bias 0.002599852392449975\n",
            "bert_model.encoder.layer.6.attention.output.dense.weight 0.019276026636362076\n",
            "bert_model.encoder.layer.6.attention.output.dense.bias 0.002968926215544343\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.weight 0.0023300836328417063\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.bias 0.0029915159102529287\n",
            "bert_model.encoder.layer.6.intermediate.dense.weight 0.027688894420862198\n",
            "bert_model.encoder.layer.6.intermediate.dense.bias 0.0011397728230804205\n",
            "bert_model.encoder.layer.6.output.dense.weight 0.017609896138310432\n",
            "bert_model.encoder.layer.6.output.dense.bias 0.0028629889711737633\n",
            "bert_model.encoder.layer.6.output.LayerNorm.weight 0.01343674585223198\n",
            "bert_model.encoder.layer.6.output.LayerNorm.bias 0.004700701683759689\n",
            "bert_model.encoder.layer.7.attention.self.query.weight 0.005774712655693293\n",
            "bert_model.encoder.layer.7.attention.self.query.bias 0.0004271842772141099\n",
            "bert_model.encoder.layer.7.attention.self.key.weight 0.004844636656343937\n",
            "bert_model.encoder.layer.7.attention.self.key.bias 3.11293386900946e-11\n",
            "bert_model.encoder.layer.7.attention.self.value.weight 0.035558730363845825\n",
            "bert_model.encoder.layer.7.attention.self.value.bias 0.002694695023819804\n",
            "bert_model.encoder.layer.7.attention.output.dense.weight 0.027957620099186897\n",
            "bert_model.encoder.layer.7.attention.output.dense.bias 0.0034252589102834463\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.weight 0.002888799412176013\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.bias 0.0034265867434442043\n",
            "bert_model.encoder.layer.7.intermediate.dense.weight 0.0505998320877552\n",
            "bert_model.encoder.layer.7.intermediate.dense.bias 0.0013811560347676277\n",
            "bert_model.encoder.layer.7.output.dense.weight 0.022366318851709366\n",
            "bert_model.encoder.layer.7.output.dense.bias 0.0031272899359464645\n",
            "bert_model.encoder.layer.7.output.LayerNorm.weight 0.006494829431176186\n",
            "bert_model.encoder.layer.7.output.LayerNorm.bias 0.005557679571211338\n",
            "bert_model.encoder.layer.8.attention.self.query.weight 0.009230042807757854\n",
            "bert_model.encoder.layer.8.attention.self.query.bias 0.00041818400495685637\n",
            "bert_model.encoder.layer.8.attention.self.key.weight 0.007186738308519125\n",
            "bert_model.encoder.layer.8.attention.self.key.bias 3.612963747623432e-11\n",
            "bert_model.encoder.layer.8.attention.self.value.weight 0.042762722820043564\n",
            "bert_model.encoder.layer.8.attention.self.value.bias 0.0038888168055564165\n",
            "bert_model.encoder.layer.8.attention.output.dense.weight 0.031413622200489044\n",
            "bert_model.encoder.layer.8.attention.output.dense.bias 0.004333606455475092\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.weight 0.003494999138638377\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.bias 0.0040041557513177395\n",
            "bert_model.encoder.layer.8.intermediate.dense.weight 0.06175147369503975\n",
            "bert_model.encoder.layer.8.intermediate.dense.bias 0.0018492675153538585\n",
            "bert_model.encoder.layer.8.output.dense.weight 0.029531041160225868\n",
            "bert_model.encoder.layer.8.output.dense.bias 0.003776855766773224\n",
            "bert_model.encoder.layer.8.output.LayerNorm.weight 0.004513092804700136\n",
            "bert_model.encoder.layer.8.output.LayerNorm.bias 0.006616620812565088\n",
            "bert_model.encoder.layer.9.attention.self.query.weight 0.021872300654649734\n",
            "bert_model.encoder.layer.9.attention.self.query.bias 0.0007021106430329382\n",
            "bert_model.encoder.layer.9.attention.self.key.weight 0.01624949648976326\n",
            "bert_model.encoder.layer.9.attention.self.key.bias 7.105946386865014e-11\n",
            "bert_model.encoder.layer.9.attention.self.value.weight 0.04977467656135559\n",
            "bert_model.encoder.layer.9.attention.self.value.bias 0.00436876155436039\n",
            "bert_model.encoder.layer.9.attention.output.dense.weight 0.04068184271454811\n",
            "bert_model.encoder.layer.9.attention.output.dense.bias 0.004326522815972567\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.weight 0.005966978147625923\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.bias 0.005083502735942602\n",
            "bert_model.encoder.layer.9.intermediate.dense.weight 0.08804665505886078\n",
            "bert_model.encoder.layer.9.intermediate.dense.bias 0.0039222026243805885\n",
            "bert_model.encoder.layer.9.output.dense.weight 0.041341595351696014\n",
            "bert_model.encoder.layer.9.output.dense.bias 0.005614705849438906\n",
            "bert_model.encoder.layer.9.output.LayerNorm.weight 0.013508406467735767\n",
            "bert_model.encoder.layer.9.output.LayerNorm.bias 0.0075624254532158375\n",
            "bert_model.encoder.layer.10.attention.self.query.weight 0.02179788425564766\n",
            "bert_model.encoder.layer.10.attention.self.query.bias 0.0009334376663900912\n",
            "bert_model.encoder.layer.10.attention.self.key.weight 0.019851671531796455\n",
            "bert_model.encoder.layer.10.attention.self.key.bias 9.837104741894365e-11\n",
            "bert_model.encoder.layer.10.attention.self.value.weight 0.08910798281431198\n",
            "bert_model.encoder.layer.10.attention.self.value.bias 0.006328152026981115\n",
            "bert_model.encoder.layer.10.attention.output.dense.weight 0.06649399548768997\n",
            "bert_model.encoder.layer.10.attention.output.dense.bias 0.005639008246362209\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.weight 0.014168964698910713\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.bias 0.007367574144154787\n",
            "bert_model.encoder.layer.10.intermediate.dense.weight 0.11273929476737976\n",
            "bert_model.encoder.layer.10.intermediate.dense.bias 0.0048994277603924274\n",
            "bert_model.encoder.layer.10.output.dense.weight 0.04817257821559906\n",
            "bert_model.encoder.layer.10.output.dense.bias 0.005736216902732849\n",
            "bert_model.encoder.layer.10.output.LayerNorm.weight 0.011063887737691402\n",
            "bert_model.encoder.layer.10.output.LayerNorm.bias 0.010223498567938805\n",
            "bert_model.encoder.layer.11.attention.self.query.weight 0.057325173169374466\n",
            "bert_model.encoder.layer.11.attention.self.query.bias 0.0024616362061351538\n",
            "bert_model.encoder.layer.11.attention.self.key.weight 0.05241841450333595\n",
            "bert_model.encoder.layer.11.attention.self.key.bias 2.0260604305377683e-10\n",
            "bert_model.encoder.layer.11.attention.self.value.weight 0.12433308362960815\n",
            "bert_model.encoder.layer.11.attention.self.value.bias 0.007772443350404501\n",
            "bert_model.encoder.layer.11.attention.output.dense.weight 0.07273028045892715\n",
            "bert_model.encoder.layer.11.attention.output.dense.bias 0.004312493838369846\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.weight 0.005589136853814125\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.bias 0.0070188469253480434\n",
            "bert_model.encoder.layer.11.intermediate.dense.weight 0.12413506209850311\n",
            "bert_model.encoder.layer.11.intermediate.dense.bias 0.003876890055835247\n",
            "bert_model.encoder.layer.11.output.dense.weight 0.1403890699148178\n",
            "bert_model.encoder.layer.11.output.dense.bias 0.005742526147514582\n",
            "bert_model.encoder.layer.11.output.LayerNorm.weight 0.018659930676221848\n",
            "bert_model.encoder.layer.11.output.LayerNorm.bias 0.03614585101604462\n",
            "bert_model.pooler.dense.weight 0.41441717743873596\n",
            "bert_model.pooler.dense.bias 0.03063858672976494\n",
            "linear.weight 1.3373403549194336\n",
            "linear.bias 0.07509228587150574\n",
            "\n",
            "  training loss: 0.02\n",
            "  Training epcoh took: 0:00:11\n",
            "  Batch   120  of  1,189.    Elapsed: 0:00:13.\n",
            "bert_model.embeddings.word_embeddings.weight 0.00041861023055389524\n",
            "bert_model.embeddings.position_embeddings.weight 0.00029495407943613827\n",
            "bert_model.embeddings.token_type_embeddings.weight 0.0021717888303101063\n",
            "bert_model.embeddings.LayerNorm.weight 3.6758654459845275e-05\n",
            "bert_model.embeddings.LayerNorm.bias 0.00013449543621391058\n",
            "bert_model.encoder.layer.0.attention.self.query.weight 5.850089291925542e-05\n",
            "bert_model.encoder.layer.0.attention.self.query.bias 6.1480136537284125e-06\n",
            "bert_model.encoder.layer.0.attention.self.key.weight 6.223550735739991e-05\n",
            "bert_model.encoder.layer.0.attention.self.key.bias 5.161299447727086e-13\n",
            "bert_model.encoder.layer.0.attention.self.value.weight 0.0002675406576599926\n",
            "bert_model.encoder.layer.0.attention.self.value.bias 7.587718573631719e-05\n",
            "bert_model.encoder.layer.0.attention.output.dense.weight 0.0003742473491001874\n",
            "bert_model.encoder.layer.0.attention.output.dense.bias 0.00010312047379557043\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.weight 2.6388393962406553e-05\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.bias 7.780947635183111e-05\n",
            "bert_model.encoder.layer.0.intermediate.dense.weight 0.0005288638640195131\n",
            "bert_model.encoder.layer.0.intermediate.dense.bias 2.368038985878229e-05\n",
            "bert_model.encoder.layer.0.output.dense.weight 0.00036452573840506375\n",
            "bert_model.encoder.layer.0.output.dense.bias 7.778516010148451e-05\n",
            "bert_model.encoder.layer.0.output.LayerNorm.weight 0.00014488058513961732\n",
            "bert_model.encoder.layer.0.output.LayerNorm.bias 0.00014405170804820955\n",
            "bert_model.encoder.layer.1.attention.self.query.weight 9.472898091189563e-05\n",
            "bert_model.encoder.layer.1.attention.self.query.bias 1.1086745871580206e-05\n",
            "bert_model.encoder.layer.1.attention.self.key.weight 0.00010626845323713496\n",
            "bert_model.encoder.layer.1.attention.self.key.bias 1.322139771796349e-12\n",
            "bert_model.encoder.layer.1.attention.self.value.weight 0.0009453457896597683\n",
            "bert_model.encoder.layer.1.attention.self.value.bias 0.00011779813939938322\n",
            "bert_model.encoder.layer.1.attention.output.dense.weight 0.0011096525704488158\n",
            "bert_model.encoder.layer.1.attention.output.dense.bias 0.00012599906767718494\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.weight 7.00782984495163e-05\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.bias 0.00012962725304532796\n",
            "bert_model.encoder.layer.1.intermediate.dense.weight 0.0016456773737445474\n",
            "bert_model.encoder.layer.1.intermediate.dense.bias 5.7009914598893374e-05\n",
            "bert_model.encoder.layer.1.output.dense.weight 0.0011156531982123852\n",
            "bert_model.encoder.layer.1.output.dense.bias 0.00013252666394691914\n",
            "bert_model.encoder.layer.1.output.LayerNorm.weight 0.00014115126396063715\n",
            "bert_model.encoder.layer.1.output.LayerNorm.bias 0.00022011349210515618\n",
            "bert_model.encoder.layer.2.attention.self.query.weight 0.00010254412336507812\n",
            "bert_model.encoder.layer.2.attention.self.query.bias 7.5079956332047004e-06\n",
            "bert_model.encoder.layer.2.attention.self.key.weight 9.82122728601098e-05\n",
            "bert_model.encoder.layer.2.attention.self.key.bias 8.200514377797175e-13\n",
            "bert_model.encoder.layer.2.attention.self.value.weight 0.002062998479232192\n",
            "bert_model.encoder.layer.2.attention.self.value.bias 0.00015165205695666373\n",
            "bert_model.encoder.layer.2.attention.output.dense.weight 0.002097498392686248\n",
            "bert_model.encoder.layer.2.attention.output.dense.bias 0.0001760983286658302\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.weight 0.00012988087837584317\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.bias 0.00018324470147490501\n",
            "bert_model.encoder.layer.2.intermediate.dense.weight 0.002401916543021798\n",
            "bert_model.encoder.layer.2.intermediate.dense.bias 7.948456186568365e-05\n",
            "bert_model.encoder.layer.2.output.dense.weight 0.001461197854951024\n",
            "bert_model.encoder.layer.2.output.dense.bias 0.00016647639859002084\n",
            "bert_model.encoder.layer.2.output.LayerNorm.weight 0.000273342477157712\n",
            "bert_model.encoder.layer.2.output.LayerNorm.bias 0.00028406374622136354\n",
            "bert_model.encoder.layer.3.attention.self.query.weight 0.0001345959462923929\n",
            "bert_model.encoder.layer.3.attention.self.query.bias 8.705153959454037e-06\n",
            "bert_model.encoder.layer.3.attention.self.key.weight 0.00011101186828454956\n",
            "bert_model.encoder.layer.3.attention.self.key.bias 1.331343347198144e-12\n",
            "bert_model.encoder.layer.3.attention.self.value.weight 0.003680304391309619\n",
            "bert_model.encoder.layer.3.attention.self.value.bias 0.00022981375514063984\n",
            "bert_model.encoder.layer.3.attention.output.dense.weight 0.00433893408626318\n",
            "bert_model.encoder.layer.3.attention.output.dense.bias 0.0002530525962356478\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.weight 0.0002907490124925971\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.bias 0.00032585361623205245\n",
            "bert_model.encoder.layer.3.intermediate.dense.weight 0.004656486678868532\n",
            "bert_model.encoder.layer.3.intermediate.dense.bias 0.00018102879403159022\n",
            "bert_model.encoder.layer.3.output.dense.weight 0.003192218253389001\n",
            "bert_model.encoder.layer.3.output.dense.bias 0.00027531254454515874\n",
            "bert_model.encoder.layer.3.output.LayerNorm.weight 0.0004308163479436189\n",
            "bert_model.encoder.layer.3.output.LayerNorm.bias 0.0005016080685891211\n",
            "bert_model.encoder.layer.4.attention.self.query.weight 0.0007518046768382192\n",
            "bert_model.encoder.layer.4.attention.self.query.bias 3.773821299546398e-05\n",
            "bert_model.encoder.layer.4.attention.self.key.weight 0.0005161896115168929\n",
            "bert_model.encoder.layer.4.attention.self.key.bias 2.668587789980692e-12\n",
            "bert_model.encoder.layer.4.attention.self.value.weight 0.005380912218242884\n",
            "bert_model.encoder.layer.4.attention.self.value.bias 0.0003284469130448997\n",
            "bert_model.encoder.layer.4.attention.output.dense.weight 0.005806214176118374\n",
            "bert_model.encoder.layer.4.attention.output.dense.bias 0.0003205443499609828\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.weight 0.000456597947049886\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.bias 0.00048615934792906046\n",
            "bert_model.encoder.layer.4.intermediate.dense.weight 0.0069880615919828415\n",
            "bert_model.encoder.layer.4.intermediate.dense.bias 0.00029110023751854897\n",
            "bert_model.encoder.layer.4.output.dense.weight 0.004740421194583178\n",
            "bert_model.encoder.layer.4.output.dense.bias 0.0004011398123111576\n",
            "bert_model.encoder.layer.4.output.LayerNorm.weight 0.0005324206431396306\n",
            "bert_model.encoder.layer.4.output.LayerNorm.bias 0.0006026177434250712\n",
            "bert_model.encoder.layer.5.attention.self.query.weight 0.0004094218311365694\n",
            "bert_model.encoder.layer.5.attention.self.query.bias 1.967858952411916e-05\n",
            "bert_model.encoder.layer.5.attention.self.key.weight 0.0003482833271846175\n",
            "bert_model.encoder.layer.5.attention.self.key.bias 1.9329579169918842e-12\n",
            "bert_model.encoder.layer.5.attention.self.value.weight 0.0067878225818276405\n",
            "bert_model.encoder.layer.5.attention.self.value.bias 0.00035906414268538356\n",
            "bert_model.encoder.layer.5.attention.output.dense.weight 0.0072741424664855\n",
            "bert_model.encoder.layer.5.attention.output.dense.bias 0.00039235877920873463\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.weight 0.0005722680944018066\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.bias 0.0006177137838676572\n",
            "bert_model.encoder.layer.5.intermediate.dense.weight 0.009068742394447327\n",
            "bert_model.encoder.layer.5.intermediate.dense.bias 0.0003870249493047595\n",
            "bert_model.encoder.layer.5.output.dense.weight 0.006256250198930502\n",
            "bert_model.encoder.layer.5.output.dense.bias 0.0005009170854464173\n",
            "bert_model.encoder.layer.5.output.LayerNorm.weight 0.0007487882976420224\n",
            "bert_model.encoder.layer.5.output.LayerNorm.bias 0.0007970449514687061\n",
            "bert_model.encoder.layer.6.attention.self.query.weight 0.00038961233804002404\n",
            "bert_model.encoder.layer.6.attention.self.query.bias 1.8702457964536734e-05\n",
            "bert_model.encoder.layer.6.attention.self.key.weight 0.0003670914738904685\n",
            "bert_model.encoder.layer.6.attention.self.key.bias 2.2505578130271875e-12\n",
            "bert_model.encoder.layer.6.attention.self.value.weight 0.010352293960750103\n",
            "bert_model.encoder.layer.6.attention.self.value.bias 0.0005036258371546865\n",
            "bert_model.encoder.layer.6.attention.output.dense.weight 0.01188837643712759\n",
            "bert_model.encoder.layer.6.attention.output.dense.bias 0.0005567641346715391\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.weight 0.0009195407037623227\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.bias 0.000968744745478034\n",
            "bert_model.encoder.layer.6.intermediate.dense.weight 0.014024460688233376\n",
            "bert_model.encoder.layer.6.intermediate.dense.bias 0.0005960045382380486\n",
            "bert_model.encoder.layer.6.output.dense.weight 0.009640177711844444\n",
            "bert_model.encoder.layer.6.output.dense.bias 0.0007782750762999058\n",
            "bert_model.encoder.layer.6.output.LayerNorm.weight 0.0011148335179314017\n",
            "bert_model.encoder.layer.6.output.LayerNorm.bias 0.0012242159573361278\n",
            "bert_model.encoder.layer.7.attention.self.query.weight 0.0003975878353230655\n",
            "bert_model.encoder.layer.7.attention.self.query.bias 2.1094096155138686e-05\n",
            "bert_model.encoder.layer.7.attention.self.key.weight 0.00036870106123387814\n",
            "bert_model.encoder.layer.7.attention.self.key.bias 2.689033891389858e-12\n",
            "bert_model.encoder.layer.7.attention.self.value.weight 0.015393511392176151\n",
            "bert_model.encoder.layer.7.attention.self.value.bias 0.0007380724418908358\n",
            "bert_model.encoder.layer.7.attention.output.dense.weight 0.017445549368858337\n",
            "bert_model.encoder.layer.7.attention.output.dense.bias 0.0008214189438149333\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.weight 0.0014357765903696418\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.bias 0.0014629402430728078\n",
            "bert_model.encoder.layer.7.intermediate.dense.weight 0.020572984591126442\n",
            "bert_model.encoder.layer.7.intermediate.dense.bias 0.0008603849564678967\n",
            "bert_model.encoder.layer.7.output.dense.weight 0.01687438227236271\n",
            "bert_model.encoder.layer.7.output.dense.bias 0.001020675408653915\n",
            "bert_model.encoder.layer.7.output.LayerNorm.weight 0.0016965047689154744\n",
            "bert_model.encoder.layer.7.output.LayerNorm.bias 0.001705569215118885\n",
            "bert_model.encoder.layer.8.attention.self.query.weight 0.0004031193966511637\n",
            "bert_model.encoder.layer.8.attention.self.query.bias 2.016019425354898e-05\n",
            "bert_model.encoder.layer.8.attention.self.key.weight 0.00035789154935628176\n",
            "bert_model.encoder.layer.8.attention.self.key.bias 1.0547473484889824e-11\n",
            "bert_model.encoder.layer.8.attention.self.value.weight 0.02422652393579483\n",
            "bert_model.encoder.layer.8.attention.self.value.bias 0.0011893189512193203\n",
            "bert_model.encoder.layer.8.attention.output.dense.weight 0.030002014711499214\n",
            "bert_model.encoder.layer.8.attention.output.dense.bias 0.0012961585307493806\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.weight 0.002186400815844536\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.bias 0.002079917583614588\n",
            "bert_model.encoder.layer.8.intermediate.dense.weight 0.030126890167593956\n",
            "bert_model.encoder.layer.8.intermediate.dense.bias 0.00121509307064116\n",
            "bert_model.encoder.layer.8.output.dense.weight 0.018907368183135986\n",
            "bert_model.encoder.layer.8.output.dense.bias 0.0016767007764428854\n",
            "bert_model.encoder.layer.8.output.LayerNorm.weight 0.002266464987769723\n",
            "bert_model.encoder.layer.8.output.LayerNorm.bias 0.0023536572698503733\n",
            "bert_model.encoder.layer.9.attention.self.query.weight 0.0001858871546573937\n",
            "bert_model.encoder.layer.9.attention.self.query.bias 8.737025382288266e-06\n",
            "bert_model.encoder.layer.9.attention.self.key.weight 0.00020889365987386554\n",
            "bert_model.encoder.layer.9.attention.self.key.bias 6.933176255330409e-12\n",
            "bert_model.encoder.layer.9.attention.self.value.weight 0.028854019939899445\n",
            "bert_model.encoder.layer.9.attention.self.value.bias 0.0013946049148216844\n",
            "bert_model.encoder.layer.9.attention.output.dense.weight 0.029777858406305313\n",
            "bert_model.encoder.layer.9.attention.output.dense.bias 0.0014396043261513114\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.weight 0.00453406386077404\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.bias 0.0024734598118811846\n",
            "bert_model.encoder.layer.9.intermediate.dense.weight 0.025199590250849724\n",
            "bert_model.encoder.layer.9.intermediate.dense.bias 0.0010554550681263208\n",
            "bert_model.encoder.layer.9.output.dense.weight 0.018892377614974976\n",
            "bert_model.encoder.layer.9.output.dense.bias 0.002197920810431242\n",
            "bert_model.encoder.layer.9.output.LayerNorm.weight 0.00418945774435997\n",
            "bert_model.encoder.layer.9.output.LayerNorm.bias 0.003174721961840987\n",
            "bert_model.encoder.layer.10.attention.self.query.weight 0.00017452044994570315\n",
            "bert_model.encoder.layer.10.attention.self.query.bias 8.10592155175982e-06\n",
            "bert_model.encoder.layer.10.attention.self.key.weight 0.00022287727915681899\n",
            "bert_model.encoder.layer.10.attention.self.key.bias 1.7599336918361352e-11\n",
            "bert_model.encoder.layer.10.attention.self.value.weight 0.05191916972398758\n",
            "bert_model.encoder.layer.10.attention.self.value.bias 0.002431301400065422\n",
            "bert_model.encoder.layer.10.attention.output.dense.weight 0.04672633856534958\n",
            "bert_model.encoder.layer.10.attention.output.dense.bias 0.0020228088833391666\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.weight 0.010063916444778442\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.bias 0.004199028480798006\n",
            "bert_model.encoder.layer.10.intermediate.dense.weight 0.04693589732050896\n",
            "bert_model.encoder.layer.10.intermediate.dense.bias 0.0020167611073702574\n",
            "bert_model.encoder.layer.10.output.dense.weight 0.028575796633958817\n",
            "bert_model.encoder.layer.10.output.dense.bias 0.0035061542876064777\n",
            "bert_model.encoder.layer.10.output.LayerNorm.weight 0.00603247806429863\n",
            "bert_model.encoder.layer.10.output.LayerNorm.bias 0.005058212671428919\n",
            "bert_model.encoder.layer.11.attention.self.query.weight 0.0008977847755886614\n",
            "bert_model.encoder.layer.11.attention.self.query.bias 3.8053211028454825e-05\n",
            "bert_model.encoder.layer.11.attention.self.key.weight 0.0014158559497445822\n",
            "bert_model.encoder.layer.11.attention.self.key.bias 1.2506348734397932e-10\n",
            "bert_model.encoder.layer.11.attention.self.value.weight 0.08257266879081726\n",
            "bert_model.encoder.layer.11.attention.self.value.bias 0.003625673707574606\n",
            "bert_model.encoder.layer.11.attention.output.dense.weight 0.06926257163286209\n",
            "bert_model.encoder.layer.11.attention.output.dense.bias 0.002407307270914316\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.weight 0.005625896621495485\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.bias 0.005895028822124004\n",
            "bert_model.encoder.layer.11.intermediate.dense.weight 0.06864803284406662\n",
            "bert_model.encoder.layer.11.intermediate.dense.bias 0.002459063660353422\n",
            "bert_model.encoder.layer.11.output.dense.weight 0.04794568195939064\n",
            "bert_model.encoder.layer.11.output.dense.bias 0.0034649972803890705\n",
            "bert_model.encoder.layer.11.output.LayerNorm.weight 0.009084772318601608\n",
            "bert_model.encoder.layer.11.output.LayerNorm.bias 0.010965650901198387\n",
            "bert_model.pooler.dense.weight 0.14506201446056366\n",
            "bert_model.pooler.dense.bias 0.009726750664412975\n",
            "linear.weight 0.96641606092453\n",
            "linear.bias 0.041093531996011734\n",
            "\n",
            "  training loss: 0.03\n",
            "  Training epcoh took: 0:00:15\n",
            "  Batch   160  of  1,189.    Elapsed: 0:00:17.\n",
            "bert_model.embeddings.word_embeddings.weight 0.00033848019666038454\n",
            "bert_model.embeddings.position_embeddings.weight 0.00025574705796316266\n",
            "bert_model.embeddings.token_type_embeddings.weight 0.002484515542164445\n",
            "bert_model.embeddings.LayerNorm.weight 4.526257180259563e-05\n",
            "bert_model.embeddings.LayerNorm.bias 0.0001528349530417472\n",
            "bert_model.encoder.layer.0.attention.self.query.weight 6.678843055851758e-05\n",
            "bert_model.encoder.layer.0.attention.self.query.bias 7.554415333288489e-06\n",
            "bert_model.encoder.layer.0.attention.self.key.weight 6.6317108576186e-05\n",
            "bert_model.encoder.layer.0.attention.self.key.bias 5.374843907619831e-13\n",
            "bert_model.encoder.layer.0.attention.self.value.weight 0.00032143958378583193\n",
            "bert_model.encoder.layer.0.attention.self.value.bias 9.129356476478279e-05\n",
            "bert_model.encoder.layer.0.attention.output.dense.weight 0.0004559944791253656\n",
            "bert_model.encoder.layer.0.attention.output.dense.bias 0.00011328201799187809\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.weight 3.215440301573835e-05\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.bias 8.815546607365832e-05\n",
            "bert_model.encoder.layer.0.intermediate.dense.weight 0.0007800062885507941\n",
            "bert_model.encoder.layer.0.intermediate.dense.bias 3.774851211346686e-05\n",
            "bert_model.encoder.layer.0.output.dense.weight 0.0004545748233795166\n",
            "bert_model.encoder.layer.0.output.dense.bias 9.125865472014993e-05\n",
            "bert_model.encoder.layer.0.output.LayerNorm.weight 0.0001036964968079701\n",
            "bert_model.encoder.layer.0.output.LayerNorm.bias 0.00016970469732768834\n",
            "bert_model.encoder.layer.1.attention.self.query.weight 0.00012641829380299896\n",
            "bert_model.encoder.layer.1.attention.self.query.bias 1.3686804777535144e-05\n",
            "bert_model.encoder.layer.1.attention.self.key.weight 0.0001238959957845509\n",
            "bert_model.encoder.layer.1.attention.self.key.bias 1.2266949608874533e-12\n",
            "bert_model.encoder.layer.1.attention.self.value.weight 0.0010825489880517125\n",
            "bert_model.encoder.layer.1.attention.self.value.bias 0.0001191374976770021\n",
            "bert_model.encoder.layer.1.attention.output.dense.weight 0.0014297865564003587\n",
            "bert_model.encoder.layer.1.attention.output.dense.bias 0.00013216296792961657\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.weight 0.0001018374168779701\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.bias 0.00014963025751058012\n",
            "bert_model.encoder.layer.1.intermediate.dense.weight 0.0020986427552998066\n",
            "bert_model.encoder.layer.1.intermediate.dense.bias 6.7042165028397e-05\n",
            "bert_model.encoder.layer.1.output.dense.weight 0.001500345184467733\n",
            "bert_model.encoder.layer.1.output.dense.bias 0.00014646138879470527\n",
            "bert_model.encoder.layer.1.output.LayerNorm.weight 0.0003403539303690195\n",
            "bert_model.encoder.layer.1.output.LayerNorm.bias 0.0002693339192774147\n",
            "bert_model.encoder.layer.2.attention.self.query.weight 7.546745473518968e-05\n",
            "bert_model.encoder.layer.2.attention.self.query.bias 5.083044470666209e-06\n",
            "bert_model.encoder.layer.2.attention.self.key.weight 7.59815375204198e-05\n",
            "bert_model.encoder.layer.2.attention.self.key.bias 9.225299560725042e-13\n",
            "bert_model.encoder.layer.2.attention.self.value.weight 0.00291919126175344\n",
            "bert_model.encoder.layer.2.attention.self.value.bias 0.0001940320507856086\n",
            "bert_model.encoder.layer.2.attention.output.dense.weight 0.003221626626327634\n",
            "bert_model.encoder.layer.2.attention.output.dense.bias 0.00021442152501549572\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.weight 0.00023771241831127554\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.bias 0.00026311780675314367\n",
            "bert_model.encoder.layer.2.intermediate.dense.weight 0.004912724252790213\n",
            "bert_model.encoder.layer.2.intermediate.dense.bias 0.000163378645083867\n",
            "bert_model.encoder.layer.2.output.dense.weight 0.002627661684527993\n",
            "bert_model.encoder.layer.2.output.dense.bias 0.00021609249233733863\n",
            "bert_model.encoder.layer.2.output.LayerNorm.weight 0.0004261618887539953\n",
            "bert_model.encoder.layer.2.output.LayerNorm.bias 0.0004032405267935246\n",
            "bert_model.encoder.layer.3.attention.self.query.weight 0.00010124679101863876\n",
            "bert_model.encoder.layer.3.attention.self.query.bias 5.582608082477236e-06\n",
            "bert_model.encoder.layer.3.attention.self.key.weight 8.51260992931202e-05\n",
            "bert_model.encoder.layer.3.attention.self.key.bias 1.7297006925723335e-12\n",
            "bert_model.encoder.layer.3.attention.self.value.weight 0.0055838581174612045\n",
            "bert_model.encoder.layer.3.attention.self.value.bias 0.00030500692082569003\n",
            "bert_model.encoder.layer.3.attention.output.dense.weight 0.006795446388423443\n",
            "bert_model.encoder.layer.3.attention.output.dense.bias 0.0003018180141225457\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.weight 0.0005370851722545922\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.bias 0.0005079508409835398\n",
            "bert_model.encoder.layer.3.intermediate.dense.weight 0.008850451558828354\n",
            "bert_model.encoder.layer.3.intermediate.dense.bias 0.00035573760396800935\n",
            "bert_model.encoder.layer.3.output.dense.weight 0.0062363604083657265\n",
            "bert_model.encoder.layer.3.output.dense.bias 0.00039447209564968944\n",
            "bert_model.encoder.layer.3.output.LayerNorm.weight 0.0008778304327279329\n",
            "bert_model.encoder.layer.3.output.LayerNorm.bias 0.0007524053216911852\n",
            "bert_model.encoder.layer.4.attention.self.query.weight 0.0001364883064525202\n",
            "bert_model.encoder.layer.4.attention.self.query.bias 6.704607585561462e-06\n",
            "bert_model.encoder.layer.4.attention.self.key.weight 0.00010487771214684471\n",
            "bert_model.encoder.layer.4.attention.self.key.bias 1.5052925269112838e-12\n",
            "bert_model.encoder.layer.4.attention.self.value.weight 0.009822197258472443\n",
            "bert_model.encoder.layer.4.attention.self.value.bias 0.0004818059678655118\n",
            "bert_model.encoder.layer.4.attention.output.dense.weight 0.011234991252422333\n",
            "bert_model.encoder.layer.4.attention.output.dense.bias 0.0004664874286390841\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.weight 0.0007602448458783329\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.bias 0.0008058241219259799\n",
            "bert_model.encoder.layer.4.intermediate.dense.weight 0.0118737006559968\n",
            "bert_model.encoder.layer.4.intermediate.dense.bias 0.00048745423555374146\n",
            "bert_model.encoder.layer.4.output.dense.weight 0.0073729343712329865\n",
            "bert_model.encoder.layer.4.output.dense.bias 0.0006657242774963379\n",
            "bert_model.encoder.layer.4.output.LayerNorm.weight 0.0010330952936783433\n",
            "bert_model.encoder.layer.4.output.LayerNorm.bias 0.0010208707535639405\n",
            "bert_model.encoder.layer.5.attention.self.query.weight 6.210344145074487e-05\n",
            "bert_model.encoder.layer.5.attention.self.query.bias 2.815687366819475e-06\n",
            "bert_model.encoder.layer.5.attention.self.key.weight 6.369139737216756e-05\n",
            "bert_model.encoder.layer.5.attention.self.key.bias 1.7658677254825395e-12\n",
            "bert_model.encoder.layer.5.attention.self.value.weight 0.013254616409540176\n",
            "bert_model.encoder.layer.5.attention.self.value.bias 0.0006012502708472311\n",
            "bert_model.encoder.layer.5.attention.output.dense.weight 0.013750405050814152\n",
            "bert_model.encoder.layer.5.attention.output.dense.bias 0.0005809409776702523\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.weight 0.0011088555911555886\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.bias 0.001102723996154964\n",
            "bert_model.encoder.layer.5.intermediate.dense.weight 0.01617337577044964\n",
            "bert_model.encoder.layer.5.intermediate.dense.bias 0.0007045074016787112\n",
            "bert_model.encoder.layer.5.output.dense.weight 0.013064640574157238\n",
            "bert_model.encoder.layer.5.output.dense.bias 0.0006299523520283401\n",
            "bert_model.encoder.layer.5.output.LayerNorm.weight 0.0012009767815470695\n",
            "bert_model.encoder.layer.5.output.LayerNorm.bias 0.0012318193912506104\n",
            "bert_model.encoder.layer.6.attention.self.query.weight 0.00011957823880948126\n",
            "bert_model.encoder.layer.6.attention.self.query.bias 5.496373432833934e-06\n",
            "bert_model.encoder.layer.6.attention.self.key.weight 0.00013556142221204937\n",
            "bert_model.encoder.layer.6.attention.self.key.bias 3.5524675649073467e-12\n",
            "bert_model.encoder.layer.6.attention.self.value.weight 0.016961686313152313\n",
            "bert_model.encoder.layer.6.attention.self.value.bias 0.0007800925523042679\n",
            "bert_model.encoder.layer.6.attention.output.dense.weight 0.023338081315159798\n",
            "bert_model.encoder.layer.6.attention.output.dense.bias 0.0008194118272513151\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.weight 0.0014818876516073942\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.bias 0.0016561065567657351\n",
            "bert_model.encoder.layer.6.intermediate.dense.weight 0.02351456880569458\n",
            "bert_model.encoder.layer.6.intermediate.dense.bias 0.0010295131942257285\n",
            "bert_model.encoder.layer.6.output.dense.weight 0.018922900781035423\n",
            "bert_model.encoder.layer.6.output.dense.bias 0.0011606791522353888\n",
            "bert_model.encoder.layer.6.output.LayerNorm.weight 0.0016532223671674728\n",
            "bert_model.encoder.layer.6.output.LayerNorm.bias 0.0017483743140473962\n",
            "bert_model.encoder.layer.7.attention.self.query.weight 0.0001116466082748957\n",
            "bert_model.encoder.layer.7.attention.self.query.bias 5.2313280320959166e-06\n",
            "bert_model.encoder.layer.7.attention.self.key.weight 0.00013906419917475432\n",
            "bert_model.encoder.layer.7.attention.self.key.bias 4.780089952333144e-12\n",
            "bert_model.encoder.layer.7.attention.self.value.weight 0.02163877710700035\n",
            "bert_model.encoder.layer.7.attention.self.value.bias 0.0010155616328120232\n",
            "bert_model.encoder.layer.7.attention.output.dense.weight 0.028050720691680908\n",
            "bert_model.encoder.layer.7.attention.output.dense.bias 0.0011795397149398923\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.weight 0.002099616453051567\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.bias 0.0022579014766961336\n",
            "bert_model.encoder.layer.7.intermediate.dense.weight 0.03441707789897919\n",
            "bert_model.encoder.layer.7.intermediate.dense.bias 0.0014906233409419656\n",
            "bert_model.encoder.layer.7.output.dense.weight 0.02575738914310932\n",
            "bert_model.encoder.layer.7.output.dense.bias 0.0016346669290214777\n",
            "bert_model.encoder.layer.7.output.LayerNorm.weight 0.0024260557256639004\n",
            "bert_model.encoder.layer.7.output.LayerNorm.bias 0.002521165180951357\n",
            "bert_model.encoder.layer.8.attention.self.query.weight 0.00018127102521248162\n",
            "bert_model.encoder.layer.8.attention.self.query.bias 8.599416105425917e-06\n",
            "bert_model.encoder.layer.8.attention.self.key.weight 0.00023182011500466615\n",
            "bert_model.encoder.layer.8.attention.self.key.bias 7.309663291321655e-12\n",
            "bert_model.encoder.layer.8.attention.self.value.weight 0.033822644501924515\n",
            "bert_model.encoder.layer.8.attention.self.value.bias 0.001608776394277811\n",
            "bert_model.encoder.layer.8.attention.output.dense.weight 0.04800194501876831\n",
            "bert_model.encoder.layer.8.attention.output.dense.bias 0.0018352781189605594\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.weight 0.003066380973905325\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.bias 0.003329999977722764\n",
            "bert_model.encoder.layer.8.intermediate.dense.weight 0.041847847402095795\n",
            "bert_model.encoder.layer.8.intermediate.dense.bias 0.0017798523185774684\n",
            "bert_model.encoder.layer.8.output.dense.weight 0.04398271068930626\n",
            "bert_model.encoder.layer.8.output.dense.bias 0.0027180842589586973\n",
            "bert_model.encoder.layer.8.output.LayerNorm.weight 0.003636741079390049\n",
            "bert_model.encoder.layer.8.output.LayerNorm.bias 0.003981672693043947\n",
            "bert_model.encoder.layer.9.attention.self.query.weight 0.0003060879244003445\n",
            "bert_model.encoder.layer.9.attention.self.query.bias 1.4273713532020338e-05\n",
            "bert_model.encoder.layer.9.attention.self.key.weight 0.00038374593714252114\n",
            "bert_model.encoder.layer.9.attention.self.key.bias 2.2847427075256554e-11\n",
            "bert_model.encoder.layer.9.attention.self.value.weight 0.05312115326523781\n",
            "bert_model.encoder.layer.9.attention.self.value.bias 0.0024865076411515474\n",
            "bert_model.encoder.layer.9.attention.output.dense.weight 0.06728217005729675\n",
            "bert_model.encoder.layer.9.attention.output.dense.bias 0.002683627652004361\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.weight 0.005110584665089846\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.bias 0.005365392193198204\n",
            "bert_model.encoder.layer.9.intermediate.dense.weight 0.08159525692462921\n",
            "bert_model.encoder.layer.9.intermediate.dense.bias 0.0036310264840722084\n",
            "bert_model.encoder.layer.9.output.dense.weight 0.06540180742740631\n",
            "bert_model.encoder.layer.9.output.dense.bias 0.0046670399606227875\n",
            "bert_model.encoder.layer.9.output.LayerNorm.weight 0.006097407080233097\n",
            "bert_model.encoder.layer.9.output.LayerNorm.bias 0.006594909355044365\n",
            "bert_model.encoder.layer.10.attention.self.query.weight 0.0004201426636427641\n",
            "bert_model.encoder.layer.10.attention.self.query.bias 1.9809480363619514e-05\n",
            "bert_model.encoder.layer.10.attention.self.key.weight 0.0005410255398601294\n",
            "bert_model.encoder.layer.10.attention.self.key.bias 7.239497890054736e-11\n",
            "bert_model.encoder.layer.10.attention.self.value.weight 0.08804435282945633\n",
            "bert_model.encoder.layer.10.attention.self.value.bias 0.004188095685094595\n",
            "bert_model.encoder.layer.10.attention.output.dense.weight 0.11806648969650269\n",
            "bert_model.encoder.layer.10.attention.output.dense.bias 0.004557847511023283\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.weight 0.009827233850955963\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.bias 0.009812116622924805\n",
            "bert_model.encoder.layer.10.intermediate.dense.weight 0.17144230008125305\n",
            "bert_model.encoder.layer.10.intermediate.dense.bias 0.007469496224075556\n",
            "bert_model.encoder.layer.10.output.dense.weight 0.14083053171634674\n",
            "bert_model.encoder.layer.10.output.dense.bias 0.009285342879593372\n",
            "bert_model.encoder.layer.10.output.LayerNorm.weight 0.016344618052244186\n",
            "bert_model.encoder.layer.10.output.LayerNorm.bias 0.013687722384929657\n",
            "bert_model.encoder.layer.11.attention.self.query.weight 0.0010738882701843977\n",
            "bert_model.encoder.layer.11.attention.self.query.bias 4.936148616252467e-05\n",
            "bert_model.encoder.layer.11.attention.self.key.weight 0.0013948882697150111\n",
            "bert_model.encoder.layer.11.attention.self.key.bias 2.0884255436115495e-10\n",
            "bert_model.encoder.layer.11.attention.self.value.weight 0.2457377016544342\n",
            "bert_model.encoder.layer.11.attention.self.value.bias 0.011577896773815155\n",
            "bert_model.encoder.layer.11.attention.output.dense.weight 0.21943771839141846\n",
            "bert_model.encoder.layer.11.attention.output.dense.bias 0.007253762800246477\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.weight 0.01853262633085251\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.bias 0.018719850108027458\n",
            "bert_model.encoder.layer.11.intermediate.dense.weight 0.19222837686538696\n",
            "bert_model.encoder.layer.11.intermediate.dense.bias 0.008164401166141033\n",
            "bert_model.encoder.layer.11.output.dense.weight 0.11613118648529053\n",
            "bert_model.encoder.layer.11.output.dense.bias 0.006934641860425472\n",
            "bert_model.encoder.layer.11.output.LayerNorm.weight 0.014136661775410175\n",
            "bert_model.encoder.layer.11.output.LayerNorm.bias 0.014739074744284153\n",
            "bert_model.pooler.dense.weight 0.10634113848209381\n",
            "bert_model.pooler.dense.bias 0.006244573276489973\n",
            "linear.weight 0.728692889213562\n",
            "linear.bias 0.028707802295684814\n",
            "\n",
            "  training loss: 0.03\n",
            "  Training epcoh took: 0:00:18\n",
            "  Batch   200  of  1,189.    Elapsed: 0:00:23.\n",
            "bert_model.embeddings.word_embeddings.weight 0.00013837075675837696\n",
            "bert_model.embeddings.position_embeddings.weight 0.00011767544492613524\n",
            "bert_model.embeddings.token_type_embeddings.weight 0.0013579964870586991\n",
            "bert_model.embeddings.LayerNorm.weight 2.149909414583817e-05\n",
            "bert_model.embeddings.LayerNorm.bias 8.464688289677724e-05\n",
            "bert_model.encoder.layer.0.attention.self.query.weight 3.133194331894629e-05\n",
            "bert_model.encoder.layer.0.attention.self.query.bias 4.499978786043357e-06\n",
            "bert_model.encoder.layer.0.attention.self.key.weight 3.41335944540333e-05\n",
            "bert_model.encoder.layer.0.attention.self.key.bias 2.0083229784056966e-13\n",
            "bert_model.encoder.layer.0.attention.self.value.weight 0.00018052695668302476\n",
            "bert_model.encoder.layer.0.attention.self.value.bias 5.2277031500125304e-05\n",
            "bert_model.encoder.layer.0.attention.output.dense.weight 0.00022823558538220823\n",
            "bert_model.encoder.layer.0.attention.output.dense.bias 5.221805258770473e-05\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.weight 1.7688358639134094e-05\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.bias 4.12184490414802e-05\n",
            "bert_model.encoder.layer.0.intermediate.dense.weight 0.0004794775741174817\n",
            "bert_model.encoder.layer.0.intermediate.dense.bias 2.4673478037584573e-05\n",
            "bert_model.encoder.layer.0.output.dense.weight 0.00022682109556626529\n",
            "bert_model.encoder.layer.0.output.dense.bias 4.127372449147515e-05\n",
            "bert_model.encoder.layer.0.output.LayerNorm.weight 7.66359589761123e-05\n",
            "bert_model.encoder.layer.0.output.LayerNorm.bias 7.87984172347933e-05\n",
            "bert_model.encoder.layer.1.attention.self.query.weight 8.684535714564845e-05\n",
            "bert_model.encoder.layer.1.attention.self.query.bias 8.794945642875973e-06\n",
            "bert_model.encoder.layer.1.attention.self.key.weight 7.633055793121457e-05\n",
            "bert_model.encoder.layer.1.attention.self.key.bias 4.788122480968438e-13\n",
            "bert_model.encoder.layer.1.attention.self.value.weight 0.0005217736470513046\n",
            "bert_model.encoder.layer.1.attention.self.value.bias 5.217860598349944e-05\n",
            "bert_model.encoder.layer.1.attention.output.dense.weight 0.0006397342076525092\n",
            "bert_model.encoder.layer.1.attention.output.dense.bias 5.1658284064615145e-05\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.weight 5.071283521829173e-05\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.bias 6.41422375338152e-05\n",
            "bert_model.encoder.layer.1.intermediate.dense.weight 0.0010329597862437367\n",
            "bert_model.encoder.layer.1.intermediate.dense.bias 3.1549516279483214e-05\n",
            "bert_model.encoder.layer.1.output.dense.weight 0.0007814603741280735\n",
            "bert_model.encoder.layer.1.output.dense.bias 6.302190013229847e-05\n",
            "bert_model.encoder.layer.1.output.LayerNorm.weight 0.00015589632675983012\n",
            "bert_model.encoder.layer.1.output.LayerNorm.bias 0.00013727491023018956\n",
            "bert_model.encoder.layer.2.attention.self.query.weight 2.819571272993926e-05\n",
            "bert_model.encoder.layer.2.attention.self.query.bias 1.8469252154318383e-06\n",
            "bert_model.encoder.layer.2.attention.self.key.weight 2.28438620979432e-05\n",
            "bert_model.encoder.layer.2.attention.self.key.bias 2.7951314765344015e-13\n",
            "bert_model.encoder.layer.2.attention.self.value.weight 0.0013425967190414667\n",
            "bert_model.encoder.layer.2.attention.self.value.bias 8.646264905110002e-05\n",
            "bert_model.encoder.layer.2.attention.output.dense.weight 0.0014007899444550276\n",
            "bert_model.encoder.layer.2.attention.output.dense.bias 8.219763549277559e-05\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.weight 0.00010963038221234456\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.bias 0.00011350389831932262\n",
            "bert_model.encoder.layer.2.intermediate.dense.weight 0.0020524959545582533\n",
            "bert_model.encoder.layer.2.intermediate.dense.bias 6.994089198997244e-05\n",
            "bert_model.encoder.layer.2.output.dense.weight 0.0013260457199066877\n",
            "bert_model.encoder.layer.2.output.dense.bias 7.322715100599453e-05\n",
            "bert_model.encoder.layer.2.output.LayerNorm.weight 0.00022487447131425142\n",
            "bert_model.encoder.layer.2.output.LayerNorm.bias 0.00016362768656108528\n",
            "bert_model.encoder.layer.3.attention.self.query.weight 2.8554586606333032e-05\n",
            "bert_model.encoder.layer.3.attention.self.query.bias 1.4942664847694687e-06\n",
            "bert_model.encoder.layer.3.attention.self.key.weight 2.374887299083639e-05\n",
            "bert_model.encoder.layer.3.attention.self.key.bias 3.4650033493496823e-13\n",
            "bert_model.encoder.layer.3.attention.self.value.weight 0.0023110853508114815\n",
            "bert_model.encoder.layer.3.attention.self.value.bias 0.00012049003998981789\n",
            "bert_model.encoder.layer.3.attention.output.dense.weight 0.003065400291234255\n",
            "bert_model.encoder.layer.3.attention.output.dense.bias 0.00011552935029612854\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.weight 0.00019195294589735568\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.bias 0.00021110643865540624\n",
            "bert_model.encoder.layer.3.intermediate.dense.weight 0.003474825993180275\n",
            "bert_model.encoder.layer.3.intermediate.dense.bias 0.00014333317812997848\n",
            "bert_model.encoder.layer.3.output.dense.weight 0.0027256645262241364\n",
            "bert_model.encoder.layer.3.output.dense.bias 0.00013198962551541626\n",
            "bert_model.encoder.layer.3.output.LayerNorm.weight 0.00022365935728885233\n",
            "bert_model.encoder.layer.3.output.LayerNorm.bias 0.00024407971068285406\n",
            "bert_model.encoder.layer.4.attention.self.query.weight 3.0177467124303803e-05\n",
            "bert_model.encoder.layer.4.attention.self.query.bias 1.510902620793786e-06\n",
            "bert_model.encoder.layer.4.attention.self.key.weight 3.460146763245575e-05\n",
            "bert_model.encoder.layer.4.attention.self.key.bias 4.2748470778855574e-13\n",
            "bert_model.encoder.layer.4.attention.self.value.weight 0.003186846384778619\n",
            "bert_model.encoder.layer.4.attention.self.value.bias 0.00015965681814122945\n",
            "bert_model.encoder.layer.4.attention.output.dense.weight 0.004143364727497101\n",
            "bert_model.encoder.layer.4.attention.output.dense.bias 0.0001635826047277078\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.weight 0.00028912670677527785\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.bias 0.00033982936292886734\n",
            "bert_model.encoder.layer.4.intermediate.dense.weight 0.0036831817124038935\n",
            "bert_model.encoder.layer.4.intermediate.dense.bias 0.0001405160001013428\n",
            "bert_model.encoder.layer.4.output.dense.weight 0.0022478592582046986\n",
            "bert_model.encoder.layer.4.output.dense.bias 0.00033095473190769553\n",
            "bert_model.encoder.layer.4.output.LayerNorm.weight 0.0003451909578870982\n",
            "bert_model.encoder.layer.4.output.LayerNorm.bias 0.0004207119345664978\n",
            "bert_model.encoder.layer.5.attention.self.query.weight 2.3169017367763445e-05\n",
            "bert_model.encoder.layer.5.attention.self.query.bias 1.115223085434991e-06\n",
            "bert_model.encoder.layer.5.attention.self.key.weight 3.278552685515024e-05\n",
            "bert_model.encoder.layer.5.attention.self.key.bias 5.151879899252532e-13\n",
            "bert_model.encoder.layer.5.attention.self.value.weight 0.00576150044798851\n",
            "bert_model.encoder.layer.5.attention.self.value.bias 0.00027734265313483775\n",
            "bert_model.encoder.layer.5.attention.output.dense.weight 0.006329561583697796\n",
            "bert_model.encoder.layer.5.attention.output.dense.bias 0.000291741598630324\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.weight 0.000567518756724894\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.bias 0.0005565693136304617\n",
            "bert_model.encoder.layer.5.intermediate.dense.weight 0.007341861724853516\n",
            "bert_model.encoder.layer.5.intermediate.dense.bias 0.00029649597126990557\n",
            "bert_model.encoder.layer.5.output.dense.weight 0.005640348419547081\n",
            "bert_model.encoder.layer.5.output.dense.bias 0.0005162958987057209\n",
            "bert_model.encoder.layer.5.output.LayerNorm.weight 0.0009361070115119219\n",
            "bert_model.encoder.layer.5.output.LayerNorm.bias 0.0008065764559432864\n",
            "bert_model.encoder.layer.6.attention.self.query.weight 3.561308403732255e-05\n",
            "bert_model.encoder.layer.6.attention.self.query.bias 1.6345105677828542e-06\n",
            "bert_model.encoder.layer.6.attention.self.key.weight 4.085269756615162e-05\n",
            "bert_model.encoder.layer.6.attention.self.key.bias 8.524478323744533e-13\n",
            "bert_model.encoder.layer.6.attention.self.value.weight 0.011412110179662704\n",
            "bert_model.encoder.layer.6.attention.self.value.bias 0.0005238943267613649\n",
            "bert_model.encoder.layer.6.attention.output.dense.weight 0.013495950028300285\n",
            "bert_model.encoder.layer.6.attention.output.dense.bias 0.000511028862092644\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.weight 0.0011637702118605375\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.bias 0.0011481199180707335\n",
            "bert_model.encoder.layer.6.intermediate.dense.weight 0.02018696255981922\n",
            "bert_model.encoder.layer.6.intermediate.dense.bias 0.000865196343511343\n",
            "bert_model.encoder.layer.6.output.dense.weight 0.013070386834442616\n",
            "bert_model.encoder.layer.6.output.dense.bias 0.0007763677276670933\n",
            "bert_model.encoder.layer.6.output.LayerNorm.weight 0.0019548828713595867\n",
            "bert_model.encoder.layer.6.output.LayerNorm.bias 0.0015796745428815484\n",
            "bert_model.encoder.layer.7.attention.self.query.weight 6.700364610878751e-05\n",
            "bert_model.encoder.layer.7.attention.self.query.bias 3.091901362495264e-06\n",
            "bert_model.encoder.layer.7.attention.self.key.weight 7.817090954631567e-05\n",
            "bert_model.encoder.layer.7.attention.self.key.bias 1.7761951848563329e-12\n",
            "bert_model.encoder.layer.7.attention.self.value.weight 0.01909523457288742\n",
            "bert_model.encoder.layer.7.attention.self.value.bias 0.0008813850581645966\n",
            "bert_model.encoder.layer.7.attention.output.dense.weight 0.027273673564195633\n",
            "bert_model.encoder.layer.7.attention.output.dense.bias 0.0009398289257660508\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.weight 0.0023414944298565388\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.bias 0.0023360871709883213\n",
            "bert_model.encoder.layer.7.intermediate.dense.weight 0.037927284836769104\n",
            "bert_model.encoder.layer.7.intermediate.dense.bias 0.001625623437575996\n",
            "bert_model.encoder.layer.7.output.dense.weight 0.023717893287539482\n",
            "bert_model.encoder.layer.7.output.dense.bias 0.0010029756231233478\n",
            "bert_model.encoder.layer.7.output.LayerNorm.weight 0.002654517302289605\n",
            "bert_model.encoder.layer.7.output.LayerNorm.bias 0.0025872415862977505\n",
            "bert_model.encoder.layer.8.attention.self.query.weight 0.0001596087822690606\n",
            "bert_model.encoder.layer.8.attention.self.query.bias 7.450195425917627e-06\n",
            "bert_model.encoder.layer.8.attention.self.key.weight 0.00016517122276127338\n",
            "bert_model.encoder.layer.8.attention.self.key.bias 4.772716510198505e-12\n",
            "bert_model.encoder.layer.8.attention.self.value.weight 0.03392846882343292\n",
            "bert_model.encoder.layer.8.attention.self.value.bias 0.0015842810971662402\n",
            "bert_model.encoder.layer.8.attention.output.dense.weight 0.04674404114484787\n",
            "bert_model.encoder.layer.8.attention.output.dense.bias 0.0014198303688317537\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.weight 0.003224453888833523\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.bias 0.003332554828375578\n",
            "bert_model.encoder.layer.8.intermediate.dense.weight 0.04463754594326019\n",
            "bert_model.encoder.layer.8.intermediate.dense.bias 0.0019499716581776738\n",
            "bert_model.encoder.layer.8.output.dense.weight 0.05167841166257858\n",
            "bert_model.encoder.layer.8.output.dense.bias 0.001711015123873949\n",
            "bert_model.encoder.layer.8.output.LayerNorm.weight 0.0034596140030771494\n",
            "bert_model.encoder.layer.8.output.LayerNorm.bias 0.003613562323153019\n",
            "bert_model.encoder.layer.9.attention.self.query.weight 0.00031307185417972505\n",
            "bert_model.encoder.layer.9.attention.self.query.bias 1.4805229511694051e-05\n",
            "bert_model.encoder.layer.9.attention.self.key.weight 0.0003993492282461375\n",
            "bert_model.encoder.layer.9.attention.self.key.bias 7.965503256990303e-12\n",
            "bert_model.encoder.layer.9.attention.self.value.weight 0.047393254935741425\n",
            "bert_model.encoder.layer.9.attention.self.value.bias 0.002246096497401595\n",
            "bert_model.encoder.layer.9.attention.output.dense.weight 0.06172559782862663\n",
            "bert_model.encoder.layer.9.attention.output.dense.bias 0.002330866176635027\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.weight 0.004540075547993183\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.bias 0.004580978769809008\n",
            "bert_model.encoder.layer.9.intermediate.dense.weight 0.08385025709867477\n",
            "bert_model.encoder.layer.9.intermediate.dense.bias 0.0036821940448135138\n",
            "bert_model.encoder.layer.9.output.dense.weight 0.06069811061024666\n",
            "bert_model.encoder.layer.9.output.dense.bias 0.003622007556259632\n",
            "bert_model.encoder.layer.9.output.LayerNorm.weight 0.005797479767352343\n",
            "bert_model.encoder.layer.9.output.LayerNorm.bias 0.0055173891596496105\n",
            "bert_model.encoder.layer.10.attention.self.query.weight 0.00034037945442833006\n",
            "bert_model.encoder.layer.10.attention.self.query.bias 1.613072345207911e-05\n",
            "bert_model.encoder.layer.10.attention.self.key.weight 0.00041097140638157725\n",
            "bert_model.encoder.layer.10.attention.self.key.bias 1.8568186918588303e-11\n",
            "bert_model.encoder.layer.10.attention.self.value.weight 0.07474450021982193\n",
            "bert_model.encoder.layer.10.attention.self.value.bias 0.0035503385588526726\n",
            "bert_model.encoder.layer.10.attention.output.dense.weight 0.0724656954407692\n",
            "bert_model.encoder.layer.10.attention.output.dense.bias 0.003175926161929965\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.weight 0.005820077378302813\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.bias 0.005489855073392391\n",
            "bert_model.encoder.layer.10.intermediate.dense.weight 0.04686281457543373\n",
            "bert_model.encoder.layer.10.intermediate.dense.bias 0.002042608568444848\n",
            "bert_model.encoder.layer.10.output.dense.weight 0.028244370594620705\n",
            "bert_model.encoder.layer.10.output.dense.bias 0.001969154691323638\n",
            "bert_model.encoder.layer.10.output.LayerNorm.weight 0.0034506607335060835\n",
            "bert_model.encoder.layer.10.output.LayerNorm.bias 0.002660666825249791\n",
            "bert_model.encoder.layer.11.attention.self.query.weight 0.0004712131340056658\n",
            "bert_model.encoder.layer.11.attention.self.query.bias 1.99742462427821e-05\n",
            "bert_model.encoder.layer.11.attention.self.key.weight 0.0005682330811396241\n",
            "bert_model.encoder.layer.11.attention.self.key.bias 4.3577003117079016e-11\n",
            "bert_model.encoder.layer.11.attention.self.value.weight 0.04491528868675232\n",
            "bert_model.encoder.layer.11.attention.self.value.bias 0.001947220996953547\n",
            "bert_model.encoder.layer.11.attention.output.dense.weight 0.02967802807688713\n",
            "bert_model.encoder.layer.11.attention.output.dense.bias 0.0011284046340733767\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.weight 0.0054515148513019085\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.bias 0.002601157408207655\n",
            "bert_model.encoder.layer.11.intermediate.dense.weight 0.02617492526769638\n",
            "bert_model.encoder.layer.11.intermediate.dense.bias 0.0009083353215828538\n",
            "bert_model.encoder.layer.11.output.dense.weight 0.011059341952204704\n",
            "bert_model.encoder.layer.11.output.dense.bias 0.0020692504476755857\n",
            "bert_model.encoder.layer.11.output.LayerNorm.weight 0.003858529031276703\n",
            "bert_model.encoder.layer.11.output.LayerNorm.bias 0.004472455009818077\n",
            "bert_model.pooler.dense.weight 0.05837174504995346\n",
            "bert_model.pooler.dense.bias 0.003821250982582569\n",
            "linear.weight 0.4044020473957062\n",
            "linear.bias 0.016444282606244087\n",
            "\n",
            "  training loss: 0.03\n",
            "  Training epcoh took: 0:00:24\n",
            "  Batch   240  of  1,189.    Elapsed: 0:00:26.\n",
            "bert_model.embeddings.word_embeddings.weight 6.117777957115322e-05\n",
            "bert_model.embeddings.position_embeddings.weight 5.0984897825401276e-05\n",
            "bert_model.embeddings.token_type_embeddings.weight 0.0005550117930397391\n",
            "bert_model.embeddings.LayerNorm.weight 1.59328574227402e-05\n",
            "bert_model.embeddings.LayerNorm.bias 3.502354957163334e-05\n",
            "bert_model.encoder.layer.0.attention.self.query.weight 1.2631279787456151e-05\n",
            "bert_model.encoder.layer.0.attention.self.query.bias 2.285556774950237e-06\n",
            "bert_model.encoder.layer.0.attention.self.key.weight 1.5102130419109017e-05\n",
            "bert_model.encoder.layer.0.attention.self.key.bias 1.3466204334348225e-13\n",
            "bert_model.encoder.layer.0.attention.self.value.weight 7.936164911370724e-05\n",
            "bert_model.encoder.layer.0.attention.self.value.bias 2.191981729993131e-05\n",
            "bert_model.encoder.layer.0.attention.output.dense.weight 0.00010625686991261318\n",
            "bert_model.encoder.layer.0.attention.output.dense.bias 2.187468453485053e-05\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.weight 7.655429726582952e-06\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.bias 1.7841413864516653e-05\n",
            "bert_model.encoder.layer.0.intermediate.dense.weight 0.0002064253785647452\n",
            "bert_model.encoder.layer.0.intermediate.dense.bias 1.0201617442362476e-05\n",
            "bert_model.encoder.layer.0.output.dense.weight 0.00011141831782879308\n",
            "bert_model.encoder.layer.0.output.dense.bias 1.811290167097468e-05\n",
            "bert_model.encoder.layer.0.output.LayerNorm.weight 3.225700493203476e-05\n",
            "bert_model.encoder.layer.0.output.LayerNorm.bias 3.574599395506084e-05\n",
            "bert_model.encoder.layer.1.attention.self.query.weight 2.18836466956418e-05\n",
            "bert_model.encoder.layer.1.attention.self.query.bias 1.9774201973632444e-06\n",
            "bert_model.encoder.layer.1.attention.self.key.weight 2.4673570806044154e-05\n",
            "bert_model.encoder.layer.1.attention.self.key.bias 2.2396293803891854e-13\n",
            "bert_model.encoder.layer.1.attention.self.value.weight 0.00024546694476157427\n",
            "bert_model.encoder.layer.1.attention.self.value.bias 2.2490368792205118e-05\n",
            "bert_model.encoder.layer.1.attention.output.dense.weight 0.0003015027614310384\n",
            "bert_model.encoder.layer.1.attention.output.dense.bias 2.1359117454267107e-05\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.weight 2.3187350961961783e-05\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.bias 2.9031438316451386e-05\n",
            "bert_model.encoder.layer.1.intermediate.dense.weight 0.0005930737825110555\n",
            "bert_model.encoder.layer.1.intermediate.dense.bias 1.8025266399490647e-05\n",
            "bert_model.encoder.layer.1.output.dense.weight 0.00036774936597794294\n",
            "bert_model.encoder.layer.1.output.dense.bias 2.5775905669433996e-05\n",
            "bert_model.encoder.layer.1.output.LayerNorm.weight 0.0001455977908335626\n",
            "bert_model.encoder.layer.1.output.LayerNorm.bias 6.210600258782506e-05\n",
            "bert_model.encoder.layer.2.attention.self.query.weight 1.4712579286424443e-05\n",
            "bert_model.encoder.layer.2.attention.self.query.bias 9.694897471490549e-07\n",
            "bert_model.encoder.layer.2.attention.self.key.weight 1.3034957191848662e-05\n",
            "bert_model.encoder.layer.2.attention.self.key.bias 1.6876739806007124e-13\n",
            "bert_model.encoder.layer.2.attention.self.value.weight 0.0007151054451242089\n",
            "bert_model.encoder.layer.2.attention.self.value.bias 4.590926255332306e-05\n",
            "bert_model.encoder.layer.2.attention.output.dense.weight 0.0008389328722842038\n",
            "bert_model.encoder.layer.2.attention.output.dense.bias 4.563020047498867e-05\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.weight 8.063088171184063e-05\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.bias 6.929015944479033e-05\n",
            "bert_model.encoder.layer.2.intermediate.dense.weight 0.0015621378552168608\n",
            "bert_model.encoder.layer.2.intermediate.dense.bias 5.600125950877555e-05\n",
            "bert_model.encoder.layer.2.output.dense.weight 0.0009526161593385041\n",
            "bert_model.encoder.layer.2.output.dense.bias 3.818068216787651e-05\n",
            "bert_model.encoder.layer.2.output.LayerNorm.weight 0.0001419314939994365\n",
            "bert_model.encoder.layer.2.output.LayerNorm.bias 0.00010623726848280057\n",
            "bert_model.encoder.layer.3.attention.self.query.weight 1.6082996808108874e-05\n",
            "bert_model.encoder.layer.3.attention.self.query.bias 8.384515126635961e-07\n",
            "bert_model.encoder.layer.3.attention.self.key.weight 1.4149639355309773e-05\n",
            "bert_model.encoder.layer.3.attention.self.key.bias 3.209521678374655e-13\n",
            "bert_model.encoder.layer.3.attention.self.value.weight 0.001392228645272553\n",
            "bert_model.encoder.layer.3.attention.self.value.bias 7.239849946927279e-05\n",
            "bert_model.encoder.layer.3.attention.output.dense.weight 0.002088997047394514\n",
            "bert_model.encoder.layer.3.attention.output.dense.bias 7.279573037521914e-05\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.weight 0.00013201010006014258\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.bias 0.0001327879581367597\n",
            "bert_model.encoder.layer.3.intermediate.dense.weight 0.002047991380095482\n",
            "bert_model.encoder.layer.3.intermediate.dense.bias 8.504915604135022e-05\n",
            "bert_model.encoder.layer.3.output.dense.weight 0.0018888802733272314\n",
            "bert_model.encoder.layer.3.output.dense.bias 8.752315625315532e-05\n",
            "bert_model.encoder.layer.3.output.LayerNorm.weight 0.00014161373837850988\n",
            "bert_model.encoder.layer.3.output.LayerNorm.bias 0.00016452487034257501\n",
            "bert_model.encoder.layer.4.attention.self.query.weight 2.0398454580572434e-05\n",
            "bert_model.encoder.layer.4.attention.self.query.bias 1.0256777613903978e-06\n",
            "bert_model.encoder.layer.4.attention.self.key.weight 2.7801672331406735e-05\n",
            "bert_model.encoder.layer.4.attention.self.key.bias 7.053759703071205e-13\n",
            "bert_model.encoder.layer.4.attention.self.value.weight 0.0022737665567547083\n",
            "bert_model.encoder.layer.4.attention.self.value.bias 0.00011450983583927155\n",
            "bert_model.encoder.layer.4.attention.output.dense.weight 0.002944778650999069\n",
            "bert_model.encoder.layer.4.attention.output.dense.bias 0.0001070243088179268\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.weight 0.0002180837473133579\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.bias 0.00023635140678379685\n",
            "bert_model.encoder.layer.4.intermediate.dense.weight 0.0025831423699855804\n",
            "bert_model.encoder.layer.4.intermediate.dense.bias 0.00010060640488518402\n",
            "bert_model.encoder.layer.4.output.dense.weight 0.0020097920205444098\n",
            "bert_model.encoder.layer.4.output.dense.bias 0.00023676980345044285\n",
            "bert_model.encoder.layer.4.output.LayerNorm.weight 0.00026905781123787165\n",
            "bert_model.encoder.layer.4.output.LayerNorm.bias 0.0003033246612176299\n",
            "bert_model.encoder.layer.5.attention.self.query.weight 2.013954144786112e-05\n",
            "bert_model.encoder.layer.5.attention.self.query.bias 9.65347112469317e-07\n",
            "bert_model.encoder.layer.5.attention.self.key.weight 3.118690801784396e-05\n",
            "bert_model.encoder.layer.5.attention.self.key.bias 8.231391371467389e-13\n",
            "bert_model.encoder.layer.5.attention.self.value.weight 0.003643451491370797\n",
            "bert_model.encoder.layer.5.attention.self.value.bias 0.00017475128697697073\n",
            "bert_model.encoder.layer.5.attention.output.dense.weight 0.004206125158816576\n",
            "bert_model.encoder.layer.5.attention.output.dense.bias 0.00017716803995426744\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.weight 0.0003564692160580307\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.bias 0.00037023151526227593\n",
            "bert_model.encoder.layer.5.intermediate.dense.weight 0.004721340723335743\n",
            "bert_model.encoder.layer.5.intermediate.dense.bias 0.0001935481559485197\n",
            "bert_model.encoder.layer.5.output.dense.weight 0.003778171492740512\n",
            "bert_model.encoder.layer.5.output.dense.bias 0.0003240043588448316\n",
            "bert_model.encoder.layer.5.output.LayerNorm.weight 0.0006049677031114697\n",
            "bert_model.encoder.layer.5.output.LayerNorm.bias 0.0005360974464565516\n",
            "bert_model.encoder.layer.6.attention.self.query.weight 2.6658211936592124e-05\n",
            "bert_model.encoder.layer.6.attention.self.query.bias 1.2234885389261763e-06\n",
            "bert_model.encoder.layer.6.attention.self.key.weight 3.0680628697155043e-05\n",
            "bert_model.encoder.layer.6.attention.self.key.bias 1.5688398930652214e-12\n",
            "bert_model.encoder.layer.6.attention.self.value.weight 0.007063090335577726\n",
            "bert_model.encoder.layer.6.attention.self.value.bias 0.0003244859690312296\n",
            "bert_model.encoder.layer.6.attention.output.dense.weight 0.00970938429236412\n",
            "bert_model.encoder.layer.6.attention.output.dense.bias 0.0003310134925413877\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.weight 0.0008000690722838044\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.bias 0.00083114521112293\n",
            "bert_model.encoder.layer.6.intermediate.dense.weight 0.017391275614500046\n",
            "bert_model.encoder.layer.6.intermediate.dense.bias 0.0007646237500011921\n",
            "bert_model.encoder.layer.6.output.dense.weight 0.009122636169195175\n",
            "bert_model.encoder.layer.6.output.dense.bias 0.00040990396519191563\n",
            "bert_model.encoder.layer.6.output.LayerNorm.weight 0.0010483924997970462\n",
            "bert_model.encoder.layer.6.output.LayerNorm.bias 0.0009812156204134226\n",
            "bert_model.encoder.layer.7.attention.self.query.weight 5.905285070184618e-05\n",
            "bert_model.encoder.layer.7.attention.self.query.bias 2.691663894438534e-06\n",
            "bert_model.encoder.layer.7.attention.self.key.weight 7.161636312957853e-05\n",
            "bert_model.encoder.layer.7.attention.self.key.bias 5.300395972823724e-12\n",
            "bert_model.encoder.layer.7.attention.self.value.weight 0.0115769999101758\n",
            "bert_model.encoder.layer.7.attention.self.value.bias 0.0005320428754203022\n",
            "bert_model.encoder.layer.7.attention.output.dense.weight 0.01847998984158039\n",
            "bert_model.encoder.layer.7.attention.output.dense.bias 0.0005676801083609462\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.weight 0.0014852085150778294\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.bias 0.0015026277396827936\n",
            "bert_model.encoder.layer.7.intermediate.dense.weight 0.020882554352283478\n",
            "bert_model.encoder.layer.7.intermediate.dense.bias 0.0009483048343099654\n",
            "bert_model.encoder.layer.7.output.dense.weight 0.01745949685573578\n",
            "bert_model.encoder.layer.7.output.dense.bias 0.0004200137045700103\n",
            "bert_model.encoder.layer.7.output.LayerNorm.weight 0.0018339278176426888\n",
            "bert_model.encoder.layer.7.output.LayerNorm.bias 0.0018572659464552999\n",
            "bert_model.encoder.layer.8.attention.self.query.weight 0.0001890760031528771\n",
            "bert_model.encoder.layer.8.attention.self.query.bias 8.515943591191899e-06\n",
            "bert_model.encoder.layer.8.attention.self.key.weight 0.0002146425686078146\n",
            "bert_model.encoder.layer.8.attention.self.key.bias 3.1974346781371565e-11\n",
            "bert_model.encoder.layer.8.attention.self.value.weight 0.024844951927661896\n",
            "bert_model.encoder.layer.8.attention.self.value.bias 0.0011509800096973777\n",
            "bert_model.encoder.layer.8.attention.output.dense.weight 0.035767827183008194\n",
            "bert_model.encoder.layer.8.attention.output.dense.bias 0.0010448909597471356\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.weight 0.002428261796012521\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.bias 0.0023780877236276865\n",
            "bert_model.encoder.layer.8.intermediate.dense.weight 0.020948458462953568\n",
            "bert_model.encoder.layer.8.intermediate.dense.bias 0.0009540249011479318\n",
            "bert_model.encoder.layer.8.output.dense.weight 0.026134125888347626\n",
            "bert_model.encoder.layer.8.output.dense.bias 0.0005229224334470928\n",
            "bert_model.encoder.layer.8.output.LayerNorm.weight 0.0024791336618363857\n",
            "bert_model.encoder.layer.8.output.LayerNorm.bias 0.002771566156297922\n",
            "bert_model.encoder.layer.9.attention.self.query.weight 0.0003634230815805495\n",
            "bert_model.encoder.layer.9.attention.self.query.bias 1.80330916919047e-05\n",
            "bert_model.encoder.layer.9.attention.self.key.weight 0.0003901203745044768\n",
            "bert_model.encoder.layer.9.attention.self.key.bias 3.4402675153089035e-11\n",
            "bert_model.encoder.layer.9.attention.self.value.weight 0.034971125423908234\n",
            "bert_model.encoder.layer.9.attention.self.value.bias 0.0017429597210139036\n",
            "bert_model.encoder.layer.9.attention.output.dense.weight 0.04190748557448387\n",
            "bert_model.encoder.layer.9.attention.output.dense.bias 0.001531912013888359\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.weight 0.0037230211310088634\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.bias 0.003444387810304761\n",
            "bert_model.encoder.layer.9.intermediate.dense.weight 0.030850887298583984\n",
            "bert_model.encoder.layer.9.intermediate.dense.bias 0.0013162068789824843\n",
            "bert_model.encoder.layer.9.output.dense.weight 0.02081928588449955\n",
            "bert_model.encoder.layer.9.output.dense.bias 0.0016776854172348976\n",
            "bert_model.encoder.layer.9.output.LayerNorm.weight 0.0043521481566131115\n",
            "bert_model.encoder.layer.9.output.LayerNorm.bias 0.002163780154660344\n",
            "bert_model.encoder.layer.10.attention.self.query.weight 0.0012883999152109027\n",
            "bert_model.encoder.layer.10.attention.self.query.bias 8.424979023402557e-05\n",
            "bert_model.encoder.layer.10.attention.self.key.weight 0.0009716315544210374\n",
            "bert_model.encoder.layer.10.attention.self.key.bias 3.932714223719991e-11\n",
            "bert_model.encoder.layer.10.attention.self.value.weight 0.021215105429291725\n",
            "bert_model.encoder.layer.10.attention.self.value.bias 0.0012518544681370258\n",
            "bert_model.encoder.layer.10.attention.output.dense.weight 0.020364824682474136\n",
            "bert_model.encoder.layer.10.attention.output.dense.bias 0.0011130147613584995\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.weight 0.0031360816210508347\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.bias 0.001444980618543923\n",
            "bert_model.encoder.layer.10.intermediate.dense.weight 0.008841859176754951\n",
            "bert_model.encoder.layer.10.intermediate.dense.bias 0.00033678821637295187\n",
            "bert_model.encoder.layer.10.output.dense.weight 0.0041775950230658054\n",
            "bert_model.encoder.layer.10.output.dense.bias 0.0010829715756699443\n",
            "bert_model.encoder.layer.10.output.LayerNorm.weight 0.0018039002316072583\n",
            "bert_model.encoder.layer.10.output.LayerNorm.bias 0.0014874275075271726\n",
            "bert_model.encoder.layer.11.attention.self.query.weight 0.0005087691824883223\n",
            "bert_model.encoder.layer.11.attention.self.query.bias 2.4345206838916056e-05\n",
            "bert_model.encoder.layer.11.attention.self.key.weight 0.0004649008915293962\n",
            "bert_model.encoder.layer.11.attention.self.key.bias 4.890554974879002e-11\n",
            "bert_model.encoder.layer.11.attention.self.value.weight 0.018049797043204308\n",
            "bert_model.encoder.layer.11.attention.self.value.bias 0.0010735784890130162\n",
            "bert_model.encoder.layer.11.attention.output.dense.weight 0.013334820978343487\n",
            "bert_model.encoder.layer.11.attention.output.dense.bias 0.0006738900556229055\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.weight 0.002141580916941166\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.bias 0.0011637854622676969\n",
            "bert_model.encoder.layer.11.intermediate.dense.weight 0.013332774862647057\n",
            "bert_model.encoder.layer.11.intermediate.dense.bias 0.00045515323290601373\n",
            "bert_model.encoder.layer.11.output.dense.weight 0.00838096160441637\n",
            "bert_model.encoder.layer.11.output.dense.bias 0.0010080207139253616\n",
            "bert_model.encoder.layer.11.output.LayerNorm.weight 0.0018833385547623038\n",
            "bert_model.encoder.layer.11.output.LayerNorm.bias 0.0023316978476941586\n",
            "bert_model.pooler.dense.weight 0.050276100635528564\n",
            "bert_model.pooler.dense.bias 0.0032602192368358374\n",
            "linear.weight 0.3288494348526001\n",
            "linear.bias 0.0123122688382864\n",
            "\n",
            "  training loss: 0.03\n",
            "  Training epcoh took: 0:00:28\n",
            "  Batch   280  of  1,189.    Elapsed: 0:00:30.\n",
            "bert_model.embeddings.word_embeddings.weight 9.248565788766427e-07\n",
            "bert_model.embeddings.position_embeddings.weight 7.908071779638703e-07\n",
            "bert_model.embeddings.token_type_embeddings.weight 5.069558937975671e-06\n",
            "bert_model.embeddings.LayerNorm.weight 3.1750104767525045e-07\n",
            "bert_model.embeddings.LayerNorm.bias 3.2677186823093507e-07\n",
            "bert_model.encoder.layer.0.attention.self.query.weight 1.538255958166701e-07\n",
            "bert_model.encoder.layer.0.attention.self.query.bias 2.201526427825229e-08\n",
            "bert_model.encoder.layer.0.attention.self.key.weight 1.9145119267705013e-07\n",
            "bert_model.encoder.layer.0.attention.self.key.bias 1.8812934218949808e-15\n",
            "bert_model.encoder.layer.0.attention.self.value.weight 9.622222023608629e-07\n",
            "bert_model.encoder.layer.0.attention.self.value.bias 2.0502079678408336e-07\n",
            "bert_model.encoder.layer.0.attention.output.dense.weight 1.0171760322919e-06\n",
            "bert_model.encoder.layer.0.attention.output.dense.bias 1.816555652567331e-07\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.weight 9.242781118246057e-08\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.bias 1.4768079381610733e-07\n",
            "bert_model.encoder.layer.0.intermediate.dense.weight 1.952815409822506e-06\n",
            "bert_model.encoder.layer.0.intermediate.dense.bias 8.345205060322769e-08\n",
            "bert_model.encoder.layer.0.output.dense.weight 9.9495593985921e-07\n",
            "bert_model.encoder.layer.0.output.dense.bias 1.3616809724226187e-07\n",
            "bert_model.encoder.layer.0.output.LayerNorm.weight 2.118605948453478e-07\n",
            "bert_model.encoder.layer.0.output.LayerNorm.bias 2.7730021656680037e-07\n",
            "bert_model.encoder.layer.1.attention.self.query.weight 3.119726841305237e-07\n",
            "bert_model.encoder.layer.1.attention.self.query.bias 2.724268277631836e-08\n",
            "bert_model.encoder.layer.1.attention.self.key.weight 3.479993893051869e-07\n",
            "bert_model.encoder.layer.1.attention.self.key.bias 5.6975997304745205e-15\n",
            "bert_model.encoder.layer.1.attention.self.value.weight 2.9571876893896842e-06\n",
            "bert_model.encoder.layer.1.attention.self.value.bias 2.648080226208549e-07\n",
            "bert_model.encoder.layer.1.attention.output.dense.weight 2.9979787541378755e-06\n",
            "bert_model.encoder.layer.1.attention.output.dense.bias 2.0898632158150576e-07\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.weight 2.836698627106671e-07\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.bias 2.836618477886077e-07\n",
            "bert_model.encoder.layer.1.intermediate.dense.weight 5.535574473469751e-06\n",
            "bert_model.encoder.layer.1.intermediate.dense.bias 1.6008793579658231e-07\n",
            "bert_model.encoder.layer.1.output.dense.weight 3.676288315546117e-06\n",
            "bert_model.encoder.layer.1.output.dense.bias 2.3304586704853136e-07\n",
            "bert_model.encoder.layer.1.output.LayerNorm.weight 1.3846496358382865e-06\n",
            "bert_model.encoder.layer.1.output.LayerNorm.bias 7.549650717919576e-07\n",
            "bert_model.encoder.layer.2.attention.self.query.weight 1.4296335848484887e-07\n",
            "bert_model.encoder.layer.2.attention.self.query.bias 9.941822476378093e-09\n",
            "bert_model.encoder.layer.2.attention.self.key.weight 1.233865987160243e-07\n",
            "bert_model.encoder.layer.2.attention.self.key.bias 2.204537076434983e-15\n",
            "bert_model.encoder.layer.2.attention.self.value.weight 6.509046670544194e-06\n",
            "bert_model.encoder.layer.2.attention.self.value.bias 4.3733285792768584e-07\n",
            "bert_model.encoder.layer.2.attention.output.dense.weight 6.70976214678376e-06\n",
            "bert_model.encoder.layer.2.attention.output.dense.bias 3.6313326745585073e-07\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.weight 6.803305154789996e-07\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.bias 5.41689757938002e-07\n",
            "bert_model.encoder.layer.2.intermediate.dense.weight 5.477869763126364e-06\n",
            "bert_model.encoder.layer.2.intermediate.dense.bias 2.007283086413736e-07\n",
            "bert_model.encoder.layer.2.output.dense.weight 4.010436441603815e-06\n",
            "bert_model.encoder.layer.2.output.dense.bias 1.264068458795009e-07\n",
            "bert_model.encoder.layer.2.output.LayerNorm.weight 5.598987513621978e-07\n",
            "bert_model.encoder.layer.2.output.LayerNorm.bias 4.0532319189878763e-07\n",
            "bert_model.encoder.layer.3.attention.self.query.weight 1.437636711898449e-07\n",
            "bert_model.encoder.layer.3.attention.self.query.bias 7.505461141477099e-09\n",
            "bert_model.encoder.layer.3.attention.self.key.weight 1.3529684395052755e-07\n",
            "bert_model.encoder.layer.3.attention.self.key.bias 3.637360222318465e-15\n",
            "bert_model.encoder.layer.3.attention.self.value.weight 5.6180138017225545e-06\n",
            "bert_model.encoder.layer.3.attention.self.value.bias 2.9285575919857365e-07\n",
            "bert_model.encoder.layer.3.attention.output.dense.weight 8.505690857418813e-06\n",
            "bert_model.encoder.layer.3.attention.output.dense.bias 2.8809688501496566e-07\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.weight 4.877655328527908e-07\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.bias 4.786090244124352e-07\n",
            "bert_model.encoder.layer.3.intermediate.dense.weight 9.097911970457062e-06\n",
            "bert_model.encoder.layer.3.intermediate.dense.bias 3.7485577308871143e-07\n",
            "bert_model.encoder.layer.3.output.dense.weight 7.821132385288365e-06\n",
            "bert_model.encoder.layer.3.output.dense.bias 3.9979460098038544e-07\n",
            "bert_model.encoder.layer.3.output.LayerNorm.weight 6.9768452704011e-07\n",
            "bert_model.encoder.layer.3.output.LayerNorm.bias 6.790759243813227e-07\n",
            "bert_model.encoder.layer.4.attention.self.query.weight 1.1753532902503139e-07\n",
            "bert_model.encoder.layer.4.attention.self.query.bias 5.842402561739846e-09\n",
            "bert_model.encoder.layer.4.attention.self.key.weight 2.082216070675713e-07\n",
            "bert_model.encoder.layer.4.attention.self.key.bias 1.665183934479713e-14\n",
            "bert_model.encoder.layer.4.attention.self.value.weight 8.299791261379141e-06\n",
            "bert_model.encoder.layer.4.attention.self.value.bias 4.161940694302757e-07\n",
            "bert_model.encoder.layer.4.attention.output.dense.weight 1.188113401440205e-05\n",
            "bert_model.encoder.layer.4.attention.output.dense.bias 3.992404344899114e-07\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.weight 8.293949349535978e-07\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.bias 8.952996495281695e-07\n",
            "bert_model.encoder.layer.4.intermediate.dense.weight 1.0977847523463424e-05\n",
            "bert_model.encoder.layer.4.intermediate.dense.bias 4.371421198356984e-07\n",
            "bert_model.encoder.layer.4.output.dense.weight 1.0002914677897934e-05\n",
            "bert_model.encoder.layer.4.output.dense.bias 7.836579811737465e-07\n",
            "bert_model.encoder.layer.4.output.LayerNorm.weight 9.336270068160957e-07\n",
            "bert_model.encoder.layer.4.output.LayerNorm.bias 1.055512370840006e-06\n",
            "bert_model.encoder.layer.5.attention.self.query.weight 1.592013489926103e-07\n",
            "bert_model.encoder.layer.5.attention.self.query.bias 7.542574564922688e-09\n",
            "bert_model.encoder.layer.5.attention.self.key.weight 2.3626164136203442e-07\n",
            "bert_model.encoder.layer.5.attention.self.key.bias 8.779626094331753e-15\n",
            "bert_model.encoder.layer.5.attention.self.value.weight 1.3603505067294464e-05\n",
            "bert_model.encoder.layer.5.attention.self.value.bias 6.465238016062358e-07\n",
            "bert_model.encoder.layer.5.attention.output.dense.weight 1.8946953787235543e-05\n",
            "bert_model.encoder.layer.5.attention.output.dense.bias 6.988374252614449e-07\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.weight 1.5320277952923789e-06\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.bias 1.6508593034814112e-06\n",
            "bert_model.encoder.layer.5.intermediate.dense.weight 2.8992337320232764e-05\n",
            "bert_model.encoder.layer.5.intermediate.dense.bias 1.2157431683590403e-06\n",
            "bert_model.encoder.layer.5.output.dense.weight 2.379363104410004e-05\n",
            "bert_model.encoder.layer.5.output.dense.bias 1.4119975730864098e-06\n",
            "bert_model.encoder.layer.5.output.LayerNorm.weight 2.654556737979874e-06\n",
            "bert_model.encoder.layer.5.output.LayerNorm.bias 2.431699385851971e-06\n",
            "bert_model.encoder.layer.6.attention.self.query.weight 2.8641852622968145e-07\n",
            "bert_model.encoder.layer.6.attention.self.query.bias 1.3220209815756334e-08\n",
            "bert_model.encoder.layer.6.attention.self.key.weight 4.010585996638838e-07\n",
            "bert_model.encoder.layer.6.attention.self.key.bias 2.6885328883422162e-14\n",
            "bert_model.encoder.layer.6.attention.self.value.weight 3.237555210944265e-05\n",
            "bert_model.encoder.layer.6.attention.self.value.bias 1.4999391169112641e-06\n",
            "bert_model.encoder.layer.6.attention.output.dense.weight 5.288176180329174e-05\n",
            "bert_model.encoder.layer.6.attention.output.dense.bias 1.65976416610647e-06\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.weight 4.585019723890582e-06\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.bias 4.398354576551355e-06\n",
            "bert_model.encoder.layer.6.intermediate.dense.weight 6.390496128005907e-05\n",
            "bert_model.encoder.layer.6.intermediate.dense.bias 2.7908461106562754e-06\n",
            "bert_model.encoder.layer.6.output.dense.weight 6.421137368306518e-05\n",
            "bert_model.encoder.layer.6.output.dense.bias 3.166418309774599e-06\n",
            "bert_model.encoder.layer.6.output.LayerNorm.weight 7.085182915034238e-06\n",
            "bert_model.encoder.layer.6.output.LayerNorm.bias 6.945774202904431e-06\n",
            "bert_model.encoder.layer.7.attention.self.query.weight 7.448998076142743e-07\n",
            "bert_model.encoder.layer.7.attention.self.query.bias 3.426195149813793e-08\n",
            "bert_model.encoder.layer.7.attention.self.key.weight 9.568153700456605e-07\n",
            "bert_model.encoder.layer.7.attention.self.key.bias 8.532693459130727e-14\n",
            "bert_model.encoder.layer.7.attention.self.value.weight 8.963780419435352e-05\n",
            "bert_model.encoder.layer.7.attention.self.value.bias 4.139613793086028e-06\n",
            "bert_model.encoder.layer.7.attention.output.dense.weight 0.00016277653048746288\n",
            "bert_model.encoder.layer.7.attention.output.dense.bias 4.7073326641111635e-06\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.weight 1.4124399967840873e-05\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.bias 1.5272264136001468e-05\n",
            "bert_model.encoder.layer.7.intermediate.dense.weight 0.00031530033447779715\n",
            "bert_model.encoder.layer.7.intermediate.dense.bias 1.4082561392569914e-05\n",
            "bert_model.encoder.layer.7.output.dense.weight 0.00031528982799500227\n",
            "bert_model.encoder.layer.7.output.dense.bias 8.05524268798763e-06\n",
            "bert_model.encoder.layer.7.output.LayerNorm.weight 3.313359047751874e-05\n",
            "bert_model.encoder.layer.7.output.LayerNorm.bias 3.4738073736662045e-05\n",
            "bert_model.encoder.layer.8.attention.self.query.weight 3.7708189211116405e-06\n",
            "bert_model.encoder.layer.8.attention.self.query.bias 1.7379522887495114e-07\n",
            "bert_model.encoder.layer.8.attention.self.key.weight 4.5225751819089055e-06\n",
            "bert_model.encoder.layer.8.attention.self.key.bias 2.771800258934143e-13\n",
            "bert_model.encoder.layer.8.attention.self.value.weight 0.00045147212222218513\n",
            "bert_model.encoder.layer.8.attention.self.value.bias 2.0932840925524943e-05\n",
            "bert_model.encoder.layer.8.attention.output.dense.weight 0.0007834379794076085\n",
            "bert_model.encoder.layer.8.attention.output.dense.bias 2.0704623238998465e-05\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.weight 5.804760803584941e-05\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.bias 5.870230961591005e-05\n",
            "bert_model.encoder.layer.8.intermediate.dense.weight 0.0007297319243662059\n",
            "bert_model.encoder.layer.8.intermediate.dense.bias 3.276870847912505e-05\n",
            "bert_model.encoder.layer.8.output.dense.weight 0.0009095209534280002\n",
            "bert_model.encoder.layer.8.output.dense.bias 2.094213414238766e-05\n",
            "bert_model.encoder.layer.8.output.LayerNorm.weight 7.441971683874726e-05\n",
            "bert_model.encoder.layer.8.output.LayerNorm.bias 8.245662320405245e-05\n",
            "bert_model.encoder.layer.9.attention.self.query.weight 1.3324960491445381e-05\n",
            "bert_model.encoder.layer.9.attention.self.query.bias 6.092458875173179e-07\n",
            "bert_model.encoder.layer.9.attention.self.key.weight 1.8755374185275286e-05\n",
            "bert_model.encoder.layer.9.attention.self.key.bias 3.0971592478168386e-12\n",
            "bert_model.encoder.layer.9.attention.self.value.weight 0.0009774303762242198\n",
            "bert_model.encoder.layer.9.attention.self.value.bias 4.592305776895955e-05\n",
            "bert_model.encoder.layer.9.attention.output.dense.weight 0.0014892249600961804\n",
            "bert_model.encoder.layer.9.attention.output.dense.bias 4.739994619740173e-05\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.weight 0.00011182331945747137\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.bias 0.00011887822620337829\n",
            "bert_model.encoder.layer.9.intermediate.dense.weight 0.0011174010578542948\n",
            "bert_model.encoder.layer.9.intermediate.dense.bias 4.6311710320878774e-05\n",
            "bert_model.encoder.layer.9.output.dense.weight 0.0006399881094694138\n",
            "bert_model.encoder.layer.9.output.dense.bias 0.0001115011764341034\n",
            "bert_model.encoder.layer.9.output.LayerNorm.weight 0.00011845917470054701\n",
            "bert_model.encoder.layer.9.output.LayerNorm.bias 0.0001301898737438023\n",
            "bert_model.encoder.layer.10.attention.self.query.weight 1.9491149942041375e-05\n",
            "bert_model.encoder.layer.10.attention.self.query.bias 9.02494321053382e-07\n",
            "bert_model.encoder.layer.10.attention.self.key.weight 2.9639135391335003e-05\n",
            "bert_model.encoder.layer.10.attention.self.key.bias 3.523302743307921e-12\n",
            "bert_model.encoder.layer.10.attention.self.value.weight 0.0016694514779374003\n",
            "bert_model.encoder.layer.10.attention.self.value.bias 8.024352428037673e-05\n",
            "bert_model.encoder.layer.10.attention.output.dense.weight 0.0018554878188297153\n",
            "bert_model.encoder.layer.10.attention.output.dense.bias 7.530814036726952e-05\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.weight 0.00023444033286068588\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.bias 0.00016651596524752676\n",
            "bert_model.encoder.layer.10.intermediate.dense.weight 0.0012704887194558978\n",
            "bert_model.encoder.layer.10.intermediate.dense.bias 5.306597813614644e-05\n",
            "bert_model.encoder.layer.10.output.dense.weight 0.0008584637544117868\n",
            "bert_model.encoder.layer.10.output.dense.bias 0.00016257035895250738\n",
            "bert_model.encoder.layer.10.output.LayerNorm.weight 0.00023310862889047712\n",
            "bert_model.encoder.layer.10.output.LayerNorm.bias 0.00022222459665499628\n",
            "bert_model.encoder.layer.11.attention.self.query.weight 6.0979647969361395e-05\n",
            "bert_model.encoder.layer.11.attention.self.query.bias 2.4803650831017876e-06\n",
            "bert_model.encoder.layer.11.attention.self.key.weight 0.00011220010492252186\n",
            "bert_model.encoder.layer.11.attention.self.key.bias 2.4651072849657396e-11\n",
            "bert_model.encoder.layer.11.attention.self.value.weight 0.0034700229298323393\n",
            "bert_model.encoder.layer.11.attention.self.value.bias 0.000146857273648493\n",
            "bert_model.encoder.layer.11.attention.output.dense.weight 0.004506415221840143\n",
            "bert_model.encoder.layer.11.attention.output.dense.bias 0.00011727825767593458\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.weight 0.00048809527652338147\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.bias 0.00045275295269675553\n",
            "bert_model.encoder.layer.11.intermediate.dense.weight 0.005007321480661631\n",
            "bert_model.encoder.layer.11.intermediate.dense.bias 0.00017991650383919477\n",
            "bert_model.encoder.layer.11.output.dense.weight 0.004723321180790663\n",
            "bert_model.encoder.layer.11.output.dense.bias 0.00040960602927953005\n",
            "bert_model.encoder.layer.11.output.LayerNorm.weight 0.0010336898267269135\n",
            "bert_model.encoder.layer.11.output.LayerNorm.bias 0.0010653253411874175\n",
            "bert_model.pooler.dense.weight 0.04020366445183754\n",
            "bert_model.pooler.dense.bias 0.002378530101850629\n",
            "linear.weight 0.25398093461990356\n",
            "linear.bias 0.008642246015369892\n",
            "\n",
            "  training loss: 0.03\n",
            "  Training epcoh took: 0:00:31\n",
            "  Batch   320  of  1,189.    Elapsed: 0:00:33.\n",
            "bert_model.embeddings.word_embeddings.weight 4.985592454431753e-07\n",
            "bert_model.embeddings.position_embeddings.weight 3.956962189022306e-07\n",
            "bert_model.embeddings.token_type_embeddings.weight 2.994552232848946e-06\n",
            "bert_model.embeddings.LayerNorm.weight 1.5362454064415942e-07\n",
            "bert_model.embeddings.LayerNorm.bias 1.8695754988584667e-07\n",
            "bert_model.encoder.layer.0.attention.self.query.weight 9.388206478888605e-08\n",
            "bert_model.encoder.layer.0.attention.self.query.bias 1.2485519285121427e-08\n",
            "bert_model.encoder.layer.0.attention.self.key.weight 1.1535405519680353e-07\n",
            "bert_model.encoder.layer.0.attention.self.key.bias 1.1998223815439532e-15\n",
            "bert_model.encoder.layer.0.attention.self.value.weight 5.516173473552044e-07\n",
            "bert_model.encoder.layer.0.attention.self.value.bias 1.161004661298648e-07\n",
            "bert_model.encoder.layer.0.attention.output.dense.weight 6.905497684783768e-07\n",
            "bert_model.encoder.layer.0.attention.output.dense.bias 1.0816928863732755e-07\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.weight 5.827385507473082e-08\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.bias 9.163696290670487e-08\n",
            "bert_model.encoder.layer.0.intermediate.dense.weight 1.4463788602370187e-06\n",
            "bert_model.encoder.layer.0.intermediate.dense.bias 6.439807265223862e-08\n",
            "bert_model.encoder.layer.0.output.dense.weight 7.489344966415956e-07\n",
            "bert_model.encoder.layer.0.output.dense.bias 9.400847744700513e-08\n",
            "bert_model.encoder.layer.0.output.LayerNorm.weight 1.3082591010515898e-07\n",
            "bert_model.encoder.layer.0.output.LayerNorm.bias 1.9237312187669886e-07\n",
            "bert_model.encoder.layer.1.attention.self.query.weight 1.6327945218108653e-07\n",
            "bert_model.encoder.layer.1.attention.self.query.bias 1.3076503435627274e-08\n",
            "bert_model.encoder.layer.1.attention.self.key.weight 1.9342904522545723e-07\n",
            "bert_model.encoder.layer.1.attention.self.key.bias 2.8903413255859265e-15\n",
            "bert_model.encoder.layer.1.attention.self.value.weight 1.8929358702735044e-06\n",
            "bert_model.encoder.layer.1.attention.self.value.bias 1.530487736545183e-07\n",
            "bert_model.encoder.layer.1.attention.output.dense.weight 1.9904671262338525e-06\n",
            "bert_model.encoder.layer.1.attention.output.dense.bias 1.1958563561620394e-07\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.weight 1.8078645780406077e-07\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.bias 1.8399236978439149e-07\n",
            "bert_model.encoder.layer.1.intermediate.dense.weight 3.722396968441899e-06\n",
            "bert_model.encoder.layer.1.intermediate.dense.bias 1.112119178969806e-07\n",
            "bert_model.encoder.layer.1.output.dense.weight 2.438943283777917e-06\n",
            "bert_model.encoder.layer.1.output.dense.bias 1.313728716922924e-07\n",
            "bert_model.encoder.layer.1.output.LayerNorm.weight 7.329517188736645e-07\n",
            "bert_model.encoder.layer.1.output.LayerNorm.bias 4.304202434468607e-07\n",
            "bert_model.encoder.layer.2.attention.self.query.weight 7.790330158741199e-08\n",
            "bert_model.encoder.layer.2.attention.self.query.bias 5.311027173604543e-09\n",
            "bert_model.encoder.layer.2.attention.self.key.weight 6.802675045491924e-08\n",
            "bert_model.encoder.layer.2.attention.self.key.bias 1.426249217300723e-15\n",
            "bert_model.encoder.layer.2.attention.self.value.weight 3.995873157691676e-06\n",
            "bert_model.encoder.layer.2.attention.self.value.bias 2.650607200394006e-07\n",
            "bert_model.encoder.layer.2.attention.output.dense.weight 4.318548690207535e-06\n",
            "bert_model.encoder.layer.2.attention.output.dense.bias 2.22429733298668e-07\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.weight 4.342745398844272e-07\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.bias 3.4702682683018793e-07\n",
            "bert_model.encoder.layer.2.intermediate.dense.weight 4.0300569708051626e-06\n",
            "bert_model.encoder.layer.2.intermediate.dense.bias 1.543582470731053e-07\n",
            "bert_model.encoder.layer.2.output.dense.weight 4.214624823362101e-06\n",
            "bert_model.encoder.layer.2.output.dense.bias 1.1160386037545322e-07\n",
            "bert_model.encoder.layer.2.output.LayerNorm.weight 4.5131235992812435e-07\n",
            "bert_model.encoder.layer.2.output.LayerNorm.bias 4.097598207408737e-07\n",
            "bert_model.encoder.layer.3.attention.self.query.weight 1.0259555693892253e-07\n",
            "bert_model.encoder.layer.3.attention.self.query.bias 5.2955364537865535e-09\n",
            "bert_model.encoder.layer.3.attention.self.key.weight 1.060438705735578e-07\n",
            "bert_model.encoder.layer.3.attention.self.key.bias 4.698641259734794e-15\n",
            "bert_model.encoder.layer.3.attention.self.value.weight 6.06665707891807e-06\n",
            "bert_model.encoder.layer.3.attention.self.value.bias 3.1426952773472294e-07\n",
            "bert_model.encoder.layer.3.attention.output.dense.weight 1.0236534762952942e-05\n",
            "bert_model.encoder.layer.3.attention.output.dense.bias 3.456324577655323e-07\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.weight 6.159617100820469e-07\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.bias 5.864480954187457e-07\n",
            "bert_model.encoder.layer.3.intermediate.dense.weight 8.653772056277376e-06\n",
            "bert_model.encoder.layer.3.intermediate.dense.bias 3.5282531030134123e-07\n",
            "bert_model.encoder.layer.3.output.dense.weight 9.670437975728419e-06\n",
            "bert_model.encoder.layer.3.output.dense.bias 5.407429171100375e-07\n",
            "bert_model.encoder.layer.3.output.LayerNorm.weight 7.319611086131772e-07\n",
            "bert_model.encoder.layer.3.output.LayerNorm.bias 8.376005098398309e-07\n",
            "bert_model.encoder.layer.4.attention.self.query.weight 1.556273332425917e-07\n",
            "bert_model.encoder.layer.4.attention.self.query.bias 7.791903122722488e-09\n",
            "bert_model.encoder.layer.4.attention.self.key.weight 2.532393068577221e-07\n",
            "bert_model.encoder.layer.4.attention.self.key.bias 9.492541538783702e-15\n",
            "bert_model.encoder.layer.4.attention.self.value.weight 1.1235805686737876e-05\n",
            "bert_model.encoder.layer.4.attention.self.value.bias 5.655012955685379e-07\n",
            "bert_model.encoder.layer.4.attention.output.dense.weight 1.6995631085592322e-05\n",
            "bert_model.encoder.layer.4.attention.output.dense.bias 5.506405500455003e-07\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.weight 1.2516410379248555e-06\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.bias 1.238884237864113e-06\n",
            "bert_model.encoder.layer.4.intermediate.dense.weight 2.25934709305875e-05\n",
            "bert_model.encoder.layer.4.intermediate.dense.bias 9.141328973782947e-07\n",
            "bert_model.encoder.layer.4.output.dense.weight 1.743775646900758e-05\n",
            "bert_model.encoder.layer.4.output.dense.bias 1.1431786788307363e-06\n",
            "bert_model.encoder.layer.4.output.LayerNorm.weight 1.769647724358947e-06\n",
            "bert_model.encoder.layer.4.output.LayerNorm.bias 1.62841024575755e-06\n",
            "bert_model.encoder.layer.5.attention.self.query.weight 2.0202288908421906e-07\n",
            "bert_model.encoder.layer.5.attention.self.query.bias 9.640057641036037e-09\n",
            "bert_model.encoder.layer.5.attention.self.key.weight 2.8074822466805927e-07\n",
            "bert_model.encoder.layer.5.attention.self.key.bias 1.1529695587478815e-14\n",
            "bert_model.encoder.layer.5.attention.self.value.weight 2.007792681979481e-05\n",
            "bert_model.encoder.layer.5.attention.self.value.bias 9.585730822436744e-07\n",
            "bert_model.encoder.layer.5.attention.output.dense.weight 2.590070289443247e-05\n",
            "bert_model.encoder.layer.5.attention.output.dense.bias 9.069139537132287e-07\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.weight 2.487946858309442e-06\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.bias 2.360844291615649e-06\n",
            "bert_model.encoder.layer.5.intermediate.dense.weight 3.8454549212474376e-05\n",
            "bert_model.encoder.layer.5.intermediate.dense.bias 1.6264197029158822e-06\n",
            "bert_model.encoder.layer.5.output.dense.weight 3.407723124837503e-05\n",
            "bert_model.encoder.layer.5.output.dense.bias 1.7781929955162923e-06\n",
            "bert_model.encoder.layer.5.output.LayerNorm.weight 3.683695922518382e-06\n",
            "bert_model.encoder.layer.5.output.LayerNorm.bias 3.348286099935649e-06\n",
            "bert_model.encoder.layer.6.attention.self.query.weight 3.562524568678782e-07\n",
            "bert_model.encoder.layer.6.attention.self.query.bias 1.6564994709256098e-08\n",
            "bert_model.encoder.layer.6.attention.self.key.weight 4.734498304515e-07\n",
            "bert_model.encoder.layer.6.attention.self.key.bias 1.9664396725001775e-14\n",
            "bert_model.encoder.layer.6.attention.self.value.weight 4.440264092409052e-05\n",
            "bert_model.encoder.layer.6.attention.self.value.bias 2.069405354632181e-06\n",
            "bert_model.encoder.layer.6.attention.output.dense.weight 7.270486821653321e-05\n",
            "bert_model.encoder.layer.6.attention.output.dense.bias 2.2030235413694754e-06\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.weight 6.264679541345686e-06\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.bias 5.999084351060446e-06\n",
            "bert_model.encoder.layer.6.intermediate.dense.weight 8.509996405337006e-05\n",
            "bert_model.encoder.layer.6.intermediate.dense.bias 3.7011875519965542e-06\n",
            "bert_model.encoder.layer.6.output.dense.weight 7.393791747745126e-05\n",
            "bert_model.encoder.layer.6.output.dense.bias 3.6980841287004296e-06\n",
            "bert_model.encoder.layer.6.output.LayerNorm.weight 8.11998779681744e-06\n",
            "bert_model.encoder.layer.6.output.LayerNorm.bias 8.321246241393965e-06\n",
            "bert_model.encoder.layer.7.attention.self.query.weight 6.069320761525887e-07\n",
            "bert_model.encoder.layer.7.attention.self.query.bias 2.8016426512067483e-08\n",
            "bert_model.encoder.layer.7.attention.self.key.weight 8.179056294466136e-07\n",
            "bert_model.encoder.layer.7.attention.self.key.bias 6.190463723229622e-14\n",
            "bert_model.encoder.layer.7.attention.self.value.weight 0.00010217954695690423\n",
            "bert_model.encoder.layer.7.attention.self.value.bias 4.728062322101323e-06\n",
            "bert_model.encoder.layer.7.attention.output.dense.weight 0.000191920276847668\n",
            "bert_model.encoder.layer.7.attention.output.dense.bias 5.339942163118394e-06\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.weight 1.8334982087253593e-05\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.bias 1.8876562535297126e-05\n",
            "bert_model.encoder.layer.7.intermediate.dense.weight 0.00036876180092804134\n",
            "bert_model.encoder.layer.7.intermediate.dense.bias 1.6407750081270933e-05\n",
            "bert_model.encoder.layer.7.output.dense.weight 0.00030804413836449385\n",
            "bert_model.encoder.layer.7.output.dense.bias 7.867090971558355e-06\n",
            "bert_model.encoder.layer.7.output.LayerNorm.weight 3.70668713003397e-05\n",
            "bert_model.encoder.layer.7.output.LayerNorm.bias 3.7913636333541945e-05\n",
            "bert_model.encoder.layer.8.attention.self.query.weight 3.1844604109210195e-06\n",
            "bert_model.encoder.layer.8.attention.self.query.bias 1.474799802281268e-07\n",
            "bert_model.encoder.layer.8.attention.self.key.weight 3.4522831811045762e-06\n",
            "bert_model.encoder.layer.8.attention.self.key.bias 1.5854117606413365e-13\n",
            "bert_model.encoder.layer.8.attention.self.value.weight 0.0004767697537317872\n",
            "bert_model.encoder.layer.8.attention.self.value.bias 2.214787127741147e-05\n",
            "bert_model.encoder.layer.8.attention.output.dense.weight 0.0008194518741220236\n",
            "bert_model.encoder.layer.8.attention.output.dense.bias 2.0543098798952997e-05\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.weight 7.014398579485714e-05\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.bias 6.77344505675137e-05\n",
            "bert_model.encoder.layer.8.intermediate.dense.weight 0.000812369748018682\n",
            "bert_model.encoder.layer.8.intermediate.dense.bias 3.616083267843351e-05\n",
            "bert_model.encoder.layer.8.output.dense.weight 0.0009743977570906281\n",
            "bert_model.encoder.layer.8.output.dense.bias 2.4198643586714752e-05\n",
            "bert_model.encoder.layer.8.output.LayerNorm.weight 8.505882578901947e-05\n",
            "bert_model.encoder.layer.8.output.LayerNorm.bias 9.347994637209922e-05\n",
            "bert_model.encoder.layer.9.attention.self.query.weight 1.117922965931939e-05\n",
            "bert_model.encoder.layer.9.attention.self.query.bias 5.171622206034954e-07\n",
            "bert_model.encoder.layer.9.attention.self.key.weight 1.4282944903243333e-05\n",
            "bert_model.encoder.layer.9.attention.self.key.bias 1.1253978434919154e-12\n",
            "bert_model.encoder.layer.9.attention.self.value.weight 0.0011014543706551194\n",
            "bert_model.encoder.layer.9.attention.self.value.bias 5.177396451472305e-05\n",
            "bert_model.encoder.layer.9.attention.output.dense.weight 0.0016257422976195812\n",
            "bert_model.encoder.layer.9.attention.output.dense.bias 4.945602631778456e-05\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.weight 0.0001311053492827341\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.bias 0.0001349904341623187\n",
            "bert_model.encoder.layer.9.intermediate.dense.weight 0.00087902438826859\n",
            "bert_model.encoder.layer.9.intermediate.dense.bias 3.598458715714514e-05\n",
            "bert_model.encoder.layer.9.output.dense.weight 0.000488713092636317\n",
            "bert_model.encoder.layer.9.output.dense.bias 0.0001214740623254329\n",
            "bert_model.encoder.layer.9.output.LayerNorm.weight 0.0001330544037045911\n",
            "bert_model.encoder.layer.9.output.LayerNorm.bias 0.00014549974002875388\n",
            "bert_model.encoder.layer.10.attention.self.query.weight 1.5401119526359253e-05\n",
            "bert_model.encoder.layer.10.attention.self.query.bias 7.051776265143417e-07\n",
            "bert_model.encoder.layer.10.attention.self.key.weight 2.6705993150244467e-05\n",
            "bert_model.encoder.layer.10.attention.self.key.bias 2.950652092451045e-12\n",
            "bert_model.encoder.layer.10.attention.self.value.weight 0.0018887375481426716\n",
            "bert_model.encoder.layer.10.attention.self.value.bias 8.915571379475296e-05\n",
            "bert_model.encoder.layer.10.attention.output.dense.weight 0.0024289004504680634\n",
            "bert_model.encoder.layer.10.attention.output.dense.bias 8.74136239872314e-05\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.weight 0.00024938659043982625\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.bias 0.00023727827647235245\n",
            "bert_model.encoder.layer.10.intermediate.dense.weight 0.0020074588246643543\n",
            "bert_model.encoder.layer.10.intermediate.dense.bias 8.555614476790652e-05\n",
            "bert_model.encoder.layer.10.output.dense.weight 0.0015619633486494422\n",
            "bert_model.encoder.layer.10.output.dense.bias 0.00022625071869697422\n",
            "bert_model.encoder.layer.10.output.LayerNorm.weight 0.0003346612793393433\n",
            "bert_model.encoder.layer.10.output.LayerNorm.bias 0.00034908202360384166\n",
            "bert_model.encoder.layer.11.attention.self.query.weight 6.977726297918707e-05\n",
            "bert_model.encoder.layer.11.attention.self.query.bias 2.878113718907116e-06\n",
            "bert_model.encoder.layer.11.attention.self.key.weight 0.00012988928938284516\n",
            "bert_model.encoder.layer.11.attention.self.key.bias 3.5865900527287664e-11\n",
            "bert_model.encoder.layer.11.attention.self.value.weight 0.00540077593177557\n",
            "bert_model.encoder.layer.11.attention.self.value.bias 0.00023014120233710855\n",
            "bert_model.encoder.layer.11.attention.output.dense.weight 0.008602012880146503\n",
            "bert_model.encoder.layer.11.attention.output.dense.bias 0.00020219806174281985\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.weight 0.0009686148259788752\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.bias 0.0009792959317564964\n",
            "bert_model.encoder.layer.11.intermediate.dense.weight 0.011706463992595673\n",
            "bert_model.encoder.layer.11.intermediate.dense.bias 0.00043506413931027055\n",
            "bert_model.encoder.layer.11.output.dense.weight 0.010033453814685345\n",
            "bert_model.encoder.layer.11.output.dense.bias 0.0008646130445413291\n",
            "bert_model.encoder.layer.11.output.LayerNorm.weight 0.0023058203514665365\n",
            "bert_model.encoder.layer.11.output.LayerNorm.bias 0.0023394799791276455\n",
            "bert_model.pooler.dense.weight 0.06069638580083847\n",
            "bert_model.pooler.dense.bias 0.003576515940949321\n",
            "linear.weight 0.398773193359375\n",
            "linear.bias 0.014686854556202888\n",
            "\n",
            "  training loss: 0.03\n",
            "  Training epcoh took: 0:00:35\n",
            "  Batch   360  of  1,189.    Elapsed: 0:00:38.\n",
            "bert_model.embeddings.word_embeddings.weight 4.377460811610945e-07\n",
            "bert_model.embeddings.position_embeddings.weight 3.6995567143094377e-07\n",
            "bert_model.embeddings.token_type_embeddings.weight 1.001873101813544e-06\n",
            "bert_model.embeddings.LayerNorm.weight 6.202761682061464e-08\n",
            "bert_model.embeddings.LayerNorm.bias 6.562047616398559e-08\n",
            "bert_model.encoder.layer.0.attention.self.query.weight 7.628513998270137e-08\n",
            "bert_model.encoder.layer.0.attention.self.query.bias 7.63977858753151e-09\n",
            "bert_model.encoder.layer.0.attention.self.key.weight 9.152184077265701e-08\n",
            "bert_model.encoder.layer.0.attention.self.key.bias 1.001617730677631e-15\n",
            "bert_model.encoder.layer.0.attention.self.value.weight 2.932057157067902e-07\n",
            "bert_model.encoder.layer.0.attention.self.value.bias 4.11604510475172e-08\n",
            "bert_model.encoder.layer.0.attention.output.dense.weight 2.8500474513748486e-07\n",
            "bert_model.encoder.layer.0.attention.output.dense.bias 3.861778452574072e-08\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.weight 2.22224390000747e-08\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.bias 3.131597026140298e-08\n",
            "bert_model.encoder.layer.0.intermediate.dense.weight 5.814053452013468e-07\n",
            "bert_model.encoder.layer.0.intermediate.dense.bias 2.0910242426452896e-08\n",
            "bert_model.encoder.layer.0.output.dense.weight 3.050955399430677e-07\n",
            "bert_model.encoder.layer.0.output.dense.bias 3.268122483746083e-08\n",
            "bert_model.encoder.layer.0.output.LayerNorm.weight 5.550720416636068e-08\n",
            "bert_model.encoder.layer.0.output.LayerNorm.bias 6.83039758087034e-08\n",
            "bert_model.encoder.layer.1.attention.self.query.weight 9.985087245922841e-08\n",
            "bert_model.encoder.layer.1.attention.self.query.bias 7.339080454471514e-09\n",
            "bert_model.encoder.layer.1.attention.self.key.weight 1.326667415924021e-07\n",
            "bert_model.encoder.layer.1.attention.self.key.bias 2.706678748116303e-15\n",
            "bert_model.encoder.layer.1.attention.self.value.weight 7.525813998654485e-07\n",
            "bert_model.encoder.layer.1.attention.self.value.bias 5.806334968383453e-08\n",
            "bert_model.encoder.layer.1.attention.output.dense.weight 7.463963811460417e-07\n",
            "bert_model.encoder.layer.1.attention.output.dense.bias 4.5290644123952006e-08\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.weight 6.97485731393499e-08\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.bias 6.804626906387057e-08\n",
            "bert_model.encoder.layer.1.intermediate.dense.weight 1.4557934946424211e-06\n",
            "bert_model.encoder.layer.1.intermediate.dense.bias 4.225285366032949e-08\n",
            "bert_model.encoder.layer.1.output.dense.weight 9.709860933071468e-07\n",
            "bert_model.encoder.layer.1.output.dense.bias 4.7424975946341874e-08\n",
            "bert_model.encoder.layer.1.output.LayerNorm.weight 3.4441782759131456e-07\n",
            "bert_model.encoder.layer.1.output.LayerNorm.bias 1.7522474138331745e-07\n",
            "bert_model.encoder.layer.2.attention.self.query.weight 5.499691368981985e-08\n",
            "bert_model.encoder.layer.2.attention.self.query.bias 3.948215976379288e-09\n",
            "bert_model.encoder.layer.2.attention.self.key.weight 5.644079692501691e-08\n",
            "bert_model.encoder.layer.2.attention.self.key.bias 1.9369011348822256e-15\n",
            "bert_model.encoder.layer.2.attention.self.value.weight 1.5736962950541056e-06\n",
            "bert_model.encoder.layer.2.attention.self.value.bias 1.0662351002110881e-07\n",
            "bert_model.encoder.layer.2.attention.output.dense.weight 1.7880034874906414e-06\n",
            "bert_model.encoder.layer.2.attention.output.dense.bias 9.254551258663923e-08\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.weight 1.8463438777871488e-07\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.bias 1.3466635095937818e-07\n",
            "bert_model.encoder.layer.2.intermediate.dense.weight 1.346113322142628e-06\n",
            "bert_model.encoder.layer.2.intermediate.dense.bias 5.1319428706619874e-08\n",
            "bert_model.encoder.layer.2.output.dense.weight 1.4668029280073824e-06\n",
            "bert_model.encoder.layer.2.output.dense.bias 3.4553266914372216e-08\n",
            "bert_model.encoder.layer.2.output.LayerNorm.weight 1.7124510520716285e-07\n",
            "bert_model.encoder.layer.2.output.LayerNorm.bias 1.4801064196490188e-07\n",
            "bert_model.encoder.layer.3.attention.self.query.weight 5.8724889839822936e-08\n",
            "bert_model.encoder.layer.3.attention.self.query.bias 2.9902904596923463e-09\n",
            "bert_model.encoder.layer.3.attention.self.key.weight 8.892125435977505e-08\n",
            "bert_model.encoder.layer.3.attention.self.key.bias 4.108338493079115e-15\n",
            "bert_model.encoder.layer.3.attention.self.value.weight 2.1276848656270886e-06\n",
            "bert_model.encoder.layer.3.attention.self.value.bias 1.0848800258145275e-07\n",
            "bert_model.encoder.layer.3.attention.output.dense.weight 3.506286475385423e-06\n",
            "bert_model.encoder.layer.3.attention.output.dense.bias 1.1621148843232731e-07\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.weight 2.09887218716176e-07\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.bias 1.973311469782857e-07\n",
            "bert_model.encoder.layer.3.intermediate.dense.weight 3.023825001946534e-06\n",
            "bert_model.encoder.layer.3.intermediate.dense.bias 1.2262076154456736e-07\n",
            "bert_model.encoder.layer.3.output.dense.weight 3.013820105479681e-06\n",
            "bert_model.encoder.layer.3.output.dense.bias 1.8442311500166397e-07\n",
            "bert_model.encoder.layer.3.output.LayerNorm.weight 2.3236100332724163e-07\n",
            "bert_model.encoder.layer.3.output.LayerNorm.bias 2.6113531248483923e-07\n",
            "bert_model.encoder.layer.4.attention.self.query.weight 1.0242286663242339e-07\n",
            "bert_model.encoder.layer.4.attention.self.query.bias 5.131369995581281e-09\n",
            "bert_model.encoder.layer.4.attention.self.key.weight 1.780453544597549e-07\n",
            "bert_model.encoder.layer.4.attention.self.key.bias 8.409601445389606e-15\n",
            "bert_model.encoder.layer.4.attention.self.value.weight 3.6050516882824013e-06\n",
            "bert_model.encoder.layer.4.attention.self.value.bias 1.7986988609663968e-07\n",
            "bert_model.encoder.layer.4.attention.output.dense.weight 5.1055089898000006e-06\n",
            "bert_model.encoder.layer.4.attention.output.dense.bias 1.6923618773034832e-07\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.weight 3.296317174772412e-07\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.bias 3.331566631459282e-07\n",
            "bert_model.encoder.layer.4.intermediate.dense.weight 6.14441114521469e-06\n",
            "bert_model.encoder.layer.4.intermediate.dense.bias 2.5281906346208416e-07\n",
            "bert_model.encoder.layer.4.output.dense.weight 4.78344827570254e-06\n",
            "bert_model.encoder.layer.4.output.dense.bias 2.7621805998023774e-07\n",
            "bert_model.encoder.layer.4.output.LayerNorm.weight 4.0929955957835773e-07\n",
            "bert_model.encoder.layer.4.output.LayerNorm.bias 3.8544774838555895e-07\n",
            "bert_model.encoder.layer.5.attention.self.query.weight 1.2731878484828485e-07\n",
            "bert_model.encoder.layer.5.attention.self.query.bias 6.0875446905583885e-09\n",
            "bert_model.encoder.layer.5.attention.self.key.weight 2.030933785590605e-07\n",
            "bert_model.encoder.layer.5.attention.self.key.bias 5.431051590984275e-15\n",
            "bert_model.encoder.layer.5.attention.self.value.weight 4.6811373977107e-06\n",
            "bert_model.encoder.layer.5.attention.self.value.bias 2.2492936579965317e-07\n",
            "bert_model.encoder.layer.5.attention.output.dense.weight 5.657072051690193e-06\n",
            "bert_model.encoder.layer.5.attention.output.dense.bias 2.016547142602576e-07\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.weight 5.419622084446019e-07\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.bias 5.14515647864755e-07\n",
            "bert_model.encoder.layer.5.intermediate.dense.weight 7.969561011123005e-06\n",
            "bert_model.encoder.layer.5.intermediate.dense.bias 3.3697537560328783e-07\n",
            "bert_model.encoder.layer.5.output.dense.weight 7.362839369307039e-06\n",
            "bert_model.encoder.layer.5.output.dense.bias 3.773273533624888e-07\n",
            "bert_model.encoder.layer.5.output.LayerNorm.weight 7.025481636446784e-07\n",
            "bert_model.encoder.layer.5.output.LayerNorm.bias 6.764482236576441e-07\n",
            "bert_model.encoder.layer.6.attention.self.query.weight 1.6535535962702852e-07\n",
            "bert_model.encoder.layer.6.attention.self.query.bias 7.672193547136885e-09\n",
            "bert_model.encoder.layer.6.attention.self.key.weight 2.4992229441522795e-07\n",
            "bert_model.encoder.layer.6.attention.self.key.bias 1.6188651236052377e-14\n",
            "bert_model.encoder.layer.6.attention.self.value.weight 9.326800864073448e-06\n",
            "bert_model.encoder.layer.6.attention.self.value.bias 4.3437424324110907e-07\n",
            "bert_model.encoder.layer.6.attention.output.dense.weight 1.5439693015650846e-05\n",
            "bert_model.encoder.layer.6.attention.output.dense.bias 4.5980317509020097e-07\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.weight 1.3798315876556444e-06\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.bias 1.330987743131118e-06\n",
            "bert_model.encoder.layer.6.intermediate.dense.weight 2.048127498710528e-05\n",
            "bert_model.encoder.layer.6.intermediate.dense.bias 8.873666956787929e-07\n",
            "bert_model.encoder.layer.6.output.dense.weight 1.8955346604343504e-05\n",
            "bert_model.encoder.layer.6.output.dense.bias 9.317544709119829e-07\n",
            "bert_model.encoder.layer.6.output.LayerNorm.weight 2.2856534087623004e-06\n",
            "bert_model.encoder.layer.6.output.LayerNorm.bias 2.2321530650515342e-06\n",
            "bert_model.encoder.layer.7.attention.self.query.weight 3.061933853132359e-07\n",
            "bert_model.encoder.layer.7.attention.self.query.bias 1.4121451563653409e-08\n",
            "bert_model.encoder.layer.7.attention.self.key.weight 4.4465463133747107e-07\n",
            "bert_model.encoder.layer.7.attention.self.key.bias 2.63299039689191e-14\n",
            "bert_model.encoder.layer.7.attention.self.value.weight 2.7174166461918503e-05\n",
            "bert_model.encoder.layer.7.attention.self.value.bias 1.2595324960784637e-06\n",
            "bert_model.encoder.layer.7.attention.output.dense.weight 5.216003046371043e-05\n",
            "bert_model.encoder.layer.7.attention.output.dense.bias 1.403602368554857e-06\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.weight 5.214648808760103e-06\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.bias 5.131314537720755e-06\n",
            "bert_model.encoder.layer.7.intermediate.dense.weight 8.616692502982914e-05\n",
            "bert_model.encoder.layer.7.intermediate.dense.bias 3.822323378699366e-06\n",
            "bert_model.encoder.layer.7.output.dense.weight 8.219611481763422e-05\n",
            "bert_model.encoder.layer.7.output.dense.bias 2.0747611415572464e-06\n",
            "bert_model.encoder.layer.7.output.LayerNorm.weight 9.791754564503208e-06\n",
            "bert_model.encoder.layer.7.output.LayerNorm.bias 1.002129283733666e-05\n",
            "bert_model.encoder.layer.8.attention.self.query.weight 1.5551405567748589e-06\n",
            "bert_model.encoder.layer.8.attention.self.query.bias 7.182798356097919e-08\n",
            "bert_model.encoder.layer.8.attention.self.key.weight 1.8583197061161627e-06\n",
            "bert_model.encoder.layer.8.attention.self.key.bias 1.2256592496571322e-13\n",
            "bert_model.encoder.layer.8.attention.self.value.weight 0.00012871751096099615\n",
            "bert_model.encoder.layer.8.attention.self.value.bias 5.991894795442931e-06\n",
            "bert_model.encoder.layer.8.attention.output.dense.weight 0.00023761481861583889\n",
            "bert_model.encoder.layer.8.attention.output.dense.bias 5.741625500377268e-06\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.weight 2.1182519049034454e-05\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.bias 2.1048492271802388e-05\n",
            "bert_model.encoder.layer.8.intermediate.dense.weight 0.00027694908203557134\n",
            "bert_model.encoder.layer.8.intermediate.dense.bias 1.2226081707922276e-05\n",
            "bert_model.encoder.layer.8.output.dense.weight 0.00033121605520136654\n",
            "bert_model.encoder.layer.8.output.dense.bias 8.70684289111523e-06\n",
            "bert_model.encoder.layer.8.output.LayerNorm.weight 3.028071478183847e-05\n",
            "bert_model.encoder.layer.8.output.LayerNorm.bias 3.316871516290121e-05\n",
            "bert_model.encoder.layer.9.attention.self.query.weight 6.369094080582727e-06\n",
            "bert_model.encoder.layer.9.attention.self.query.bias 2.919672681400698e-07\n",
            "bert_model.encoder.layer.9.attention.self.key.weight 8.73056342243217e-06\n",
            "bert_model.encoder.layer.9.attention.self.key.bias 6.564696702904271e-13\n",
            "bert_model.encoder.layer.9.attention.self.value.weight 0.00038969313027337193\n",
            "bert_model.encoder.layer.9.attention.self.value.bias 1.828362474043388e-05\n",
            "bert_model.encoder.layer.9.attention.output.dense.weight 0.0006411861395463347\n",
            "bert_model.encoder.layer.9.attention.output.dense.bias 1.880123272712808e-05\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.weight 5.167954441276379e-05\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.bias 5.583560778177343e-05\n",
            "bert_model.encoder.layer.9.intermediate.dense.weight 0.0003390961210243404\n",
            "bert_model.encoder.layer.9.intermediate.dense.bias 1.3826492249791045e-05\n",
            "bert_model.encoder.layer.9.output.dense.weight 0.00019349461945239455\n",
            "bert_model.encoder.layer.9.output.dense.bias 5.4176889534574e-05\n",
            "bert_model.encoder.layer.9.output.LayerNorm.weight 6.41287406324409e-05\n",
            "bert_model.encoder.layer.9.output.LayerNorm.bias 6.561431655427441e-05\n",
            "bert_model.encoder.layer.10.attention.self.query.weight 9.792481250769924e-06\n",
            "bert_model.encoder.layer.10.attention.self.query.bias 4.42400192923742e-07\n",
            "bert_model.encoder.layer.10.attention.self.key.weight 1.7918553567142226e-05\n",
            "bert_model.encoder.layer.10.attention.self.key.bias 3.0643103072353073e-12\n",
            "bert_model.encoder.layer.10.attention.self.value.weight 0.0009663196397013962\n",
            "bert_model.encoder.layer.10.attention.self.value.bias 4.525964322965592e-05\n",
            "bert_model.encoder.layer.10.attention.output.dense.weight 0.001322070718742907\n",
            "bert_model.encoder.layer.10.attention.output.dense.bias 4.321055530454032e-05\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.weight 0.00016393944679293782\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.bias 0.00013425826909951866\n",
            "bert_model.encoder.layer.10.intermediate.dense.weight 0.0014949642354622483\n",
            "bert_model.encoder.layer.10.intermediate.dense.bias 6.430968642234802e-05\n",
            "bert_model.encoder.layer.10.output.dense.weight 0.001047252444550395\n",
            "bert_model.encoder.layer.10.output.dense.bias 0.00011811632430180907\n",
            "bert_model.encoder.layer.10.output.LayerNorm.weight 0.0001948177523445338\n",
            "bert_model.encoder.layer.10.output.LayerNorm.bias 0.00019962976512033492\n",
            "bert_model.encoder.layer.11.attention.self.query.weight 6.0105729062343016e-05\n",
            "bert_model.encoder.layer.11.attention.self.query.bias 2.5017325242515653e-06\n",
            "bert_model.encoder.layer.11.attention.self.key.weight 0.00011611119407461956\n",
            "bert_model.encoder.layer.11.attention.self.key.bias 3.621846225709824e-11\n",
            "bert_model.encoder.layer.11.attention.self.value.weight 0.0032150615006685257\n",
            "bert_model.encoder.layer.11.attention.self.value.bias 0.00013839472376275808\n",
            "bert_model.encoder.layer.11.attention.output.dense.weight 0.0047278753481805325\n",
            "bert_model.encoder.layer.11.attention.output.dense.bias 0.00010518099588807672\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.weight 0.0005616057314909995\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.bias 0.0005351254949346185\n",
            "bert_model.encoder.layer.11.intermediate.dense.weight 0.006357522215694189\n",
            "bert_model.encoder.layer.11.intermediate.dense.bias 0.00023654039250686765\n",
            "bert_model.encoder.layer.11.output.dense.weight 0.005730052012950182\n",
            "bert_model.encoder.layer.11.output.dense.bias 0.0004685011808760464\n",
            "bert_model.encoder.layer.11.output.LayerNorm.weight 0.0012119343737140298\n",
            "bert_model.encoder.layer.11.output.LayerNorm.bias 0.0012197545729577541\n",
            "bert_model.pooler.dense.weight 0.03579111769795418\n",
            "bert_model.pooler.dense.bias 0.0020741287153214216\n",
            "linear.weight 0.2829867899417877\n",
            "linear.bias 0.00966491550207138\n",
            "\n",
            "  training loss: 0.03\n",
            "  Training epcoh took: 0:00:40\n",
            "  Batch   400  of  1,189.    Elapsed: 0:00:42.\n",
            "bert_model.embeddings.word_embeddings.weight 2.625241393161559e-07\n",
            "bert_model.embeddings.position_embeddings.weight 2.5239492629225424e-07\n",
            "bert_model.embeddings.token_type_embeddings.weight 1.084014115804166e-06\n",
            "bert_model.embeddings.LayerNorm.weight 6.367029214970898e-08\n",
            "bert_model.embeddings.LayerNorm.bias 7.095112408705972e-08\n",
            "bert_model.encoder.layer.0.attention.self.query.weight 5.04097066311715e-08\n",
            "bert_model.encoder.layer.0.attention.self.query.bias 6.603796176563037e-09\n",
            "bert_model.encoder.layer.0.attention.self.key.weight 6.147484299390271e-08\n",
            "bert_model.encoder.layer.0.attention.self.key.bias 6.494374189561724e-16\n",
            "bert_model.encoder.layer.0.attention.self.value.weight 2.575143298599869e-07\n",
            "bert_model.encoder.layer.0.attention.self.value.bias 4.319699797861176e-08\n",
            "bert_model.encoder.layer.0.attention.output.dense.weight 2.4666900344527676e-07\n",
            "bert_model.encoder.layer.0.attention.output.dense.bias 3.421321181917847e-08\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.weight 1.995542575627951e-08\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.bias 2.8690621434179775e-08\n",
            "bert_model.encoder.layer.0.intermediate.dense.weight 5.49954165762756e-07\n",
            "bert_model.encoder.layer.0.intermediate.dense.bias 2.133528198555723e-08\n",
            "bert_model.encoder.layer.0.output.dense.weight 2.6022942734016397e-07\n",
            "bert_model.encoder.layer.0.output.dense.bias 2.2087094819767117e-08\n",
            "bert_model.encoder.layer.0.output.LayerNorm.weight 3.5258540975746655e-08\n",
            "bert_model.encoder.layer.0.output.LayerNorm.bias 4.811186116171484e-08\n",
            "bert_model.encoder.layer.1.attention.self.query.weight 5.3102038322094813e-08\n",
            "bert_model.encoder.layer.1.attention.self.query.bias 3.997407738154379e-09\n",
            "bert_model.encoder.layer.1.attention.self.key.weight 7.146679337211026e-08\n",
            "bert_model.encoder.layer.1.attention.self.key.bias 1.2542252960428472e-15\n",
            "bert_model.encoder.layer.1.attention.self.value.weight 4.19614764268772e-07\n",
            "bert_model.encoder.layer.1.attention.self.value.bias 3.223863487278322e-08\n",
            "bert_model.encoder.layer.1.attention.output.dense.weight 3.969303179474082e-07\n",
            "bert_model.encoder.layer.1.attention.output.dense.bias 2.388304842781963e-08\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.weight 3.7895901527917886e-08\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.bias 3.634202982993884e-08\n",
            "bert_model.encoder.layer.1.intermediate.dense.weight 8.109271334433288e-07\n",
            "bert_model.encoder.layer.1.intermediate.dense.bias 2.2972685087552236e-08\n",
            "bert_model.encoder.layer.1.output.dense.weight 5.578704076469876e-07\n",
            "bert_model.encoder.layer.1.output.dense.bias 2.419688449606383e-08\n",
            "bert_model.encoder.layer.1.output.LayerNorm.weight 1.9301394615922618e-07\n",
            "bert_model.encoder.layer.1.output.LayerNorm.bias 1.0418477813800564e-07\n",
            "bert_model.encoder.layer.2.attention.self.query.weight 2.6086134141678485e-08\n",
            "bert_model.encoder.layer.2.attention.self.query.bias 1.8051662387108536e-09\n",
            "bert_model.encoder.layer.2.attention.self.key.weight 2.7934765611803414e-08\n",
            "bert_model.encoder.layer.2.attention.self.key.bias 6.947083653715993e-16\n",
            "bert_model.encoder.layer.2.attention.self.value.weight 8.868177019394352e-07\n",
            "bert_model.encoder.layer.2.attention.self.value.bias 6.1979022802916e-08\n",
            "bert_model.encoder.layer.2.attention.output.dense.weight 1.0148215778826852e-06\n",
            "bert_model.encoder.layer.2.attention.output.dense.bias 5.3868856042527113e-08\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.weight 1.0014223050802684e-07\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.bias 7.850949401699836e-08\n",
            "bert_model.encoder.layer.2.intermediate.dense.weight 7.840568514438928e-07\n",
            "bert_model.encoder.layer.2.intermediate.dense.bias 3.014513794141749e-08\n",
            "bert_model.encoder.layer.2.output.dense.weight 8.174015988515748e-07\n",
            "bert_model.encoder.layer.2.output.dense.bias 1.7830327436740845e-08\n",
            "bert_model.encoder.layer.2.output.LayerNorm.weight 1.0406903072635032e-07\n",
            "bert_model.encoder.layer.2.output.LayerNorm.bias 8.62348272789859e-08\n",
            "bert_model.encoder.layer.3.attention.self.query.weight 3.925066849319592e-08\n",
            "bert_model.encoder.layer.3.attention.self.query.bias 1.9924846217378445e-09\n",
            "bert_model.encoder.layer.3.attention.self.key.weight 5.117549051192327e-08\n",
            "bert_model.encoder.layer.3.attention.self.key.bias 2.190697193351558e-15\n",
            "bert_model.encoder.layer.3.attention.self.value.weight 1.1879568546646624e-06\n",
            "bert_model.encoder.layer.3.attention.self.value.bias 6.027978827205516e-08\n",
            "bert_model.encoder.layer.3.attention.output.dense.weight 1.8075106709147803e-06\n",
            "bert_model.encoder.layer.3.attention.output.dense.bias 6.049480560932352e-08\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.weight 1.050820515047235e-07\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.bias 1.034138108479965e-07\n",
            "bert_model.encoder.layer.3.intermediate.dense.weight 1.610546405572677e-06\n",
            "bert_model.encoder.layer.3.intermediate.dense.bias 6.405249308727434e-08\n",
            "bert_model.encoder.layer.3.output.dense.weight 1.4432797570407274e-06\n",
            "bert_model.encoder.layer.3.output.dense.bias 9.553794910743818e-08\n",
            "bert_model.encoder.layer.3.output.LayerNorm.weight 1.1929087406770122e-07\n",
            "bert_model.encoder.layer.3.output.LayerNorm.bias 1.3326429382232163e-07\n",
            "bert_model.encoder.layer.4.attention.self.query.weight 4.4274742094785324e-08\n",
            "bert_model.encoder.layer.4.attention.self.query.bias 2.2319128767378515e-09\n",
            "bert_model.encoder.layer.4.attention.self.key.weight 8.512323290688073e-08\n",
            "bert_model.encoder.layer.4.attention.self.key.bias 4.170123617350686e-15\n",
            "bert_model.encoder.layer.4.attention.self.value.weight 1.7151385236502392e-06\n",
            "bert_model.encoder.layer.4.attention.self.value.bias 8.725474032189595e-08\n",
            "bert_model.encoder.layer.4.attention.output.dense.weight 2.3675486318097683e-06\n",
            "bert_model.encoder.layer.4.attention.output.dense.bias 8.290489716955562e-08\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.weight 1.588287545928324e-07\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.bias 1.554749644583353e-07\n",
            "bert_model.encoder.layer.4.intermediate.dense.weight 2.930932623712579e-06\n",
            "bert_model.encoder.layer.4.intermediate.dense.bias 1.2175233621292136e-07\n",
            "bert_model.encoder.layer.4.output.dense.weight 2.2591123070014874e-06\n",
            "bert_model.encoder.layer.4.output.dense.bias 1.3545532340231148e-07\n",
            "bert_model.encoder.layer.4.output.LayerNorm.weight 2.1617859147227136e-07\n",
            "bert_model.encoder.layer.4.output.LayerNorm.bias 1.9663194450458832e-07\n",
            "bert_model.encoder.layer.5.attention.self.query.weight 5.598347030399964e-08\n",
            "bert_model.encoder.layer.5.attention.self.query.bias 2.6895754512423764e-09\n",
            "bert_model.encoder.layer.5.attention.self.key.weight 8.366070147758364e-08\n",
            "bert_model.encoder.layer.5.attention.self.key.bias 1.7127844756099735e-15\n",
            "bert_model.encoder.layer.5.attention.self.value.weight 2.264332806589664e-06\n",
            "bert_model.encoder.layer.5.attention.self.value.bias 1.1002918398617112e-07\n",
            "bert_model.encoder.layer.5.attention.output.dense.weight 2.7435567062639166e-06\n",
            "bert_model.encoder.layer.5.attention.output.dense.bias 9.470752360130064e-08\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.weight 2.864049406525737e-07\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.bias 2.59948251368769e-07\n",
            "bert_model.encoder.layer.5.intermediate.dense.weight 3.874679805448977e-06\n",
            "bert_model.encoder.layer.5.intermediate.dense.bias 1.644546614443243e-07\n",
            "bert_model.encoder.layer.5.output.dense.weight 3.435524149608682e-06\n",
            "bert_model.encoder.layer.5.output.dense.bias 1.6293461158056743e-07\n",
            "bert_model.encoder.layer.5.output.LayerNorm.weight 3.143739775168797e-07\n",
            "bert_model.encoder.layer.5.output.LayerNorm.bias 3.18244900654463e-07\n",
            "bert_model.encoder.layer.6.attention.self.query.weight 7.155998815733255e-08\n",
            "bert_model.encoder.layer.6.attention.self.query.bias 3.321906749675918e-09\n",
            "bert_model.encoder.layer.6.attention.self.key.weight 1.0977394993005873e-07\n",
            "bert_model.encoder.layer.6.attention.self.key.bias 4.325708746684724e-15\n",
            "bert_model.encoder.layer.6.attention.self.value.weight 4.4190014705236536e-06\n",
            "bert_model.encoder.layer.6.attention.self.value.bias 2.0676894507687393e-07\n",
            "bert_model.encoder.layer.6.attention.output.dense.weight 7.3654859988891985e-06\n",
            "bert_model.encoder.layer.6.attention.output.dense.bias 2.1165669750189409e-07\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.weight 6.362760700540093e-07\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.bias 6.521794375657919e-07\n",
            "bert_model.encoder.layer.6.intermediate.dense.weight 1.0181134712183848e-05\n",
            "bert_model.encoder.layer.6.intermediate.dense.bias 4.4029937384948425e-07\n",
            "bert_model.encoder.layer.6.output.dense.weight 9.073506589629687e-06\n",
            "bert_model.encoder.layer.6.output.dense.bias 4.3621739109767077e-07\n",
            "bert_model.encoder.layer.6.output.LayerNorm.weight 1.1082714763688273e-06\n",
            "bert_model.encoder.layer.6.output.LayerNorm.bias 1.0750516139523825e-06\n",
            "bert_model.encoder.layer.7.attention.self.query.weight 1.645825307150517e-07\n",
            "bert_model.encoder.layer.7.attention.self.query.bias 7.598878859482738e-09\n",
            "bert_model.encoder.layer.7.attention.self.key.weight 2.2637304653017054e-07\n",
            "bert_model.encoder.layer.7.attention.self.key.bias 1.3139049716932513e-14\n",
            "bert_model.encoder.layer.7.attention.self.value.weight 1.3200432476878632e-05\n",
            "bert_model.encoder.layer.7.attention.self.value.bias 6.131116379037849e-07\n",
            "bert_model.encoder.layer.7.attention.output.dense.weight 2.580122963991016e-05\n",
            "bert_model.encoder.layer.7.attention.output.dense.bias 6.737749345120392e-07\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.weight 2.55281588579237e-06\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.bias 2.592006921986467e-06\n",
            "bert_model.encoder.layer.7.intermediate.dense.weight 4.388329398352653e-05\n",
            "bert_model.encoder.layer.7.intermediate.dense.bias 1.9389306089578895e-06\n",
            "bert_model.encoder.layer.7.output.dense.weight 4.144372360315174e-05\n",
            "bert_model.encoder.layer.7.output.dense.bias 1.0224031257166644e-06\n",
            "bert_model.encoder.layer.7.output.LayerNorm.weight 5.155388407729333e-06\n",
            "bert_model.encoder.layer.7.output.LayerNorm.bias 5.364756361814216e-06\n",
            "bert_model.encoder.layer.8.attention.self.query.weight 7.700870128246606e-07\n",
            "bert_model.encoder.layer.8.attention.self.query.bias 3.549839888705719e-08\n",
            "bert_model.encoder.layer.8.attention.self.key.weight 9.809502898860956e-07\n",
            "bert_model.encoder.layer.8.attention.self.key.bias 9.176451373944794e-14\n",
            "bert_model.encoder.layer.8.attention.self.value.weight 6.879481225041673e-05\n",
            "bert_model.encoder.layer.8.attention.self.value.bias 3.203218739145086e-06\n",
            "bert_model.encoder.layer.8.attention.output.dense.weight 0.0001317119604209438\n",
            "bert_model.encoder.layer.8.attention.output.dense.bias 3.0788648928137263e-06\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.weight 1.169495953945443e-05\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.bias 1.2069860531482846e-05\n",
            "bert_model.encoder.layer.8.intermediate.dense.weight 0.00015212951984722167\n",
            "bert_model.encoder.layer.8.intermediate.dense.bias 6.672581548627932e-06\n",
            "bert_model.encoder.layer.8.output.dense.weight 0.00021395621297415346\n",
            "bert_model.encoder.layer.8.output.dense.bias 5.865654202352744e-06\n",
            "bert_model.encoder.layer.8.output.LayerNorm.weight 1.9775663531618193e-05\n",
            "bert_model.encoder.layer.8.output.LayerNorm.bias 2.2388063371181488e-05\n",
            "bert_model.encoder.layer.9.attention.self.query.weight 3.907608061126666e-06\n",
            "bert_model.encoder.layer.9.attention.self.query.bias 1.775229065970052e-07\n",
            "bert_model.encoder.layer.9.attention.self.key.weight 5.877327566849999e-06\n",
            "bert_model.encoder.layer.9.attention.self.key.bias 4.971580872675796e-13\n",
            "bert_model.encoder.layer.9.attention.self.value.weight 0.00026459485525265336\n",
            "bert_model.encoder.layer.9.attention.self.value.bias 1.2385292393446434e-05\n",
            "bert_model.encoder.layer.9.attention.output.dense.weight 0.000481979688629508\n",
            "bert_model.encoder.layer.9.attention.output.dense.bias 1.370340851281071e-05\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.weight 4.075104880030267e-05\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.bias 4.314369289204478e-05\n",
            "bert_model.encoder.layer.9.intermediate.dense.weight 0.0002701232151594013\n",
            "bert_model.encoder.layer.9.intermediate.dense.bias 1.0956655387417413e-05\n",
            "bert_model.encoder.layer.9.output.dense.weight 0.00014622259186580777\n",
            "bert_model.encoder.layer.9.output.dense.bias 4.301595254219137e-05\n",
            "bert_model.encoder.layer.9.output.LayerNorm.weight 4.981158781447448e-05\n",
            "bert_model.encoder.layer.9.output.LayerNorm.bias 5.251359107205644e-05\n",
            "bert_model.encoder.layer.10.attention.self.query.weight 8.234844244725537e-06\n",
            "bert_model.encoder.layer.10.attention.self.query.bias 3.703358686379943e-07\n",
            "bert_model.encoder.layer.10.attention.self.key.weight 1.3321614460437559e-05\n",
            "bert_model.encoder.layer.10.attention.self.key.bias 2.013105827869399e-12\n",
            "bert_model.encoder.layer.10.attention.self.value.weight 0.0006693911855109036\n",
            "bert_model.encoder.layer.10.attention.self.value.bias 3.116166408290155e-05\n",
            "bert_model.encoder.layer.10.attention.output.dense.weight 0.0010589729063212872\n",
            "bert_model.encoder.layer.10.attention.output.dense.bias 3.2023795938584954e-05\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.weight 0.00012213144509587437\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.bias 0.00011378734780009836\n",
            "bert_model.encoder.layer.10.intermediate.dense.weight 0.0011392846936360002\n",
            "bert_model.encoder.layer.10.intermediate.dense.bias 4.8750451242085546e-05\n",
            "bert_model.encoder.layer.10.output.dense.weight 0.0011378267081454396\n",
            "bert_model.encoder.layer.10.output.dense.bias 0.00010540877701714635\n",
            "bert_model.encoder.layer.10.output.LayerNorm.weight 0.00017885038687381893\n",
            "bert_model.encoder.layer.10.output.LayerNorm.bias 0.00018644060764927417\n",
            "bert_model.encoder.layer.11.attention.self.query.weight 6.422697333618999e-05\n",
            "bert_model.encoder.layer.11.attention.self.query.bias 2.6922468805423705e-06\n",
            "bert_model.encoder.layer.11.attention.self.key.weight 0.00012056831474183127\n",
            "bert_model.encoder.layer.11.attention.self.key.bias 2.292978827644898e-11\n",
            "bert_model.encoder.layer.11.attention.self.value.weight 0.0026604519225656986\n",
            "bert_model.encoder.layer.11.attention.self.value.bias 0.00011510269541759044\n",
            "bert_model.encoder.layer.11.attention.output.dense.weight 0.005128823686391115\n",
            "bert_model.encoder.layer.11.attention.output.dense.bias 0.00011023285333067179\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.weight 0.0005990591598674655\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.bias 0.0006002570735290647\n",
            "bert_model.encoder.layer.11.intermediate.dense.weight 0.007570488378405571\n",
            "bert_model.encoder.layer.11.intermediate.dense.bias 0.0002819825313054025\n",
            "bert_model.encoder.layer.11.output.dense.weight 0.007519355043768883\n",
            "bert_model.encoder.layer.11.output.dense.bias 0.0005684580537490547\n",
            "bert_model.encoder.layer.11.output.LayerNorm.weight 0.0014542111894115806\n",
            "bert_model.encoder.layer.11.output.LayerNorm.bias 0.0015186488162726164\n",
            "bert_model.pooler.dense.weight 0.039060741662979126\n",
            "bert_model.pooler.dense.bias 0.0022815647535026073\n",
            "linear.weight 0.2835735082626343\n",
            "linear.bias 0.009708819910883904\n",
            "\n",
            "  training loss: 0.03\n",
            "  Training epcoh took: 0:00:43\n",
            "  Batch   440  of  1,189.    Elapsed: 0:00:45.\n",
            "bert_model.embeddings.word_embeddings.weight 1.466564185648167e-07\n",
            "bert_model.embeddings.position_embeddings.weight 1.0627637436755322e-07\n",
            "bert_model.embeddings.token_type_embeddings.weight 4.780559947903384e-07\n",
            "bert_model.embeddings.LayerNorm.weight 2.0078823936842127e-08\n",
            "bert_model.embeddings.LayerNorm.bias 3.048115715387212e-08\n",
            "bert_model.encoder.layer.0.attention.self.query.weight 2.9942146539951864e-08\n",
            "bert_model.encoder.layer.0.attention.self.query.bias 3.5581741997248173e-09\n",
            "bert_model.encoder.layer.0.attention.self.key.weight 3.398962178380316e-08\n",
            "bert_model.encoder.layer.0.attention.self.key.bias 4.178528672346731e-16\n",
            "bert_model.encoder.layer.0.attention.self.value.weight 1.2092932877294515e-07\n",
            "bert_model.encoder.layer.0.attention.self.value.bias 1.8970876425328242e-08\n",
            "bert_model.encoder.layer.0.attention.output.dense.weight 1.4365356548751151e-07\n",
            "bert_model.encoder.layer.0.attention.output.dense.bias 1.675448402238544e-08\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.weight 1.2088404055532465e-08\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.bias 1.5195453784144775e-08\n",
            "bert_model.encoder.layer.0.intermediate.dense.weight 3.048526764359849e-07\n",
            "bert_model.encoder.layer.0.intermediate.dense.bias 1.1449124315277004e-08\n",
            "bert_model.encoder.layer.0.output.dense.weight 1.8931662282284378e-07\n",
            "bert_model.encoder.layer.0.output.dense.bias 1.3493468564718114e-08\n",
            "bert_model.encoder.layer.0.output.LayerNorm.weight 2.3942487104022803e-08\n",
            "bert_model.encoder.layer.0.output.LayerNorm.bias 3.064520015527705e-08\n",
            "bert_model.encoder.layer.1.attention.self.query.weight 3.840793283416133e-08\n",
            "bert_model.encoder.layer.1.attention.self.query.bias 2.7582742756493417e-09\n",
            "bert_model.encoder.layer.1.attention.self.key.weight 4.824115151791375e-08\n",
            "bert_model.encoder.layer.1.attention.self.key.bias 1.1352545422824156e-15\n",
            "bert_model.encoder.layer.1.attention.self.value.weight 3.217950279577053e-07\n",
            "bert_model.encoder.layer.1.attention.self.value.bias 2.1701653807326693e-08\n",
            "bert_model.encoder.layer.1.attention.output.dense.weight 3.345418519984378e-07\n",
            "bert_model.encoder.layer.1.attention.output.dense.bias 1.6381900280748596e-08\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.weight 2.8376634375604226e-08\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.bias 3.0504889281246506e-08\n",
            "bert_model.encoder.layer.1.intermediate.dense.weight 6.916023949088412e-07\n",
            "bert_model.encoder.layer.1.intermediate.dense.bias 2.0992104055039817e-08\n",
            "bert_model.encoder.layer.1.output.dense.weight 5.328305974217074e-07\n",
            "bert_model.encoder.layer.1.output.dense.bias 2.0182252313816207e-08\n",
            "bert_model.encoder.layer.1.output.LayerNorm.weight 1.5244147277826414e-07\n",
            "bert_model.encoder.layer.1.output.LayerNorm.bias 8.303528886699496e-08\n",
            "bert_model.encoder.layer.2.attention.self.query.weight 1.688341022543227e-08\n",
            "bert_model.encoder.layer.2.attention.self.query.bias 1.21258847407546e-09\n",
            "bert_model.encoder.layer.2.attention.self.key.weight 1.6517587297926184e-08\n",
            "bert_model.encoder.layer.2.attention.self.key.bias 7.682598890112753e-16\n",
            "bert_model.encoder.layer.2.attention.self.value.weight 6.877070859445666e-07\n",
            "bert_model.encoder.layer.2.attention.self.value.bias 4.925389518461998e-08\n",
            "bert_model.encoder.layer.2.attention.output.dense.weight 7.979738256835844e-07\n",
            "bert_model.encoder.layer.2.attention.output.dense.bias 4.5241723256594923e-08\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.weight 6.655290007984149e-08\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.bias 5.6725269814705825e-08\n",
            "bert_model.encoder.layer.2.intermediate.dense.weight 6.636759621869714e-07\n",
            "bert_model.encoder.layer.2.intermediate.dense.bias 2.559996303830303e-08\n",
            "bert_model.encoder.layer.2.output.dense.weight 7.538523618677573e-07\n",
            "bert_model.encoder.layer.2.output.dense.bias 1.633002355561075e-08\n",
            "bert_model.encoder.layer.2.output.LayerNorm.weight 7.577447291851058e-08\n",
            "bert_model.encoder.layer.2.output.LayerNorm.bias 7.824041858839337e-08\n",
            "bert_model.encoder.layer.3.attention.self.query.weight 2.410379273953822e-08\n",
            "bert_model.encoder.layer.3.attention.self.query.bias 1.2234688817613915e-09\n",
            "bert_model.encoder.layer.3.attention.self.key.weight 3.786319169307717e-08\n",
            "bert_model.encoder.layer.3.attention.self.key.bias 2.1033907546209787e-15\n",
            "bert_model.encoder.layer.3.attention.self.value.weight 1.067627863449161e-06\n",
            "bert_model.encoder.layer.3.attention.self.value.bias 5.424218230132283e-08\n",
            "bert_model.encoder.layer.3.attention.output.dense.weight 1.5871684126977925e-06\n",
            "bert_model.encoder.layer.3.attention.output.dense.bias 5.459270013830064e-08\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.weight 9.250903332258531e-08\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.bias 9.372148213060427e-08\n",
            "bert_model.encoder.layer.3.intermediate.dense.weight 1.2749014786095358e-06\n",
            "bert_model.encoder.layer.3.intermediate.dense.bias 5.03276069707681e-08\n",
            "bert_model.encoder.layer.3.output.dense.weight 1.133529167418601e-06\n",
            "bert_model.encoder.layer.3.output.dense.bias 8.26643997697829e-08\n",
            "bert_model.encoder.layer.3.output.LayerNorm.weight 1.0845329256881087e-07\n",
            "bert_model.encoder.layer.3.output.LayerNorm.bias 1.1208506123239204e-07\n",
            "bert_model.encoder.layer.4.attention.self.query.weight 2.5931324643124753e-08\n",
            "bert_model.encoder.layer.4.attention.self.query.bias 1.3246741481509616e-09\n",
            "bert_model.encoder.layer.4.attention.self.key.weight 5.311650497219489e-08\n",
            "bert_model.encoder.layer.4.attention.self.key.bias 2.2365583099729844e-15\n",
            "bert_model.encoder.layer.4.attention.self.value.weight 1.4090454669712926e-06\n",
            "bert_model.encoder.layer.4.attention.self.value.bias 7.224644349435039e-08\n",
            "bert_model.encoder.layer.4.attention.output.dense.weight 1.973708549485309e-06\n",
            "bert_model.encoder.layer.4.attention.output.dense.bias 7.301258619918372e-08\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.weight 1.1524941356810814e-07\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.bias 1.267458884512962e-07\n",
            "bert_model.encoder.layer.4.intermediate.dense.weight 2.058698100881884e-06\n",
            "bert_model.encoder.layer.4.intermediate.dense.bias 8.419719677021931e-08\n",
            "bert_model.encoder.layer.4.output.dense.weight 1.7967370240512537e-06\n",
            "bert_model.encoder.layer.4.output.dense.bias 1.1377268549495057e-07\n",
            "bert_model.encoder.layer.4.output.LayerNorm.weight 1.6190196561183257e-07\n",
            "bert_model.encoder.layer.4.output.LayerNorm.bias 1.6365149235753051e-07\n",
            "bert_model.encoder.layer.5.attention.self.query.weight 3.62070800008496e-08\n",
            "bert_model.encoder.layer.5.attention.self.query.bias 1.7497260307308693e-09\n",
            "bert_model.encoder.layer.5.attention.self.key.weight 5.4235915314393424e-08\n",
            "bert_model.encoder.layer.5.attention.self.key.bias 1.6785155342673142e-15\n",
            "bert_model.encoder.layer.5.attention.self.value.weight 2.1335158635338303e-06\n",
            "bert_model.encoder.layer.5.attention.self.value.bias 1.0305911501973242e-07\n",
            "bert_model.encoder.layer.5.attention.output.dense.weight 2.859128471754957e-06\n",
            "bert_model.encoder.layer.5.attention.output.dense.bias 9.302145542733342e-08\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.weight 2.436279658013518e-07\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.bias 2.669603986760194e-07\n",
            "bert_model.encoder.layer.5.intermediate.dense.weight 4.3423438000900205e-06\n",
            "bert_model.encoder.layer.5.intermediate.dense.bias 1.8333086870825355e-07\n",
            "bert_model.encoder.layer.5.output.dense.weight 4.338256530900253e-06\n",
            "bert_model.encoder.layer.5.output.dense.bias 1.8671234158773586e-07\n",
            "bert_model.encoder.layer.5.output.LayerNorm.weight 3.9510641158813087e-07\n",
            "bert_model.encoder.layer.5.output.LayerNorm.bias 4.0122094446815026e-07\n",
            "bert_model.encoder.layer.6.attention.self.query.weight 5.546055348304435e-08\n",
            "bert_model.encoder.layer.6.attention.self.query.bias 2.5835305006438603e-09\n",
            "bert_model.encoder.layer.6.attention.self.key.weight 8.041804733238678e-08\n",
            "bert_model.encoder.layer.6.attention.self.key.bias 2.9778015007964325e-15\n",
            "bert_model.encoder.layer.6.attention.self.value.weight 5.260537818685407e-06\n",
            "bert_model.encoder.layer.6.attention.self.value.bias 2.4555282607252593e-07\n",
            "bert_model.encoder.layer.6.attention.output.dense.weight 8.299760338559281e-06\n",
            "bert_model.encoder.layer.6.attention.output.dense.bias 2.3276585636722302e-07\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.weight 8.714692967259907e-07\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.bias 8.088788376880984e-07\n",
            "bert_model.encoder.layer.6.intermediate.dense.weight 1.072422310244292e-05\n",
            "bert_model.encoder.layer.6.intermediate.dense.bias 4.6123014385557326e-07\n",
            "bert_model.encoder.layer.6.output.dense.weight 1.098666871257592e-05\n",
            "bert_model.encoder.layer.6.output.dense.bias 5.242887368694937e-07\n",
            "bert_model.encoder.layer.6.output.LayerNorm.weight 1.7067806084014592e-06\n",
            "bert_model.encoder.layer.6.output.LayerNorm.bias 1.381716856485582e-06\n",
            "bert_model.encoder.layer.7.attention.self.query.weight 1.4919307034233498e-07\n",
            "bert_model.encoder.layer.7.attention.self.query.bias 6.9226180343662236e-09\n",
            "bert_model.encoder.layer.7.attention.self.key.weight 2.042588675976731e-07\n",
            "bert_model.encoder.layer.7.attention.self.key.bias 1.3238006035061391e-14\n",
            "bert_model.encoder.layer.7.attention.self.value.weight 1.6966947441687807e-05\n",
            "bert_model.encoder.layer.7.attention.self.value.bias 7.877887924223614e-07\n",
            "bert_model.encoder.layer.7.attention.output.dense.weight 3.505828499328345e-05\n",
            "bert_model.encoder.layer.7.attention.output.dense.bias 8.952840175879828e-07\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.weight 3.5040641250816407e-06\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.bias 3.467944679869106e-06\n",
            "bert_model.encoder.layer.7.intermediate.dense.weight 4.45112309535034e-05\n",
            "bert_model.encoder.layer.7.intermediate.dense.bias 1.968387323358911e-06\n",
            "bert_model.encoder.layer.7.output.dense.weight 5.196149504627101e-05\n",
            "bert_model.encoder.layer.7.output.dense.bias 1.2644976550291176e-06\n",
            "bert_model.encoder.layer.7.output.LayerNorm.weight 5.848485216120025e-06\n",
            "bert_model.encoder.layer.7.output.LayerNorm.bias 6.0202078202564735e-06\n",
            "bert_model.encoder.layer.8.attention.self.query.weight 6.681542004116636e-07\n",
            "bert_model.encoder.layer.8.attention.self.query.bias 3.105547108361861e-08\n",
            "bert_model.encoder.layer.8.attention.self.key.weight 8.846528771755402e-07\n",
            "bert_model.encoder.layer.8.attention.self.key.bias 4.657246674899182e-14\n",
            "bert_model.encoder.layer.8.attention.self.value.weight 7.030338747426867e-05\n",
            "bert_model.encoder.layer.8.attention.self.value.bias 3.283237901996472e-06\n",
            "bert_model.encoder.layer.8.attention.output.dense.weight 0.00012783455895259976\n",
            "bert_model.encoder.layer.8.attention.output.dense.bias 2.934156782430364e-06\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.weight 1.2023946510453243e-05\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.bias 1.2184509614598937e-05\n",
            "bert_model.encoder.layer.8.intermediate.dense.weight 0.00017822514928411692\n",
            "bert_model.encoder.layer.8.intermediate.dense.bias 7.789921255607624e-06\n",
            "bert_model.encoder.layer.8.output.dense.weight 0.0002346006949665025\n",
            "bert_model.encoder.layer.8.output.dense.bias 6.627615221077576e-06\n",
            "bert_model.encoder.layer.8.output.LayerNorm.weight 2.4259530619019642e-05\n",
            "bert_model.encoder.layer.8.output.LayerNorm.bias 2.5403185645700432e-05\n",
            "bert_model.encoder.layer.9.attention.self.query.weight 3.39733628607064e-06\n",
            "bert_model.encoder.layer.9.attention.self.query.bias 1.5442316225744435e-07\n",
            "bert_model.encoder.layer.9.attention.self.key.weight 5.175907517696032e-06\n",
            "bert_model.encoder.layer.9.attention.self.key.bias 5.467678718638902e-13\n",
            "bert_model.encoder.layer.9.attention.self.value.weight 0.00031766906613484025\n",
            "bert_model.encoder.layer.9.attention.self.value.bias 1.4851812920824159e-05\n",
            "bert_model.encoder.layer.9.attention.output.dense.weight 0.0005695227300748229\n",
            "bert_model.encoder.layer.9.attention.output.dense.bias 1.5736415662104264e-05\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.weight 5.320033960742876e-05\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.bias 5.295117443893105e-05\n",
            "bert_model.encoder.layer.9.intermediate.dense.weight 0.00024169363314285874\n",
            "bert_model.encoder.layer.9.intermediate.dense.bias 9.871057045529597e-06\n",
            "bert_model.encoder.layer.9.output.dense.weight 0.00017299970204476267\n",
            "bert_model.encoder.layer.9.output.dense.bias 5.074789805803448e-05\n",
            "bert_model.encoder.layer.9.output.LayerNorm.weight 6.036550985299982e-05\n",
            "bert_model.encoder.layer.9.output.LayerNorm.bias 6.329336611088365e-05\n",
            "bert_model.encoder.layer.10.attention.self.query.weight 6.416575615730835e-06\n",
            "bert_model.encoder.layer.10.attention.self.query.bias 2.8581820288309245e-07\n",
            "bert_model.encoder.layer.10.attention.self.key.weight 1.0721821126935538e-05\n",
            "bert_model.encoder.layer.10.attention.self.key.bias 1.843938630258224e-12\n",
            "bert_model.encoder.layer.10.attention.self.value.weight 0.000837378203868866\n",
            "bert_model.encoder.layer.10.attention.self.value.bias 3.8807640521554276e-05\n",
            "bert_model.encoder.layer.10.attention.output.dense.weight 0.0014276619767770171\n",
            "bert_model.encoder.layer.10.attention.output.dense.bias 4.0634156903252006e-05\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.weight 0.0001460556813981384\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.bias 0.00015631667338311672\n",
            "bert_model.encoder.layer.10.intermediate.dense.weight 0.0019087104592472315\n",
            "bert_model.encoder.layer.10.intermediate.dense.bias 8.250556129496545e-05\n",
            "bert_model.encoder.layer.10.output.dense.weight 0.0017727476079016924\n",
            "bert_model.encoder.layer.10.output.dense.bias 0.00014196985284797847\n",
            "bert_model.encoder.layer.10.output.LayerNorm.weight 0.00027123582549393177\n",
            "bert_model.encoder.layer.10.output.LayerNorm.bias 0.00026724295457825065\n",
            "bert_model.encoder.layer.11.attention.self.query.weight 7.586268475279212e-05\n",
            "bert_model.encoder.layer.11.attention.self.query.bias 3.1666397717344807e-06\n",
            "bert_model.encoder.layer.11.attention.self.key.weight 0.00015054189134389162\n",
            "bert_model.encoder.layer.11.attention.self.key.bias 4.0383963534340594e-11\n",
            "bert_model.encoder.layer.11.attention.self.value.weight 0.003990030847489834\n",
            "bert_model.encoder.layer.11.attention.self.value.bias 0.00017344603838864714\n",
            "bert_model.encoder.layer.11.attention.output.dense.weight 0.007220827974379063\n",
            "bert_model.encoder.layer.11.attention.output.dense.bias 0.00015322006947826594\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.weight 0.0008764652302488685\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.bias 0.0008691671537235379\n",
            "bert_model.encoder.layer.11.intermediate.dense.weight 0.010736722499132156\n",
            "bert_model.encoder.layer.11.intermediate.dense.bias 0.0004038778424728662\n",
            "bert_model.encoder.layer.11.output.dense.weight 0.008975757285952568\n",
            "bert_model.encoder.layer.11.output.dense.bias 0.0006460098084062338\n",
            "bert_model.encoder.layer.11.output.LayerNorm.weight 0.0018562412587925792\n",
            "bert_model.encoder.layer.11.output.LayerNorm.bias 0.0017976529197767377\n",
            "bert_model.pooler.dense.weight 0.04153117537498474\n",
            "bert_model.pooler.dense.bias 0.0024123075418174267\n",
            "linear.weight 0.31902554631233215\n",
            "linear.bias 0.010816862806677818\n",
            "\n",
            "  training loss: 0.03\n",
            "  Training epcoh took: 0:00:47\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-26e827a2ce8f>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# tell the model that we are in training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# each batch cointains 32 examples corresponding input ids, attention, token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m       \u001b[0;31m# Progress update every 40 batches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m40\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-68bb23c3cd87>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Pad or truncate all sentences to the same length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Create the attention masks which explicitly differentiate real tokens from [PAD] tokens.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         inputs = self.tokenizer.encode_plus(title,None, add_special_tokens=True,max_length=self.max_len,padding='max_length',return_token_type_ids=True,truncation=True,\n\u001b[0m\u001b[1;32m     34\u001b[0m                                             \u001b[0mreturn_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2715\u001b[0m         )\n\u001b[1;32m   2716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2717\u001b[0;31m         return self._encode_plus(\n\u001b[0m\u001b[1;32m   2718\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2719\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m         return self.prepare_for_model(\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0mfirst_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0mpair_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecond_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mprepare_for_model\u001b[0;34m(self, ids, pair_ids, add_special_tokens, padding, truncation, max_length, stride, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0mencoded_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"length\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3207\u001b[0;31m         batch_outputs = BatchEncoding(\n\u001b[0m\u001b[1;32m   3208\u001b[0m             \u001b[0mencoded_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m                     \u001b[0;31m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# training loop\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 2023\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    train_loss = 0\n",
        "    model.train() # tell the model that we are in training mode\n",
        "\n",
        "    for index, batch in enumerate(train_data_loader):\n",
        "      # Progress update every 40 batches.\n",
        "        if index % 40 == 0 and not index == 0:\n",
        "          elapsed = format_time(time.time() - t0)\n",
        "          print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(index, len(train_data_loader), elapsed))\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "        attention_mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.float)\n",
        "        outputs = model(input_ids, attention_mask, token_type_ids)\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward() #calculate gradients\n",
        "      # for name, param in model.named_parameters():\n",
        "      #     if param.grad is not None:\n",
        "      #         print(name, param.grad.data.norm(2).item())\n",
        "        # Gradient cliping: This is a technique to prevent \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step() # update rules (how parameters would be modified based on gradients, learning rate and so on)\n",
        "        scheduler.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_data_loader)\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  training loss: {0:.2f}\".format(train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "\n",
        "# Validation loop\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "    t0 = time.time()\n",
        "    valid_loss = 0\n",
        "    model.eval() # we are doing evaluation now!\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for index, batch in enumerate(val_data_loader): # each batch cointains 32 examples corresponding input ids, attention, token\n",
        "          input_ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "          attention_mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "          token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n",
        "          targets = batch['targets'].to(device, dtype = torch.float)\n",
        "          outputs = model(input_ids, attention_mask, token_type_ids)\n",
        "          loss = loss_fn(outputs, targets)\n",
        "          valid_loss += loss.item()\n",
        "\n",
        "      valid_loss /= len(val_data_loader)\n",
        "      validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(valid_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': train_loss,\n",
        "            'Valid. Loss': valid_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # training loop\n",
        "# # Set the seed value all over the place to make this reproducible.\n",
        "# import random\n",
        "# import numpy as np\n",
        "# from sklearn import metrics\n",
        "# from tqdm import tqdm, trange\n",
        "\n",
        "# seed_val = 2023\n",
        "# random.seed(seed_val)\n",
        "# np.random.seed(seed_val)\n",
        "# torch.manual_seed(seed_val)\n",
        "# torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# # We'll store a number of quantities such as training and validation loss,\n",
        "# # validation accuracy, and timings.\n",
        "# training_stats = []\n",
        "\n",
        "# # Measure the total training time for the whole run.\n",
        "# total_t0 = time.time()\n",
        "\n",
        "# # This is a function called train_model that trains a deep learning model using a training loop. The function takes in several arguments including the number of epochs (n_epochs), training and validation data loaders (training_loader and validation_loader), the model architecture (model), optimizer (optimizer), and file paths for checkpointing (checkpoint_path and best_model_path).\n",
        "\n",
        "# # The function starts by initializing a variable valid_loss_min with a very large value (infinity) to track the minimum validation loss. Then, the function loops through each epoch, where for each epoch, it loops through each batch of data in the training data loader and performs the forward and backward passes to update the model's parameters.\n",
        "# # After the training loop for each epoch is completed, the function loops through each batch of data in the validation data loader and calculates the validation loss, which is used to monitor the model's performance.\n",
        "\n",
        "# # def train_model(n_epochs, training_loader, validation_loader, model,\n",
        "# #                 optimizer, checkpoint_path, best_model_path): #file paths for checkpointing\n",
        "\n",
        "#   # initialize tracker with the maximum positive value to track the minimum validation loss\n",
        "\n",
        "#   #valid_loss_min = np.Inf\n",
        "\n",
        "# tr_loss = 0.0\n",
        "# tr_step = 0.0\n",
        "# for epoch_i in range(0, epochs):\n",
        "#     print(\"\")\n",
        "#     print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "#     print('Training...')\n",
        "#     #initially train and validation loss are zero.\n",
        "#     # Measure how long the training epoch takes.\n",
        "#     t0 = time.time()\n",
        "\n",
        "#     model.train() # tell the model that we are in training mode\n",
        "\n",
        "#     for index, batch in enumerate(train_data_loader): # each batch cointains 32 examples corresponding input ids, attention, token\n",
        "#       # Progress update every 40 batches.\n",
        "#       if index % 40 == 0 and not index == 0:\n",
        "#         elapsed = format_time(time.time() - t0)\n",
        "#          # Report progress.\n",
        "#         print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(index, len(train_data_loader), elapsed))\n",
        "\n",
        "#         input_ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "#         attention_mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "#         token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n",
        "#         targets = batch['targets'].to(device, dtype = torch.float)\n",
        "#         outputs = model(input_ids, attention_mask, token_type_ids)\n",
        "#         optimizer.zero_grad()\n",
        "#         loss = loss_fn(outputs, targets)\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward() #calculate gradients\n",
        "#         # Gradient cliping: This is a technique to prevent \"exploding gradients\" problem.\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "#         optimizer.step() # update rules (how parameters would be modified based on gradients, learning rate and so on)\n",
        "#         scheduler.step() #update the learning rate\n",
        "#         tr_loss += loss.item()\n",
        "#         tr_step += 1\n",
        "#         # Measure how long this epoch took.\n",
        "#         training_time = format_time(time.time() - t0)\n",
        "\n",
        "#         print(\"\")\n",
        "#         print(\"  training loss: {0:.2f}\".format(tr_loss))\n",
        "#         print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "\n",
        "# # Validation loop\n",
        "#     print(\"\")\n",
        "#     print(\"Running Validation...\")\n",
        "#     t0 = time.time()\n",
        "#     model.eval() # we are doing evaluation now!\n",
        "#     preds=[]\n",
        "#     label_ids=[]\n",
        "#     with torch.no_grad():\n",
        "#       for index, batch in enumerate(val_data_loader): # each batch cointains 32 examples corresponding input ids, attention, token\n",
        "#         input_ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "#         attention_mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "#         token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n",
        "#         targets = batch['targets'].to(device, dtype = torch.float)\n",
        "#         outputs = model(input_ids, attention_mask, token_type_ids)\n",
        "\n",
        "#         preds.extend(torch.sigmoid(outputs).detach().cpu().numpy().tolist())\n",
        "#         label_ids.extend(targets.detach().cpu().numpy().tolist())\n",
        "\n",
        "#         preds_out = np.array(preds)>=0.5\n",
        "\n",
        "\n",
        "#     #     # Move logits and labels to CPU\n",
        "#     #     logits = logits.detach().cpu().numpy()\n",
        "#     #     label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "#     #     # Calculate the accuracy for this batch of test sentences, and\n",
        "#     #     # accumulate it over all batches.\n",
        "#     #     total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "\n",
        "#     # # Report the final accuracy for this validation run.\n",
        "#     # avg_val_accuracy = total_eval_accuracy / len(val_data_loader)\n",
        "#     # print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "#     # # Calculate the average loss over all of the batches.\n",
        "#     # avg_val_loss = total_eval_loss / len(val_data_loader)\n",
        "\n",
        "#     #      # Measure how long the validation run took.\n",
        "#     validation_time = format_time(time.time() - t0)\n",
        "\n",
        "#     # print(\"  Validation Loss: {0:.2f}\".format(val_loss))\n",
        "#     # print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "#       # create checkpoint variable and add important data\n",
        "#       #For each epoch, the function creates a dictionary called checkpoint that contains the epoch number, current validation loss, model's state dictionary, and optimizer's state dictionary.\n",
        "#       #The checkpoint dictionary is used for saving the model's state at certain intervals (called checkpointing), which allows for resuming training from a specific epoch and avoiding loss of progress due to interruptions.\n",
        "#        # Record all statistics from this epoch.\n",
        "\n",
        "#     training_stats.append(\n",
        "#         {\n",
        "#             'epoch': epoch_i + 1,\n",
        "#             'Training Loss': tr_loss,\n",
        "#             #'Valid. Loss': val_loss,\n",
        "#             #'Valid. Accur.': avg_val_accuracy,\n",
        "#             'Training Time': training_time,\n",
        "#             'Validation Time': validation_time\n",
        "#         }\n",
        "#     )\n",
        "\n",
        "# # The line of code you have provided calculates the accuracy score of the predicted labels (preds_out) compared to the true labels (label_ids) using scikit-learn's accuracy_score function from the metrics module.\n",
        "\n",
        "# #The accuracy_score function takes two parameters: the true labels and the predicted labels, in that order. It then returns the accuracy score, which is the proportion of correct predictions out of all predictions made.\n",
        "\n",
        "# #So, the variable accuracy will contain the accuracy score of the model's predictions on the given dataset. This is a commonly used evaluation metric for classification tasks.\n",
        "#     accuracy = metrics.accuracy_score(label_ids, preds_out)\n",
        "#     F1_score_micro = metrics.f1_score(label_ids,preds_out, average='micro',zero_division=0)\n",
        "#     F1_score_macro = metrics.f1_score(label_ids,preds_out, average='macro',zero_division=0)\n",
        "\n",
        "\n",
        "\n",
        "#     print(f'tain_loss={tr_loss/tr_step}')\n",
        "#     print(f'Accuracy={accuracy}')\n",
        "#     print(f'F1_Score_Micro={F1_score_micro}')\n",
        "#     print(f'F1_Score_Macro={F1_score_macro}')\n",
        "\n",
        "\n",
        "# print(\"Training complete!\")\n",
        "\n",
        "# print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "\n",
        "#    # The function also has commented out code that saves the checkpoint and best model if the validation loss decreases.\n",
        "#    # This is a common technique called early stopping, which stops training the model when the validation loss stops improving to avoid overfitting. However, in the current implementation, this code is commented out and not used.\n",
        "\n",
        "#     #   ## TODO: save the model if validation loss has decreased\n",
        "#     #   if valid_loss <= valid_loss_min:\n",
        "#     #     print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
        "#     #     # save checkpoint as best model\n",
        "#     #     save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "#     #     valid_loss_min = valid_loss\n",
        "\n",
        "#     # print('############# Epoch {}  Done   #############\\n'.format(epoch))"
      ],
      "metadata": {
        "id": "gbrwRs1o6B5S"
      },
      "id": "gbrwRs1o6B5S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5c93931d",
      "metadata": {
        "id": "5c93931d"
      },
      "source": [
        "Using word embeddings for converting tags to numeric values is not possible, since many tags are technical words without any numeric representation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('display.precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "behMuhJVr7le",
        "outputId": "80b0f65f-3e0f-4908-895d-4a081124053c"
      },
      "id": "behMuhJVr7le",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss Training Time Validation Time\n",
              "epoch                                                          \n",
              "1               0.07     1.33e-03       0:02:09         0:01:20\n",
              "2               0.04     1.05e-03       0:01:55         0:01:23"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2e1bb01-2f29-4968-b878-0de0f14f9990\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.07</td>\n",
              "      <td>1.33e-03</td>\n",
              "      <td>0:02:09</td>\n",
              "      <td>0:01:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.04</td>\n",
              "      <td>1.05e-03</td>\n",
              "      <td>0:01:55</td>\n",
              "      <td>0:01:23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2e1bb01-2f29-4968-b878-0de0f14f9990')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2e1bb01-2f29-4968-b878-0de0f14f9990 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2e1bb01-2f29-4968-b878-0de0f14f9990');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "SPqVXvp0ssWP",
        "outputId": "3bfe890b-4d13-474a-8ce1-503f660b29f4"
      },
      "id": "SPqVXvp0ssWP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = test_df['Tidy_body'][2374]\n",
        "example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "uruOQD0xfRUE",
        "outputId": "02ee4499-10dc-45ae-984b-a79939114f9b"
      },
      "id": "uruOQD0xfRUE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'note this is symfony  26 but i believe the same overall issue applies regardless of versionto start consider this form type that is designed to represent oneormore entities as a hidden field namespace stuff omitted for brevityclass hiddenentitytype extends abstracttype          var entitymanager         protected em    public function __constructentitymanager em            thisem  em        public function buildformformbuilderinterface builder array options            if optionsmultiple             builderaddviewtransformer                new entitiestoprimarykeystransformer                    thisemgetrepositoryoptionsclass                    optionsget_pk_callback                    optionsidentifier                                     else             builderaddviewtransformer                new entitytoprimarykeytransformer                    thisemgetrepositoryoptionsclass                    optionsget_pk_callback                                                  see class docblock for description of options           inheritdoc         public function setdefaultoptionsoptionsresolverinterface resolver            resolversetdefaultsarray            get_pk_callback  functionentity                 return entitygetid                        multiple  false            identifier  id            data_class  null                resolversetrequiredarrayclass        public function getname            return hidden_entity              inheritdoc         public function getparent            return hidden    this works its straightforward and for the most part looks like like all the examples you see for adding data transformers to a form type until you get to unit testing see the problem the transformers cant be mocked but wait you say unit tests for symfony forms are integration tests theyre supposed to make sure the transformers dont fail even says so in the documentation  this test checks that none of your data transformers used by the form  failed the issynchronized method is only set to false if a data  transformer throws an exceptionok so then you live with the fact you cant isolate the transformers no big deal now consider what happens when unit testing a form that has a field of this type assume that hiddenentitytype has been defined  tagged in the service containerclass someotherformtype extends abstracttype    public function buildformformbuilderinterface builder array options            builder            addfield hidden_entity array                class  appbundleentityname                multiple  true                      now enters the problem the unit test for someotherformtype now needs to implement getextensions in order for the hidden_entity type to function so how does that lookprotected function getextensions    mockentitymanager  this        getmockbuilderdoctrineormentitymanager        disableoriginalconstructor        getmock     expectations go here     return array        new preloadedextension            arrayhidden_entity  new hiddenentitytypemockentitymanager            array            see where that comment is in the middle yeah so for this to work correctly all of the mocks and expectations that are in the unit test class for the  hiddenentitytype now effectively need to be duplicated here im not ok with this so what are my optionsinject the transformer as one of the optionsthis would be very straightforward and would make mocking simpler but ultimately just kicks the can down the road because in this scenario new entitytoprimarykeytransformer would just move from one form type class to another not to mention that i feel form types should hide their internal complexity from the rest of the system this option means pushing that complexity outside the boundary of the form typeinject a transformer factory of sorts into the form typethis is a more typical approach to removing newables from within a method but i cant shake the feeling that this is being done just to make the code testable and is not actually making the code better but if that was done it would look something like thisclass hiddenentitytype extends abstracttype          var datatransformerfactory          protected transformerfactory    public function __constructdatatransformerfactory transformerfactory            thistransformerfactory  transformerfactory        public function buildformformbuilderinterface builder array options            builderaddviewtransformer            thistransformerfactorycreatetransfomerfortypethis options                 rest of type unchanged this feels ok until i consider what the factory will actually look like it will need the entity manager injected for starters but what then if i look further down the road this supposedlygeneric factory could need all sorts of dependencies for creating data transformers of different kinds that is clearly not a good longterm design decision so then what relabel this as an entitymanagerawaredatatransformerfactory its starting to feel messy in herestuff im not thinking ofthoughts experiences solid advice'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "mI_kRHZ-lEzL",
        "outputId": "f694632a-b8e4-4935-b0f2-102debeff7b3"
      },
      "id": "mI_kRHZ-lEzL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Tidy_body  \\\n",
              "0     im creating a simple rest application with dro...   \n",
              "1     im using spring  springdatajpa and find myself...   \n",
              "2     i got one problem and i have described it belo...   \n",
              "3     can any one tell me what is a the best way to ...   \n",
              "4     why does the code below crash the net compiler...   \n",
              "...                                                 ...   \n",
              "2372  filtering rows in a particular column are easy...   \n",
              "2373  im testing a method that manipulates a collect...   \n",
              "2374  note this is symfony  26 but i believe the sam...   \n",
              "2375  i have the following example codeclass a     p...   \n",
              "2376  include cassertint main    struct point_of_par...   \n",
              "\n",
              "                            Tags  \\\n",
              "0                         [java]   \n",
              "1                         [java]   \n",
              "2     [ios, iphone, objective-c]   \n",
              "3                         [java]   \n",
              "4                           [c#]   \n",
              "...                          ...   \n",
              "2372                        [c#]   \n",
              "2373                        [c#]   \n",
              "2374                       [php]   \n",
              "2375                       [c++]   \n",
              "2376                       [c++]   \n",
              "\n",
              "                                         Binarized_Tags  \n",
              "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
              "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
              "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...  \n",
              "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
              "4     [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
              "...                                                 ...  \n",
              "2372  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
              "2373  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
              "2374  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2375  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
              "2376  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
              "\n",
              "[2377 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37f4484d-9536-4c5d-8649-af1977b5e9aa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tidy_body</th>\n",
              "      <th>Tags</th>\n",
              "      <th>Binarized_Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>im creating a simple rest application with dro...</td>\n",
              "      <td>[java]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im using spring  springdatajpa and find myself...</td>\n",
              "      <td>[java]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i got one problem and i have described it belo...</td>\n",
              "      <td>[ios, iphone, objective-c]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>can any one tell me what is a the best way to ...</td>\n",
              "      <td>[java]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>why does the code below crash the net compiler...</td>\n",
              "      <td>[c#]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>filtering rows in a particular column are easy...</td>\n",
              "      <td>[c#]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>im testing a method that manipulates a collect...</td>\n",
              "      <td>[c#]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>note this is symfony  26 but i believe the sam...</td>\n",
              "      <td>[php]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2375</th>\n",
              "      <td>i have the following example codeclass a     p...</td>\n",
              "      <td>[c++]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2376</th>\n",
              "      <td>include cassertint main    struct point_of_par...</td>\n",
              "      <td>[c++]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2377 rows  3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37f4484d-9536-4c5d-8649-af1977b5e9aa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-37f4484d-9536-4c5d-8649-af1977b5e9aa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-37f4484d-9536-4c5d-8649-af1977b5e9aa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "589635ad",
      "metadata": {
        "id": "589635ad",
        "outputId": "ec7a6a18-1bed-45ff-e448-581fe10d330b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.17071707546710968, 0.19788900017738342, 0.21107731759548187, 0.15182703733444214, 0.16406583786010742, 0.2088538408279419, 0.1630168855190277, 0.17239728569984436, 0.20080435276031494, 0.18382464349269867, 0.1743704080581665, 0.15247520804405212, 0.20041188597679138, 0.2146158218383789, 0.22487105429172516, 0.21170394122600555, 0.1931118667125702, 0.14756499230861664, 0.16436760127544403, 0.13168522715568542, 0.18709668517112732, 0.16109640896320343, 0.21007110178470612, 0.16722731292247772, 0.18607808649539948, 0.24415501952171326, 0.1626816987991333, 0.18970374763011932, 0.21194742619991302, 0.1679966300725937]]\n",
            "['ruby']\n"
          ]
        }
      ],
      "source": [
        "# testing\n",
        "#tokenize test\n",
        "encodings = tokenizer.encode_plus(\n",
        "    example,\n",
        "    None,\n",
        "    add_special_tokens=True,\n",
        "    max_length=MAX_LEN,\n",
        "    padding='max_length',\n",
        "    return_token_type_ids=True,\n",
        "    truncation=True,\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "#before predicting we should set eval model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    input_ids = encodings['input_ids'].to(device, dtype=torch.long)\n",
        "    attention_mask = encodings['attention_mask'].to(device, dtype=torch.long)\n",
        "    token_type_ids = encodings['token_type_ids'].to(device, dtype=torch.long)\n",
        "    output = model(input_ids, attention_mask, token_type_ids)\n",
        "    # Now we have 768 outputs, sigmoid\n",
        "    final_output = torch.sigmoid(output).cpu().detach().numpy().tolist()\n",
        "    print (final_output)\n",
        "    print(mlb.classes_[np.argmax(final_output, axis=1)])\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OA3sIRXohl1T"
      },
      "id": "OA3sIRXohl1T"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72fe81e3",
      "metadata": {
        "id": "72fe81e3"
      },
      "outputs": [],
      "source": [
        "# from sklearn.cluster import DBSCAN\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from gensim.models import KeyedVectors\n",
        "\n",
        "# # Load the pre-trained word2vec model\n",
        "# model = KeyedVectors.load_word2vec_format(data_location + \"GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
        "\n",
        "# # Normalize the data\n",
        "# tag_vectors_scaled = StandardScaler().fit_transform(tag_vectors)\n",
        "\n",
        "# # apply DBSCAN to cluster the vectors\n",
        "# dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
        "# clusters = dbscan.fit_predict(tag_vectors_scaled)\n",
        "\n",
        "# # assign each tag to its corresponding cluster\n",
        "# df[\"Cluster\"] = np.where(np.array(clusters) == -1, \"Noise\", clusters)\n",
        "\n",
        "# # print the number of clusters and their sizes\n",
        "# print(\"Number of clusters:\", len(np.unique(clusters))-1) # exclude the noise cluster\n",
        "# print(\"Cluster sizes:\", df.groupby(\"Cluster\").size())\n",
        "\n",
        "# unique_tags = tags_df[\"Tag\"].unique()\n",
        "# tag_vectors = []\n",
        "# for tag in unique_tags:\n",
        "#     try:\n",
        "#         tag_vec = model[tag]\n",
        "#         tag_vectors.append(tag_vec)\n",
        "#     except KeyError:\n",
        "#         # handle tags that are not in the vocabulary of the model\n",
        "#         print(tag)\n",
        "#         pass\n",
        "\n",
        "# df = pd.DataFrame(data = {'tags': unique_tags, 'word2vec presentation': tag_vectors})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}